{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-2GcUhgB0S7"
      },
      "source": [
        "# ML4NLP1\n",
        "## Starting Point for Exercise 1, part II\n",
        "\n",
        "This notebook is supposed to serve as a starting point and/or inspiration when starting exercise 1, part II.\n",
        "\n",
        "One of the goals of this exercise is o make you acquainted with **skorch**. You will probably need to consult the [documentation](https://skorch.readthedocs.io/en/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V920LTuiq40d"
      },
      "source": [
        "# Installing skorch and loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "utYcb97jq40t"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "# Installation on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch'])\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WZ3Y_KHvq40x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from skorch import NeuralNetClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D9d6X0ZZq40z"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H55IvQdyq403"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import string\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnY8yaDq400"
      },
      "source": [
        "## Training a classifier and making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWjt9xGoswAC",
        "outputId": "028812c7-56e1-46b3-ba67-66edaa621b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs\n",
            "To: /content/x_train.txt\n",
            "100% 64.1M/64.1M [00:01<00:00, 39.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6\n",
            "To: /content/x_test.txt\n",
            "100% 65.2M/65.2M [00:00<00:00, 186MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl\n",
            "To: /content/y_train.txt\n",
            "100% 480k/480k [00:00<00:00, 18.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X\n",
            "To: /content/y_test.txt\n",
            "100% 480k/480k [00:00<00:00, 18.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download dataset\n",
        "!gdown 1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs # x_train\n",
        "!gdown 1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6 # x_test\n",
        "!gdown 1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl # y_train\n",
        "!gdown 1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X # y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-M6DgXdjtJyH"
      },
      "outputs": [],
      "source": [
        "with open(f'x_train.txt') as f:\n",
        "    x_train = f.read().splitlines()\n",
        "with open(f'y_train.txt') as f:\n",
        "    y_train = f.read().splitlines()\n",
        "with open(f'x_test.txt') as f:\n",
        "    x_test = f.read().splitlines()\n",
        "with open(f'y_test.txt') as f:\n",
        "    y_test = f.read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oRqfDA9FuoX1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# combine x_train and y_train into one dataframe\n",
        "train_df = pd.DataFrame({'text': x_train, 'label': y_train})\n",
        "\n",
        "#combine x_test and y_test into one dataframe\n",
        "test_df = pd.DataFrame({'text': x_test, 'label': y_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r2cICoZ8xNMM"
      },
      "outputs": [],
      "source": [
        "# T: Please use again the train/test data that includes English, German, Dutch, Danish, Swedish and Norwegian, plus 20 additional languages of your choice (the labels can be found in the file labels.csv)\n",
        "# and adjust the train/test split if needed\n",
        "from sklearn.model_selection import train_test_split\n",
        "all_df = pd.DataFrame({'text': x_train + x_test, 'label': y_train + y_test})\n",
        "train_df_re, test_df_re = train_test_split(all_df, test_size=0.2, stratify=all_df['label'])\n",
        "train_df_re, valid_df = train_test_split(train_df_re, test_size=0.2, stratify=train_df_re['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PXpIOpjRxzTl"
      },
      "outputs": [],
      "source": [
        "#lables\n",
        "decided_labels = ['eng', 'deu', 'nld', 'dan', 'swe', 'nno', 'jpn']\n",
        "\n",
        "additional_labels = ['lzh', 'kor', 'ell', 'fra', 'isl',\n",
        "                     'ita', 'pol', 'spa', 'rus', 'ara',\n",
        "                     'ang', 'fas', 'lat', 'por', 'hye',\n",
        "                     'tur', 'chr', 'ind',  'zea', 'hat']\n",
        "\n",
        "selected_labels = decided_labels + additional_labels\n",
        "\n",
        "train_subset = train_df_re[train_df_re['label'].isin(selected_labels)]\n",
        "valid_subset = valid_df[valid_df['label'].isin(selected_labels)]\n",
        "test_subset = test_df_re[test_df_re['label'].isin(selected_labels)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = train_subset.copy()\n",
        "valid_subset = valid_subset.copy()\n",
        "test_subset = test_subset.copy()"
      ],
      "metadata": {
        "id": "QnXX3zItfpka"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean text\n",
        "train_subset['text'] = train_subset['text'].str.lower()\n",
        "valid_subset['text'] = valid_subset['text'].str.lower()\n",
        "test_subset['text'] = test_subset['text'].str.lower()"
      ],
      "metadata": {
        "id": "F69rcChifSC2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean text\n",
        "def remove_punctuation_and_numbers(text):\n",
        "    return re.sub(r'[^\\w\\s]|_', '', text)\n",
        "\n",
        "train_subset['text'] = train_subset['text'].apply(remove_punctuation_and_numbers)\n",
        "valid_subset['text'] = valid_subset['text'].apply(remove_punctuation_and_numbers)\n",
        "test_subset['text'] = test_subset['text'].apply(remove_punctuation_and_numbers)"
      ],
      "metadata": {
        "id": "d5pz9JwgfVQf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4dVfMUq2ckxY"
      },
      "outputs": [],
      "source": [
        "#Label encode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_fitted = LabelEncoder().fit(train_subset['label'])\n",
        "\n",
        "y_train_subset = le_fitted.transform(train_subset['label'])\n",
        "y_valid_subset = le_fitted.transform(valid_subset['label'])\n",
        "y_test_subset = le_fitted.transform(test_subset['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original version"
      ],
      "metadata": {
        "id": "sCJTiCcKM48Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "212FI4CFFnrS"
      },
      "outputs": [],
      "source": [
        "# T: In the following, you can find a small (almost) working example of a neural network. Unfortunately, again, the cat messed up some of the code. Please fix the code such that it is executable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we extract some simple features as input for the neural network\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2,2), max_features=100, binary=True)\n",
        "X = vectorizer.fit_transform(train_subset['text'].to_numpy())"
      ],
      "metadata": {
        "id": "7RxhY8E4KsOc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation dataset\n",
        "import skorch\n",
        "from skorch.helper import predefined_split\n",
        "from skorch.dataset import Dataset\n",
        "X_valid = vectorizer.transform(valid_subset['text'].to_numpy())\n",
        "X_valid = X_valid.astype(np.float32)\n",
        "y_valid = y_valid_subset.astype(np.int64)\n",
        "valid_ds = Dataset(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "ET7hqh-gMlAp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.astype(np.float32)\n",
        "y = y_train_subset.astype(np.int64)"
      ],
      "metadata": {
        "id": "3nxWF5xUMlHY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMFoiitJq407"
      },
      "source": [
        "In the following, we define a vanilla neural network with two hidden layers. The output layer should have as many outputs as there are classes. In addition, it should have a nonlinearity function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=200,\n",
        "            nonlin=F.relu,\n",
        "            num_classes=27\n",
        "    ):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.num_units = num_units\n",
        "\n",
        "        self.dense0 = nn.Linear(100, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, num_classes)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = self.nonlin(self.dense0(X))\n",
        "        X = F.relu(self.dense1(X))\n",
        "        X = self.output(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "rEyoxp9rMvcf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.astype(np.float32)\n",
        "y = y_train_subset.astype(np.int64)"
      ],
      "metadata": {
        "id": "WJp5uVwRMxrf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CPU\n",
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.1,\n",
        "    train_split=predefined_split(valid_ds),\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu' # comment this to train with CPU\n",
        ")"
      ],
      "metadata": {
        "id": "SuDBa9c0M9Eu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAYsQ8vHM_9l",
        "outputId": "b1e8d0e8-0006-4ae3-a80a-4248bf42f2c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.0073\u001b[0m       \u001b[32m0.2785\u001b[0m        \u001b[35m2.6321\u001b[0m  1.9663\n",
            "      2        \u001b[36m2.1372\u001b[0m       \u001b[32m0.4315\u001b[0m        \u001b[35m1.7380\u001b[0m  1.7973\n",
            "      3        \u001b[36m1.4961\u001b[0m       \u001b[32m0.5338\u001b[0m        \u001b[35m1.3481\u001b[0m  2.2392\n",
            "      4        \u001b[36m1.2529\u001b[0m       \u001b[32m0.5745\u001b[0m        \u001b[35m1.1875\u001b[0m  2.9329\n",
            "      5        \u001b[36m1.1380\u001b[0m       \u001b[32m0.6007\u001b[0m        \u001b[35m1.1044\u001b[0m  3.3591\n",
            "      6        \u001b[36m1.0712\u001b[0m       \u001b[32m0.6322\u001b[0m        \u001b[35m1.0563\u001b[0m  1.8145\n",
            "      7        \u001b[36m1.0253\u001b[0m       \u001b[32m0.6410\u001b[0m        \u001b[35m1.0235\u001b[0m  1.7978\n",
            "      8        \u001b[36m0.9895\u001b[0m       \u001b[32m0.6486\u001b[0m        \u001b[35m0.9984\u001b[0m  1.7899\n",
            "      9        \u001b[36m0.9608\u001b[0m       \u001b[32m0.6528\u001b[0m        \u001b[35m0.9810\u001b[0m  1.7985\n",
            "     10        \u001b[36m0.9387\u001b[0m       \u001b[32m0.6551\u001b[0m        \u001b[35m0.9694\u001b[0m  1.7577\n",
            "     11        \u001b[36m0.9220\u001b[0m       \u001b[32m0.6553\u001b[0m        \u001b[35m0.9608\u001b[0m  2.3324\n",
            "     12        \u001b[36m0.9085\u001b[0m       \u001b[32m0.6574\u001b[0m        \u001b[35m0.9553\u001b[0m  1.8234\n",
            "     13        \u001b[36m0.8972\u001b[0m       0.6512        \u001b[35m0.9515\u001b[0m  1.7411\n",
            "     14        \u001b[36m0.8874\u001b[0m       0.6493        \u001b[35m0.9483\u001b[0m  1.7689\n",
            "     15        \u001b[36m0.8790\u001b[0m       0.6488        \u001b[35m0.9460\u001b[0m  1.7690\n",
            "     16        \u001b[36m0.8715\u001b[0m       0.6502        \u001b[35m0.9445\u001b[0m  1.7613\n",
            "     17        \u001b[36m0.8646\u001b[0m       0.6507        \u001b[35m0.9432\u001b[0m  2.1731\n",
            "     18        \u001b[36m0.8581\u001b[0m       0.6528        \u001b[35m0.9415\u001b[0m  2.0011\n",
            "     19        \u001b[36m0.8520\u001b[0m       0.6542        \u001b[35m0.9404\u001b[0m  1.7895\n",
            "     20        \u001b[36m0.8464\u001b[0m       0.6537        \u001b[35m0.9401\u001b[0m  1.6986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule(\n",
              "    (dense0): Linear(in_features=100, out_features=200, bias=True)\n",
              "    (dense1): Linear(in_features=200, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=27, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max_features_changed"
      ],
      "metadata": {
        "id": "aJxkNOY7NAWA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-Ls0e0GQgMF"
      },
      "outputs": [],
      "source": [
        "# Changed the max_features to 1000\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2,2), max_features=1000, binary=True)\n",
        "X = vectorizer.fit_transform(train_subset['text'].to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USDZkUopa0MY"
      },
      "outputs": [],
      "source": [
        "# Validation dataset\n",
        "import skorch\n",
        "from skorch.helper import predefined_split\n",
        "from skorch.dataset import Dataset\n",
        "X_valid = vectorizer.transform(valid_subset['text'].to_numpy())\n",
        "X_valid = X_valid.astype(np.float32)\n",
        "y_valid = y_valid_subset.astype(np.int64)\n",
        "valid_ds = Dataset(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2p1_wAVa0MY"
      },
      "outputs": [],
      "source": [
        "X = X.astype(np.float32)\n",
        "y = y_train_subset.astype(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhfiGzKWrmsW",
        "outputId": "b53c58b0-1dae-4e23-b98d-04562eae8ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(21600, 100)\n"
          ]
        }
      ],
      "source": [
        "#Check shape\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRAe6clPkY9_",
        "outputId": "bc4db620-af45-4044-ec97-e364f2ac4a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26]\n"
          ]
        }
      ],
      "source": [
        "#Check num_classes\n",
        "print(np.unique(y))\n",
        "n_classes = len(np.unique(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV6uGF_EmRgN"
      },
      "outputs": [],
      "source": [
        "#Changed the num_classes, and self.dense0 == nn.Linear(100, num_units) based on the changing of max_features\n",
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=200,\n",
        "            nonlin=F.relu,\n",
        "            num_classes=27\n",
        "    ):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.num_units = num_units\n",
        "\n",
        "        self.dense0 = nn.Linear(1000, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, num_classes)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = self.nonlin(self.dense0(X))\n",
        "        X = F.relu(self.dense1(X))\n",
        "        X = self.output(X)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKnJECeQGpyI"
      },
      "outputs": [],
      "source": [
        "\n",
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.1,\n",
        "    train_split=predefined_split(valid_ds),\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu' # comment this to train with CPU\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcNOd9yBSxys",
        "outputId": "a71ceeeb-6e2d-49a1-f7be-0edb07f25b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.6837\u001b[0m       \u001b[32m0.6813\u001b[0m        \u001b[35m1.4990\u001b[0m  3.6681\n",
            "      2        \u001b[36m0.8702\u001b[0m       \u001b[32m0.8977\u001b[0m        \u001b[35m0.4790\u001b[0m  5.0055\n",
            "      3        \u001b[36m0.3489\u001b[0m       \u001b[32m0.9551\u001b[0m        \u001b[35m0.2761\u001b[0m  4.4568\n",
            "      4        \u001b[36m0.2234\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.2184\u001b[0m  3.4463\n",
            "      5        \u001b[36m0.1766\u001b[0m       \u001b[32m0.9641\u001b[0m        \u001b[35m0.1904\u001b[0m  3.2655\n",
            "      6        \u001b[36m0.1484\u001b[0m       0.9630        \u001b[35m0.1723\u001b[0m  5.6223\n",
            "      7        \u001b[36m0.1274\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1599\u001b[0m  3.6078\n",
            "      8        \u001b[36m0.1116\u001b[0m       0.9644        \u001b[35m0.1517\u001b[0m  3.4585\n",
            "      9        \u001b[36m0.0995\u001b[0m       \u001b[32m0.9650\u001b[0m        \u001b[35m0.1464\u001b[0m  3.4328\n",
            "     10        \u001b[36m0.0901\u001b[0m       \u001b[32m0.9667\u001b[0m        \u001b[35m0.1428\u001b[0m  4.4043\n",
            "     11        \u001b[36m0.0824\u001b[0m       \u001b[32m0.9669\u001b[0m        \u001b[35m0.1405\u001b[0m  3.2564\n",
            "     12        \u001b[36m0.0759\u001b[0m       \u001b[32m0.9676\u001b[0m        \u001b[35m0.1390\u001b[0m  3.4075\n",
            "     13        \u001b[36m0.0702\u001b[0m       \u001b[32m0.9678\u001b[0m        \u001b[35m0.1381\u001b[0m  4.1798\n",
            "     14        \u001b[36m0.0652\u001b[0m       0.9676        \u001b[35m0.1377\u001b[0m  3.5700\n",
            "     15        \u001b[36m0.0606\u001b[0m       0.9676        0.1377  3.2655\n",
            "     16        \u001b[36m0.0565\u001b[0m       0.9662        0.1380  3.4725\n",
            "     17        \u001b[36m0.0528\u001b[0m       0.9664        0.1384  4.5456\n",
            "     18        \u001b[36m0.0495\u001b[0m       0.9660        0.1391  3.4382\n",
            "     19        \u001b[36m0.0464\u001b[0m       0.9660        0.1399  3.4631\n",
            "     20        \u001b[36m0.0436\u001b[0m       0.9657        0.1409  4.7531\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule(\n",
              "    (dense0): Linear(in_features=1000, out_features=200, bias=True)\n",
              "    (dense1): Linear(in_features=200, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=27, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "net.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLUylZada0MZ"
      },
      "outputs": [],
      "source": [
        "#Weights Initialization\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZZlJ_pIa0MZ"
      },
      "outputs": [],
      "source": [
        "net = skorch.NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.1,\n",
        "    train_split=predefined_split(valid_ds),\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    callbacks=[('weights_init', skorch.callbacks.Initializer('*.*', fn=weights_init))]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5ZPNeKna0MZ",
        "outputId": "fc07cae3-e911-4ec5-ad9f-093bd7af8375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.7115\u001b[0m       \u001b[32m0.7461\u001b[0m        \u001b[35m1.4827\u001b[0m  4.2845\n",
            "      2        \u001b[36m0.8410\u001b[0m       \u001b[32m0.8831\u001b[0m        \u001b[35m0.4673\u001b[0m  3.3845\n",
            "      3        \u001b[36m0.3558\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.2798\u001b[0m  3.5473\n",
            "      4        \u001b[36m0.2285\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.2188\u001b[0m  4.5250\n",
            "      5        \u001b[36m0.1777\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1905\u001b[0m  3.3483\n",
            "      6        \u001b[36m0.1486\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1725\u001b[0m  3.3457\n",
            "      7        \u001b[36m0.1280\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1599\u001b[0m  4.2898\n",
            "      8        \u001b[36m0.1127\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1509\u001b[0m  3.5599\n",
            "      9        \u001b[36m0.1009\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.1445\u001b[0m  3.4065\n",
            "     10        \u001b[36m0.0915\u001b[0m       \u001b[32m0.9641\u001b[0m        \u001b[35m0.1396\u001b[0m  3.3097\n",
            "     11        \u001b[36m0.0838\u001b[0m       \u001b[32m0.9655\u001b[0m        \u001b[35m0.1360\u001b[0m  4.3939\n",
            "     12        \u001b[36m0.0771\u001b[0m       \u001b[32m0.9664\u001b[0m        \u001b[35m0.1334\u001b[0m  3.4396\n",
            "     13        \u001b[36m0.0713\u001b[0m       \u001b[32m0.9671\u001b[0m        \u001b[35m0.1315\u001b[0m  3.5226\n",
            "     14        \u001b[36m0.0662\u001b[0m       0.9671        \u001b[35m0.1303\u001b[0m  5.3196\n",
            "     15        \u001b[36m0.0616\u001b[0m       \u001b[32m0.9674\u001b[0m        \u001b[35m0.1297\u001b[0m  4.7374\n",
            "     16        \u001b[36m0.0574\u001b[0m       0.9674        \u001b[35m0.1294\u001b[0m  3.3641\n",
            "     17        \u001b[36m0.0536\u001b[0m       \u001b[32m0.9678\u001b[0m        \u001b[35m0.1293\u001b[0m  4.4444\n",
            "     18        \u001b[36m0.0501\u001b[0m       0.9676        0.1294  3.3415\n",
            "     19        \u001b[36m0.0469\u001b[0m       \u001b[32m0.9683\u001b[0m        0.1296  3.5282\n",
            "     20        \u001b[36m0.0440\u001b[0m       0.9683        0.1300  3.8269\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule(\n",
              "    (dense0): Linear(in_features=1000, out_features=200, bias=True)\n",
              "    (dense1): Linear(in_features=200, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=27, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "net.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3sIlF75a0MZ"
      },
      "outputs": [],
      "source": [
        "# Add earlystop\n",
        "from skorch.callbacks import EarlyStopping\n",
        "net = skorch.NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.1,\n",
        "    train_split=predefined_split(valid_ds),\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    callbacks=[\n",
        "        ('weights_init', skorch.callbacks.Initializer('*.*', fn=weights_init)),\n",
        "        ('early_stopping', EarlyStopping(patience=5))\n",
        "    ],\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uoc_tu9Ow-2O",
        "outputId": "3c38ab8e-df02-40ef-d42c-a2f625cc4e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "{'lr': 0.1, 'max_epochs': 20, 'module__nonlin': <function relu at 0x7a6a85279b40>, 'module__num_units': 200, 'optimizer': <class 'torch.optim.sgd.SGD'>}\n"
          ]
        }
      ],
      "source": [
        "#Gridsearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'module__num_units': [100, 200, 300],  # Layer Sizes\n",
        "    'module__nonlin': [F.relu, torch.sigmoid],  # Activation Functions\n",
        "    'lr': [1, 0.1],  # Learning Rate\n",
        "    'max_epochs': [10, 20],  # Epochs\n",
        "    'optimizer': [torch.optim.SGD, torch.optim.Adam],# Optimizers\n",
        "\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(net, param_grid, refit=True, cv=3, scoring='accuracy')\n",
        "gs.fit(X, y)\n",
        "\n",
        "print(\"Best parameters set found on development set:\")\n",
        "print(gs.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update parameters\n",
        "net = skorch.NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "\n",
        "    module__num_units=200,\n",
        "    module__nonlin=F.relu,\n",
        "    lr=0.1,\n",
        "    max_epochs=20,\n",
        "    optimizer=torch.optim.SGD,\n",
        "\n",
        "    train_split=predefined_split(valid_ds),\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    callbacks=[\n",
        "        ('weights_init', skorch.callbacks.Initializer('*.*', fn=weights_init)),\n",
        "        ('early_stopping', EarlyStopping(patience=5))\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "VArk_hV0GJzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lvM8T-Ka0MZ",
        "outputId": "3bbb5b92-2dc3-4e19-e28b-cc56bdd507c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.7510\u001b[0m       \u001b[32m0.6664\u001b[0m        \u001b[35m1.6341\u001b[0m  3.5182\n",
            "      2        \u001b[36m0.9239\u001b[0m       \u001b[32m0.8609\u001b[0m        \u001b[35m0.5146\u001b[0m  3.7639\n",
            "      3        \u001b[36m0.3751\u001b[0m       \u001b[32m0.9512\u001b[0m        \u001b[35m0.2975\u001b[0m  3.9592\n",
            "      4        \u001b[36m0.2393\u001b[0m       \u001b[32m0.9535\u001b[0m        \u001b[35m0.2326\u001b[0m  3.4345\n",
            "      5        \u001b[36m0.1848\u001b[0m       \u001b[32m0.9574\u001b[0m        \u001b[35m0.2008\u001b[0m  3.4058\n",
            "      6        \u001b[36m0.1539\u001b[0m       \u001b[32m0.9588\u001b[0m        \u001b[35m0.1806\u001b[0m  4.3953\n",
            "      7        \u001b[36m0.1320\u001b[0m       \u001b[32m0.9597\u001b[0m        \u001b[35m0.1666\u001b[0m  3.4007\n",
            "      8        \u001b[36m0.1156\u001b[0m       \u001b[32m0.9618\u001b[0m        \u001b[35m0.1571\u001b[0m  3.3969\n",
            "      9        \u001b[36m0.1031\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1505\u001b[0m  3.8815\n",
            "     10        \u001b[36m0.0933\u001b[0m       \u001b[32m0.9639\u001b[0m        \u001b[35m0.1457\u001b[0m  4.0868\n",
            "     11        \u001b[36m0.0853\u001b[0m       \u001b[32m0.9646\u001b[0m        \u001b[35m0.1421\u001b[0m  3.2466\n",
            "     12        \u001b[36m0.0784\u001b[0m       \u001b[32m0.9648\u001b[0m        \u001b[35m0.1392\u001b[0m  3.2905\n",
            "     13        \u001b[36m0.0724\u001b[0m       \u001b[32m0.9655\u001b[0m        \u001b[35m0.1371\u001b[0m  4.4577\n",
            "     14        \u001b[36m0.0670\u001b[0m       0.9650        \u001b[35m0.1355\u001b[0m  3.4395\n",
            "     15        \u001b[36m0.0622\u001b[0m       \u001b[32m0.9657\u001b[0m        \u001b[35m0.1345\u001b[0m  3.4119\n",
            "     16        \u001b[36m0.0578\u001b[0m       \u001b[32m0.9662\u001b[0m        \u001b[35m0.1340\u001b[0m  3.7423\n",
            "     17        \u001b[36m0.0539\u001b[0m       0.9655        \u001b[35m0.1340\u001b[0m  3.9473\n",
            "     18        \u001b[36m0.0502\u001b[0m       0.9657        0.1341  3.2907\n",
            "     19        \u001b[36m0.0470\u001b[0m       0.9657        0.1345  3.3305\n",
            "     20        \u001b[36m0.0440\u001b[0m       0.9650        0.1350  4.3609\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule(\n",
              "    (dense0): Linear(in_features=1000, out_features=200, bias=True)\n",
              "    (dense1): Linear(in_features=200, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=27, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "net.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc89xgFNa0Ma"
      },
      "outputs": [],
      "source": [
        "# Evaluate the result\n",
        "X_train = vectorizer.transform(train_subset['text'].to_numpy()).astype(np.float32)\n",
        "X_test = vectorizer.transform(test_subset['text'].to_numpy()).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = net.score(X_train, y_train_subset)\n",
        "valid_accuracy = net.score(X_valid, y_valid_subset)\n",
        "test_accuracy = net.score(X_test, y_test_subset)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation Accuracy: {valid_accuracy*100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0KzsKMWJmp1",
        "outputId": "b1c2bbc1-5c35-45e4-9292-da211be33ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 98.99%\n",
            "Validation Accuracy: 96.50%\n",
            "Test Accuracy: 96.41%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd97b8bffa4d3737e84826bc3d37be3046061822757ce35137ab82ad4c5a2016"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}