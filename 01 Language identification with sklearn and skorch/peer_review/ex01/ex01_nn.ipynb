{"cells":[{"cell_type":"markdown","source":["# ML4NLP1\n","## Starting Point for Exercise 1, part II\n","\n","This notebook is supposed to serve as a starting point and/or inspiration when starting exercise 1, part II.\n","\n","One of the goals of this exercise is o make you acquainted with **skorch**. You will probably need to consult the [documentation](https://skorch.readthedocs.io/en/stable/)."],"metadata":{"id":"Q-2GcUhgB0S7"}},{"cell_type":"markdown","metadata":{"id":"V920LTuiq40d"},"source":["# Installing skorch and loading libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"utYcb97jq40t"},"outputs":[],"source":["import subprocess\n","\n","# Installation on Google Colab\n","try:\n","    import google.colab\n","    subprocess.run(['python', '-m', 'pip', 'install', 'skorch'])\n","except ImportError:\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZ3Y_KHvq40x"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from skorch import NeuralNetClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9d6X0ZZq40z"},"outputs":[],"source":["torch.manual_seed(0)\n","torch.cuda.manual_seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H55IvQdyq403"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import csv\n","import re\n","import string\n","from collections import defaultdict"]},{"cell_type":"markdown","metadata":{"id":"dAnY8yaDq400"},"source":["## Training a classifier and making predictions"]},{"cell_type":"code","source":["# download dataset\n","!gdown 1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs # x_train\n","!gdown 1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6 # x_test\n","!gdown 1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl # y_train\n","!gdown 1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X # y_test"],"metadata":{"id":"zWjt9xGoswAC","executionInfo":{"status":"ok","timestamp":1696790296123,"user_tz":-480,"elapsed":14475,"user":{"displayName":"Haozhe Luo","userId":"17359668240613124024"}},"outputId":"da648cbb-ba9c-46ef-899e-95e6430af495","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs\n","To: /content/x_train.txt\n","100% 64.1M/64.1M [00:01<00:00, 41.6MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6\n","To: /content/x_test.txt\n","100% 65.2M/65.2M [00:00<00:00, 70.5MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl\n","To: /content/y_train.txt\n","100% 480k/480k [00:00<00:00, 103MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X\n","To: /content/y_test.txt\n","100% 480k/480k [00:00<00:00, 128MB/s]\n"]}]},{"cell_type":"code","source":["with open(f'x_train.txt') as f:\n","    x_train = f.read().splitlines()\n","with open(f'y_train.txt') as f:\n","    y_train = f.read().splitlines()\n","with open(f'x_test.txt') as f:\n","    x_test = f.read().splitlines()\n","with open(f'y_test.txt') as f:\n","    y_test = f.read().splitlines()"],"metadata":{"id":"-M6DgXdjtJyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","# combine x_train and y_train into one dataframe\n","train_df = pd.DataFrame({'text': x_train, 'label': y_train})\n","\n","#combine x_test and y_test into one dataframe\n","test_df = pd.DataFrame({'text': x_test, 'label': y_test})"],"metadata":{"id":"oRqfDA9FuoX1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# T: Please use again the train/test data that includes English, German, Dutch, Danish, Swedish and Norwegian, plus 20 additional languages of your choice (the labels can be found in the file labels.csv)\n","# and adjust the train/test split if needed\n","\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","test_df_to_train, test_df_remaining = train_test_split(test_df, test_size=0.5, random_state=42, stratify=test_df['label'])\n","\n","train_df = pd.concat([train_df, test_df_to_train], ignore_index=True)\n","\n","test_df = test_df_remaining\n","\n","fixed_languages = ['eng', 'deu', 'nld', 'dan', 'swe', 'nor']\n","self_selected_languages = ['est', 'tha', 'guj', 'tam', 'vie', 'lat', 'urd', 'por', 'fra', 'rus', 'ara', 'heb', 'hin', 'jpn', 'kor', 'zho', 'spa', 'ita', 'tur', 'ell']\n","final_language_list = fixed_languages + self_selected_languages\n","sub_traindf = train_df[train_df['label'].isin(final_language_list)]\n","sub_testdf = test_df[test_df['label'].isin(final_language_list)]\n"],"metadata":{"id":"r2cICoZ8xNMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# T: use your adjusted code to encode the labels here\n","# T: With the following code, we wanted to encode the labels, however, our cat was walking on the keyboard and some of it got changed. Can you fix it?\n","from sklearn.preprocessing import LabelEncoder\n","le_fitted = LabelEncoder().fit(sub_traindf['label'])\n","y_train_dev, y_test = le_fitted.transform(sub_traindf['label']), le_fitted.transform(sub_testdf['label'])\n"],"metadata":{"id":"PXpIOpjRxzTl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# T: In the following, you can find a small (almost) working example of a neural network. Unfortunately, again, the cat messed up some of the code. Please fix the code such that it is executable."],"metadata":{"id":"212FI4CFFnrS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# First, we extract some simple features as input for the neural network\n","# import package:\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=1000, binary=True)\n","X = vectorizer.fit_transform(sub_traindf['text'].to_numpy())"],"metadata":{"id":"2-Ls0e0GQgMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = X.astype(np.float32)\n","y = y_train_dev.astype(np.int64)"],"metadata":{"id":"9EiRal_1Q0iJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oMFoiitJq407"},"source":["In the following, we define a vanilla neural network with two hidden layers. The output layer should have as many outputs as there are classes. In addition, it should have a nonlinearity function."]},{"cell_type":"code","source":["class ClassifierModule(nn.Module):\n","    def __init__(\n","            self,\n","            num_units=200,\n","            nonlin=F.relu,\n","    ):\n","        super(ClassifierModule, self).__init__()\n","        self.num_units = num_units\n","        self.nonlin = nonlin\n","\n","        self.dense0 = nn.Linear(1000, num_units)\n","        self.nonlin = nonlin\n","        self.dense1 = nn.Linear(num_units, 50)\n","        self.output = nn.Linear(50, 25)\n","\n","    def forward(self, X, **kwargs):\n","      X = self.nonlin(self.dense0(X))\n","      X = F.relu(self.dense1(X))\n","      X = self.output(X)\n","      return X.squeeze(dim=1)"],"metadata":{"id":"7Q5EDIGQUUBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kPLtiJ2ETRJJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from sklearn.model_selection import GridSearchCV\n","from skorch.callbacks import EarlyStopping\n","net = NeuralNetClassifier(\n","    ClassifierModule,\n","    max_epochs=20,\n","    criterion=nn.CrossEntropyLoss(),\n","    callbacks=[('earlystopping', EarlyStopping(patience=5))],\n","    lr=0.1,\n","    #device='cuda',  # comment this to train with CPU\n",")\n","params = {\n","    'optimizer': [torch.optim.SGD, torch.optim.Adam],\n","    'module__nonlin':[F.relu, F.tanh],\n","    'module__num_units': [800,200],\n","    'callbacks__earlystopping__patience':[5,10]\n","}\n","\n","# Note: Consider using StratifiedKFold for classification tasks\n","gs = GridSearchCV(net, params, refit=True, cv=3, scoring='accuracy', verbose=3)"],"metadata":{"id":"wKnJECeQGpyI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X.shape)\n","print(y_train_dev.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbmoA3QzyeWA","executionInfo":{"status":"ok","timestamp":1696783705822,"user_tz":-480,"elapsed":327,"user":{"displayName":"Haozhe Luo","userId":"17359668240613124024"}},"outputId":"aef2b7a3-be48-4cde-ae69-ccea92b0fce8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(18750, 1000)\n","(18750,)\n"]}]},{"cell_type":"code","source":["gs.fit(X, y_train_dev)"],"metadata":{"id":"QcNOd9yBSxys","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d5a71a37-eba6-4536-ff16-258666255ce0","executionInfo":{"status":"ok","timestamp":1696785514537,"user_tz":-480,"elapsed":1807806,"user":{"displayName":"Haozhe Luo","userId":"17359668240613124024"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 16 candidates, totalling 48 fits\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8769\u001b[0m       \u001b[32m0.4356\u001b[0m        \u001b[35m2.4801\u001b[0m  2.2969\n","      2        \u001b[36m1.4343\u001b[0m       \u001b[32m0.5916\u001b[0m        \u001b[35m1.3274\u001b[0m  2.2242\n","      3        \u001b[36m0.5960\u001b[0m       \u001b[32m0.8956\u001b[0m        \u001b[35m0.4880\u001b[0m  2.3504\n","      4        \u001b[36m0.3404\u001b[0m       \u001b[32m0.9496\u001b[0m        \u001b[35m0.3138\u001b[0m  2.9736\n","      5        \u001b[36m0.2463\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.2495\u001b[0m  2.1917\n","      6        \u001b[36m0.1972\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.2166\u001b[0m  2.1699\n","      7        \u001b[36m0.1673\u001b[0m       \u001b[32m0.9604\u001b[0m        \u001b[35m0.1973\u001b[0m  2.2055\n","      8        \u001b[36m0.1465\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1844\u001b[0m  2.1756\n","      9        \u001b[36m0.1302\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1747\u001b[0m  3.2393\n","     10        \u001b[36m0.1164\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1669\u001b[0m  2.1843\n","     11        \u001b[36m0.1044\u001b[0m       \u001b[32m0.9648\u001b[0m        \u001b[35m0.1607\u001b[0m  2.2160\n","     12        \u001b[36m0.0940\u001b[0m       \u001b[32m0.9656\u001b[0m        \u001b[35m0.1558\u001b[0m  2.1917\n","     13        \u001b[36m0.0850\u001b[0m       0.9652        \u001b[35m0.1523\u001b[0m  2.1812\n","     14        \u001b[36m0.0774\u001b[0m       0.9648        \u001b[35m0.1498\u001b[0m  2.7670\n","     15        \u001b[36m0.0708\u001b[0m       0.9652        \u001b[35m0.1481\u001b[0m  2.6865\n","     16        \u001b[36m0.0651\u001b[0m       0.9648        \u001b[35m0.1470\u001b[0m  2.1858\n","     17        \u001b[36m0.0601\u001b[0m       0.9648        \u001b[35m0.1465\u001b[0m  2.2027\n","     18        \u001b[36m0.0557\u001b[0m       0.9656        \u001b[35m0.1464\u001b[0m  2.2192\n","     19        \u001b[36m0.0518\u001b[0m       0.9656        0.1466  2.4229\n","     20        \u001b[36m0.0484\u001b[0m       0.9652        0.1470  3.0478\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.965 total time=  49.2s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8423\u001b[0m       \u001b[32m0.4372\u001b[0m        \u001b[35m2.4402\u001b[0m  2.1716\n","      2        \u001b[36m1.3741\u001b[0m       \u001b[32m0.5932\u001b[0m        \u001b[35m1.3959\u001b[0m  2.1824\n","      3        \u001b[36m0.5516\u001b[0m       \u001b[32m0.9200\u001b[0m        \u001b[35m0.4458\u001b[0m  2.1991\n","      4        \u001b[36m0.3147\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m0.2910\u001b[0m  2.5208\n","      5        \u001b[36m0.2280\u001b[0m       \u001b[32m0.9548\u001b[0m        \u001b[35m0.2366\u001b[0m  2.8912\n","      6        \u001b[36m0.1859\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.2104\u001b[0m  2.2174\n","      7        \u001b[36m0.1605\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1951\u001b[0m  2.2046\n","      8        \u001b[36m0.1421\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1845\u001b[0m  2.5207\n","      9        \u001b[36m0.1272\u001b[0m       \u001b[32m0.9628\u001b[0m        \u001b[35m0.1763\u001b[0m  2.9987\n","     10        \u001b[36m0.1144\u001b[0m       0.9628        \u001b[35m0.1696\u001b[0m  2.8530\n","     11        \u001b[36m0.1032\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1643\u001b[0m  2.1735\n","     12        \u001b[36m0.0935\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1603\u001b[0m  2.1824\n","     13        \u001b[36m0.0851\u001b[0m       0.9640        \u001b[35m0.1572\u001b[0m  2.1541\n","     14        \u001b[36m0.0778\u001b[0m       0.9632        \u001b[35m0.1550\u001b[0m  2.1826\n","     15        \u001b[36m0.0715\u001b[0m       0.9636        \u001b[35m0.1535\u001b[0m  3.2515\n","     16        \u001b[36m0.0660\u001b[0m       0.9640        \u001b[35m0.1525\u001b[0m  2.9575\n","     17        \u001b[36m0.0612\u001b[0m       0.9640        \u001b[35m0.1519\u001b[0m  2.1747\n","     18        \u001b[36m0.0569\u001b[0m       0.9636        \u001b[35m0.1515\u001b[0m  2.1884\n","     19        \u001b[36m0.0531\u001b[0m       0.9640        \u001b[35m0.1515\u001b[0m  2.2205\n","     20        \u001b[36m0.0497\u001b[0m       0.9636        0.1517  3.2087\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.965 total time=  50.5s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8528\u001b[0m       \u001b[32m0.4100\u001b[0m        \u001b[35m2.3280\u001b[0m  2.2011\n","      2        \u001b[36m1.5061\u001b[0m       \u001b[32m0.7336\u001b[0m        \u001b[35m0.9836\u001b[0m  2.1741\n","      3        \u001b[36m0.6193\u001b[0m       \u001b[32m0.8992\u001b[0m        \u001b[35m0.4779\u001b[0m  2.1701\n","      4        \u001b[36m0.3630\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m0.3214\u001b[0m  2.1689\n","      5        \u001b[36m0.2637\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m0.2557\u001b[0m  3.2003\n","      6        \u001b[36m0.2120\u001b[0m       \u001b[32m0.9452\u001b[0m        \u001b[35m0.2232\u001b[0m  2.2633\n","      7        \u001b[36m0.1812\u001b[0m       \u001b[32m0.9500\u001b[0m        \u001b[35m0.2049\u001b[0m  2.1742\n","      8        \u001b[36m0.1599\u001b[0m       \u001b[32m0.9532\u001b[0m        \u001b[35m0.1928\u001b[0m  2.1664\n","      9        \u001b[36m0.1432\u001b[0m       \u001b[32m0.9548\u001b[0m        \u001b[35m0.1834\u001b[0m  2.2201\n","     10        \u001b[36m0.1289\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.1755\u001b[0m  3.1410\n","     11        \u001b[36m0.1163\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1686\u001b[0m  2.3365\n","     12        \u001b[36m0.1050\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1628\u001b[0m  2.2082\n","     13        \u001b[36m0.0950\u001b[0m       0.9632        \u001b[35m0.1581\u001b[0m  2.2364\n","     14        \u001b[36m0.0863\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1545\u001b[0m  2.2087\n","     15        \u001b[36m0.0788\u001b[0m       0.9640        \u001b[35m0.1517\u001b[0m  2.7357\n","     16        \u001b[36m0.0722\u001b[0m       0.9640        \u001b[35m0.1497\u001b[0m  2.7032\n","     17        \u001b[36m0.0665\u001b[0m       0.9640        \u001b[35m0.1483\u001b[0m  2.2228\n","     18        \u001b[36m0.0614\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1475\u001b[0m  2.2470\n","     19        \u001b[36m0.0570\u001b[0m       0.9636        \u001b[35m0.1470\u001b[0m  2.2279\n","     20        \u001b[36m0.0530\u001b[0m       0.9636        \u001b[35m0.1469\u001b[0m  2.4329\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.971 total time=  49.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m5.5981\u001b[0m       \u001b[32m0.5880\u001b[0m        \u001b[35m1.3912\u001b[0m  2.9442\n","      2        \u001b[36m1.1886\u001b[0m       \u001b[32m0.6464\u001b[0m        \u001b[35m1.0448\u001b[0m  2.6825\n","      3        \u001b[36m1.0919\u001b[0m       0.6464        1.2413  2.6648\n","      4        \u001b[36m0.9727\u001b[0m       0.6428        1.4700  4.0333\n","      5        \u001b[36m0.9320\u001b[0m       \u001b[32m0.6756\u001b[0m        1.3024  3.3947\n","      6        \u001b[36m0.7587\u001b[0m       \u001b[32m0.7492\u001b[0m        \u001b[35m0.9905\u001b[0m  2.6258\n","      7        \u001b[36m0.7418\u001b[0m       0.7204        1.1468  2.6116\n","      8        0.8539       0.7112        1.1116  2.6932\n","      9        \u001b[36m0.7416\u001b[0m       0.6892       10.2237  4.1663\n","     10        1.0958       0.7220        1.3642  3.7601\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.618 total time=  36.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1       \u001b[36m11.7180\u001b[0m       \u001b[32m0.3964\u001b[0m        \u001b[35m1.8590\u001b[0m  3.5792\n","      2        \u001b[36m1.8608\u001b[0m       \u001b[32m0.4160\u001b[0m        \u001b[35m1.8258\u001b[0m  2.6325\n","      3        1.9448       0.4016        1.8264  2.6411\n","      4        2.3833       0.3952        1.8539  2.6155\n","      5        1.9267       0.3908        1.8867  3.1416\n","      6        5.0505       0.3592        2.0354  3.1081\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.368 total time=  21.4s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m6.7601\u001b[0m       \u001b[32m0.4732\u001b[0m        \u001b[35m1.5700\u001b[0m  2.6285\n","      2        \u001b[36m1.6209\u001b[0m       \u001b[32m0.4784\u001b[0m        1.5760  2.9969\n","      3        1.8084       0.3936        1.9220  3.2407\n","      4        1.7754       0.4280        1.7869  2.6020\n","      5        1.7992       0.3912        1.9373  2.6153\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.316 total time=  17.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9257\u001b[0m       \u001b[32m0.4212\u001b[0m        \u001b[35m2.5107\u001b[0m  2.4590\n","      2        \u001b[36m1.5918\u001b[0m       \u001b[32m0.5712\u001b[0m        \u001b[35m1.4053\u001b[0m  1.6102\n","      3        \u001b[36m0.6815\u001b[0m       \u001b[32m0.8392\u001b[0m        \u001b[35m0.5921\u001b[0m  1.6061\n","      4        \u001b[36m0.3672\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m0.3357\u001b[0m  1.5750\n","      5        \u001b[36m0.2527\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.2599\u001b[0m  1.5725\n","      6        \u001b[36m0.2006\u001b[0m       \u001b[32m0.9488\u001b[0m        \u001b[35m0.2241\u001b[0m  1.6315\n","      7        \u001b[36m0.1708\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.2038\u001b[0m  1.6660\n","      8        \u001b[36m0.1506\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1906\u001b[0m  2.5390\n","      9        \u001b[36m0.1350\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1809\u001b[0m  1.6932\n","     10        \u001b[36m0.1218\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1732\u001b[0m  1.6311\n","     11        \u001b[36m0.1100\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1668\u001b[0m  1.6571\n","     12        \u001b[36m0.0994\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1614\u001b[0m  1.5987\n","     13        \u001b[36m0.0900\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1571\u001b[0m  1.6341\n","     14        \u001b[36m0.0818\u001b[0m       0.9628        \u001b[35m0.1540\u001b[0m  1.6576\n","     15        \u001b[36m0.0748\u001b[0m       0.9628        \u001b[35m0.1518\u001b[0m  2.4324\n","     16        \u001b[36m0.0687\u001b[0m       0.9620        \u001b[35m0.1504\u001b[0m  1.8424\n","     17        \u001b[36m0.0634\u001b[0m       0.9632        \u001b[35m0.1496\u001b[0m  1.6209\n","     18        \u001b[36m0.0588\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1493\u001b[0m  1.6855\n","     19        \u001b[36m0.0548\u001b[0m       \u001b[32m0.9648\u001b[0m        0.1494  1.6319\n","     20        \u001b[36m0.0512\u001b[0m       0.9648        0.1497  1.5955\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.965 total time=  36.3s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0356\u001b[0m       \u001b[32m0.3244\u001b[0m        \u001b[35m2.6350\u001b[0m  1.8508\n","      2        \u001b[36m1.8005\u001b[0m       \u001b[32m0.5392\u001b[0m        \u001b[35m1.6539\u001b[0m  2.4762\n","      3        \u001b[36m0.7577\u001b[0m       \u001b[32m0.7600\u001b[0m        \u001b[35m0.7281\u001b[0m  1.6416\n","      4        \u001b[36m0.3866\u001b[0m       \u001b[32m0.9364\u001b[0m        \u001b[35m0.3426\u001b[0m  1.6378\n","      5        \u001b[36m0.2533\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m0.2597\u001b[0m  1.5973\n","      6        \u001b[36m0.1993\u001b[0m       \u001b[32m0.9496\u001b[0m        \u001b[35m0.2258\u001b[0m  1.6155\n","      7        \u001b[36m0.1702\u001b[0m       \u001b[32m0.9512\u001b[0m        \u001b[35m0.2075\u001b[0m  1.6114\n","      8        \u001b[36m0.1505\u001b[0m       \u001b[32m0.9544\u001b[0m        \u001b[35m0.1956\u001b[0m  1.7253\n","      9        \u001b[36m0.1351\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.1866\u001b[0m  2.6165\n","     10        \u001b[36m0.1220\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.1791\u001b[0m  1.6286\n","     11        \u001b[36m0.1102\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1725\u001b[0m  1.9755\n","     12        \u001b[36m0.0996\u001b[0m       0.9592        \u001b[35m0.1668\u001b[0m  1.6040\n","     13        \u001b[36m0.0903\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1622\u001b[0m  1.6675\n","     14        \u001b[36m0.0821\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1586\u001b[0m  1.6151\n","     15        \u001b[36m0.0752\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1561\u001b[0m  1.6922\n","     16        \u001b[36m0.0692\u001b[0m       0.9616        \u001b[35m0.1543\u001b[0m  2.5458\n","     17        \u001b[36m0.0641\u001b[0m       0.9620        \u001b[35m0.1532\u001b[0m  1.6366\n","     18        \u001b[36m0.0596\u001b[0m       0.9620        \u001b[35m0.1526\u001b[0m  1.6446\n","     19        \u001b[36m0.0557\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1525\u001b[0m  1.6062\n","     20        \u001b[36m0.0522\u001b[0m       0.9620        0.1527  1.6791\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.963 total time=  37.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9592\u001b[0m       \u001b[32m0.3188\u001b[0m        \u001b[35m2.5201\u001b[0m  1.6567\n","      2        \u001b[36m1.7635\u001b[0m       \u001b[32m0.6360\u001b[0m        \u001b[35m1.2510\u001b[0m  2.1789\n","      3        \u001b[36m0.7536\u001b[0m       \u001b[32m0.8076\u001b[0m        \u001b[35m0.5971\u001b[0m  2.1060\n","      4        \u001b[36m0.4020\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m0.3577\u001b[0m  1.6697\n","      5        \u001b[36m0.2761\u001b[0m       \u001b[32m0.9472\u001b[0m        \u001b[35m0.2741\u001b[0m  1.6630\n","      6        \u001b[36m0.2168\u001b[0m       \u001b[32m0.9508\u001b[0m        \u001b[35m0.2366\u001b[0m  1.6452\n","      7        \u001b[36m0.1823\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.2155\u001b[0m  1.6254\n","      8        \u001b[36m0.1587\u001b[0m       \u001b[32m0.9568\u001b[0m        \u001b[35m0.2011\u001b[0m  1.6502\n","      9        \u001b[36m0.1404\u001b[0m       \u001b[32m0.9588\u001b[0m        \u001b[35m0.1901\u001b[0m  2.0571\n","     10        \u001b[36m0.1252\u001b[0m       0.9588        \u001b[35m0.1814\u001b[0m  2.2328\n","     11        \u001b[36m0.1125\u001b[0m       0.9588        \u001b[35m0.1746\u001b[0m  1.6346\n","     12        \u001b[36m0.1018\u001b[0m       0.9588        \u001b[35m0.1694\u001b[0m  1.6433\n","     13        \u001b[36m0.0925\u001b[0m       0.9588        \u001b[35m0.1656\u001b[0m  1.6439\n","     14        \u001b[36m0.0845\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1627\u001b[0m  1.6376\n","     15        \u001b[36m0.0774\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1607\u001b[0m  1.6417\n","     16        \u001b[36m0.0712\u001b[0m       0.9608        \u001b[35m0.1590\u001b[0m  1.9143\n","     17        \u001b[36m0.0656\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1583\u001b[0m  2.3789\n","     18        \u001b[36m0.0606\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1576\u001b[0m  1.6269\n","     19        \u001b[36m0.0562\u001b[0m       0.9612        \u001b[35m0.1575\u001b[0m  1.6346\n","     20        \u001b[36m0.0522\u001b[0m       0.9612        \u001b[35m0.1574\u001b[0m  1.6358\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.968 total time=  36.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.3896\u001b[0m       \u001b[32m0.6756\u001b[0m        \u001b[35m0.9203\u001b[0m  1.7422\n","      2        \u001b[36m0.7641\u001b[0m       \u001b[32m0.7460\u001b[0m        \u001b[35m0.8283\u001b[0m  1.7836\n","      3        0.7745       0.7008        2.5942  2.5845\n","      4        1.1908       0.6940        1.7108  1.9902\n","      5        0.9453       0.7280        1.0189  1.7848\n","      6        \u001b[36m0.7261\u001b[0m       0.7312        1.3905  1.7406\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.761 total time=  14.3s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.2526\u001b[0m       \u001b[32m0.5300\u001b[0m        \u001b[35m1.3719\u001b[0m  1.7927\n","      2        \u001b[36m1.2458\u001b[0m       \u001b[32m0.5720\u001b[0m        \u001b[35m1.1308\u001b[0m  2.4833\n","      3        \u001b[36m1.1372\u001b[0m       \u001b[32m0.5888\u001b[0m        1.2354  2.0812\n","      4        \u001b[36m1.0948\u001b[0m       \u001b[32m0.6216\u001b[0m        \u001b[35m1.1046\u001b[0m  1.7969\n","      5        1.1271       \u001b[32m0.6340\u001b[0m        \u001b[35m0.9619\u001b[0m  1.7906\n","      6        1.3261       0.6080        1.1414  1.7924\n","      7        1.1273       \u001b[32m0.6468\u001b[0m        0.9810  1.7861\n","      8        \u001b[36m0.9987\u001b[0m       0.6424        0.9996  1.9427\n","      9        \u001b[36m0.9950\u001b[0m       \u001b[32m0.6552\u001b[0m        1.0376  2.5919\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.615 total time=  21.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.5016\u001b[0m       \u001b[32m0.6072\u001b[0m        \u001b[35m1.1011\u001b[0m  1.8103\n","      2        \u001b[36m1.1018\u001b[0m       0.6032        \u001b[35m1.0312\u001b[0m  1.7882\n","      3        \u001b[36m1.0909\u001b[0m       \u001b[32m0.6240\u001b[0m        1.1239  1.7875\n","      4        \u001b[36m1.0814\u001b[0m       0.5872        1.1894  2.0710\n","      5        1.1148       0.6052        1.0984  2.5072\n","      6        1.1128       0.5936        1.2886  1.7851\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.593 total time=  14.5s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.5942\u001b[0m       \u001b[32m0.4920\u001b[0m        \u001b[35m1.8210\u001b[0m  2.2693\n","      2        \u001b[36m1.0663\u001b[0m       \u001b[32m0.7360\u001b[0m        \u001b[35m0.9006\u001b[0m  2.1868\n","      3        \u001b[36m0.4873\u001b[0m       \u001b[32m0.9048\u001b[0m        \u001b[35m0.4197\u001b[0m  3.2315\n","      4        \u001b[36m0.2915\u001b[0m       \u001b[32m0.9468\u001b[0m        \u001b[35m0.2802\u001b[0m  2.2811\n","      5        \u001b[36m0.2139\u001b[0m       \u001b[32m0.9528\u001b[0m        \u001b[35m0.2306\u001b[0m  2.2252\n","      6        \u001b[36m0.1749\u001b[0m       \u001b[32m0.9588\u001b[0m        \u001b[35m0.2057\u001b[0m  2.2183\n","      7        \u001b[36m0.1502\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1903\u001b[0m  2.2517\n","      8        \u001b[36m0.1318\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1796\u001b[0m  2.9386\n","      9        \u001b[36m0.1171\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1717\u001b[0m  2.5601\n","     10        \u001b[36m0.1049\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1658\u001b[0m  2.2267\n","     11        \u001b[36m0.0947\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1615\u001b[0m  2.2506\n","     12        \u001b[36m0.0861\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1584\u001b[0m  2.2099\n","     13        \u001b[36m0.0788\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1562\u001b[0m  2.5820\n","     14        \u001b[36m0.0724\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1548\u001b[0m  2.8941\n","     15        \u001b[36m0.0669\u001b[0m       \u001b[32m0.9652\u001b[0m        \u001b[35m0.1539\u001b[0m  2.2844\n","     16        \u001b[36m0.0620\u001b[0m       0.9652        \u001b[35m0.1534\u001b[0m  2.2880\n","     17        \u001b[36m0.0577\u001b[0m       0.9648        \u001b[35m0.1533\u001b[0m  2.2568\n","     18        \u001b[36m0.0538\u001b[0m       0.9648        0.1534  2.2560\n","     19        \u001b[36m0.0504\u001b[0m       0.9652        0.1538  3.2149\n","     20        \u001b[36m0.0473\u001b[0m       0.9652        0.1543  2.2603\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.967 total time=  50.2s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.5883\u001b[0m       \u001b[32m0.5204\u001b[0m        \u001b[35m1.8829\u001b[0m  3.1238\n","      2        \u001b[36m1.0678\u001b[0m       \u001b[32m0.7620\u001b[0m        \u001b[35m0.8349\u001b[0m  2.2100\n","      3        \u001b[36m0.4583\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m0.3806\u001b[0m  3.2393\n","      4        \u001b[36m0.2750\u001b[0m       \u001b[32m0.9532\u001b[0m        \u001b[35m0.2664\u001b[0m  2.2929\n","      5        \u001b[36m0.2069\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.2247\u001b[0m  2.2149\n","      6        \u001b[36m0.1731\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.2035\u001b[0m  2.2335\n","      7        \u001b[36m0.1513\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1900\u001b[0m  2.1947\n","      8        \u001b[36m0.1348\u001b[0m       \u001b[32m0.9604\u001b[0m        \u001b[35m0.1800\u001b[0m  2.8741\n","      9        \u001b[36m0.1211\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1721\u001b[0m  2.6266\n","     10        \u001b[36m0.1093\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1656\u001b[0m  2.2137\n","     11        \u001b[36m0.0992\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1605\u001b[0m  2.2567\n","     12        \u001b[36m0.0904\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1566\u001b[0m  2.2443\n","     13        \u001b[36m0.0829\u001b[0m       0.9632        \u001b[35m0.1536\u001b[0m  2.5295\n","     14        \u001b[36m0.0763\u001b[0m       0.9632        \u001b[35m0.1513\u001b[0m  2.9449\n","     15        \u001b[36m0.0706\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1497\u001b[0m  2.2702\n","     16        \u001b[36m0.0655\u001b[0m       0.9640        \u001b[35m0.1485\u001b[0m  2.2445\n","     17        \u001b[36m0.0610\u001b[0m       0.9640        \u001b[35m0.1477\u001b[0m  2.2567\n","     18        \u001b[36m0.0570\u001b[0m       0.9632        \u001b[35m0.1473\u001b[0m  2.2310\n","     19        \u001b[36m0.0535\u001b[0m       0.9636        \u001b[35m0.1470\u001b[0m  3.2568\n","     20        \u001b[36m0.0503\u001b[0m       0.9636        \u001b[35m0.1470\u001b[0m  2.2082\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.965 total time=  50.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.5668\u001b[0m       \u001b[32m0.6468\u001b[0m        \u001b[35m1.6215\u001b[0m  2.2289\n","      2        \u001b[36m0.9904\u001b[0m       \u001b[32m0.8284\u001b[0m        \u001b[35m0.6552\u001b[0m  2.2765\n","      3        \u001b[36m0.4578\u001b[0m       \u001b[32m0.9428\u001b[0m        \u001b[35m0.3726\u001b[0m  2.5096\n","      4        \u001b[36m0.2904\u001b[0m       \u001b[32m0.9496\u001b[0m        \u001b[35m0.2717\u001b[0m  3.0066\n","      5        \u001b[36m0.2210\u001b[0m       \u001b[32m0.9532\u001b[0m        \u001b[35m0.2283\u001b[0m  2.2219\n","      6        \u001b[36m0.1839\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.2046\u001b[0m  2.2526\n","      7        \u001b[36m0.1592\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1890\u001b[0m  2.2307\n","      8        \u001b[36m0.1401\u001b[0m       \u001b[32m0.9604\u001b[0m        \u001b[35m0.1772\u001b[0m  2.2122\n","      9        \u001b[36m0.1246\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1680\u001b[0m  3.2983\n","     10        \u001b[36m0.1116\u001b[0m       0.9608        \u001b[35m0.1607\u001b[0m  2.2125\n","     11        \u001b[36m0.1009\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1552\u001b[0m  2.2023\n","     12        \u001b[36m0.0918\u001b[0m       0.9612        \u001b[35m0.1512\u001b[0m  2.2410\n","     13        \u001b[36m0.0841\u001b[0m       0.9612        \u001b[35m0.1483\u001b[0m  2.2421\n","     14        \u001b[36m0.0775\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1462\u001b[0m  3.1607\n","     15        \u001b[36m0.0716\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1449\u001b[0m  2.3109\n","     16        \u001b[36m0.0664\u001b[0m       0.9632        \u001b[35m0.1441\u001b[0m  2.2222\n","     17        \u001b[36m0.0617\u001b[0m       0.9632        \u001b[35m0.1436\u001b[0m  2.2033\n","     18        \u001b[36m0.0576\u001b[0m       0.9624        \u001b[35m0.1434\u001b[0m  2.1666\n","     19        \u001b[36m0.0538\u001b[0m       0.9624        0.1435  2.7516\n","     20        \u001b[36m0.0504\u001b[0m       0.9620        0.1437  2.8098\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.970 total time=  49.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.3308\u001b[0m       \u001b[32m0.3104\u001b[0m        \u001b[35m2.1712\u001b[0m  2.5863\n","      2        \u001b[36m2.3195\u001b[0m       \u001b[32m0.3128\u001b[0m        2.4484  2.6280\n","      3        \u001b[36m2.2097\u001b[0m       \u001b[32m0.3168\u001b[0m        \u001b[35m2.1704\u001b[0m  2.6706\n","      4        \u001b[36m2.1683\u001b[0m       0.2780        2.3573  3.3893\n","      5        2.3061       0.2772        2.2729  2.5233\n","      6        2.2720       0.2776        2.2693  2.5878\n","      7        2.2691       0.2776        2.2693  2.6023\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.276 total time=  23.6s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9478\u001b[0m       \u001b[32m0.3420\u001b[0m        \u001b[35m2.0436\u001b[0m  2.6658\n","      2        \u001b[36m2.0269\u001b[0m       \u001b[32m0.3428\u001b[0m        \u001b[35m2.0363\u001b[0m  2.6382\n","      3        \u001b[36m2.0066\u001b[0m       \u001b[32m0.3512\u001b[0m        \u001b[35m1.9926\u001b[0m  2.6883\n","      4        \u001b[36m2.0021\u001b[0m       \u001b[32m0.3516\u001b[0m        2.0022  3.2127\n","      5        2.0355       0.3512        \u001b[35m1.9896\u001b[0m  2.9348\n","      6        \u001b[36m1.9945\u001b[0m       0.3512        1.9913  2.6622\n","      7        2.0003       0.3500        1.9948  2.6297\n","      8        2.1257       0.3476        2.0154  2.6571\n","      9        2.1797       0.3500        2.0010  3.7757\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.299 total time=  30.6s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.7565\u001b[0m       \u001b[32m0.4160\u001b[0m        \u001b[35m1.7819\u001b[0m  2.5896\n","      2        \u001b[36m1.8298\u001b[0m       0.3892        1.8751  3.0292\n","      3        1.9557       0.3472        2.0261  3.1836\n","      4        2.0269       0.3476        2.0171  2.6238\n","      5        2.0115       0.3504        1.9994  2.6051\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.353 total time=  17.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8184\u001b[0m       \u001b[32m0.4108\u001b[0m        \u001b[35m2.2250\u001b[0m  2.4531\n","      2        \u001b[36m1.5142\u001b[0m       \u001b[32m0.6564\u001b[0m        \u001b[35m1.0987\u001b[0m  1.6373\n","      3        \u001b[36m0.6590\u001b[0m       \u001b[32m0.9056\u001b[0m        \u001b[35m0.5032\u001b[0m  1.6687\n","      4        \u001b[36m0.3514\u001b[0m       \u001b[32m0.9416\u001b[0m        \u001b[35m0.3126\u001b[0m  1.6473\n","      5        \u001b[36m0.2460\u001b[0m       \u001b[32m0.9468\u001b[0m        \u001b[35m0.2457\u001b[0m  1.6563\n","      6        \u001b[36m0.1983\u001b[0m       \u001b[32m0.9500\u001b[0m        \u001b[35m0.2137\u001b[0m  1.6525\n","      7        \u001b[36m0.1702\u001b[0m       \u001b[32m0.9520\u001b[0m        \u001b[35m0.1947\u001b[0m  1.7867\n","      8        \u001b[36m0.1502\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.1815\u001b[0m  2.5421\n","      9        \u001b[36m0.1342\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1714\u001b[0m  1.6476\n","     10        \u001b[36m0.1206\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1633\u001b[0m  1.6127\n","     11        \u001b[36m0.1087\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1567\u001b[0m  1.6638\n","     12        \u001b[36m0.0985\u001b[0m       \u001b[32m0.9652\u001b[0m        \u001b[35m0.1516\u001b[0m  1.6453\n","     13        \u001b[36m0.0897\u001b[0m       \u001b[32m0.9664\u001b[0m        \u001b[35m0.1477\u001b[0m  1.6472\n","     14        \u001b[36m0.0821\u001b[0m       \u001b[32m0.9676\u001b[0m        \u001b[35m0.1447\u001b[0m  1.7089\n","     15        \u001b[36m0.0756\u001b[0m       0.9672        \u001b[35m0.1427\u001b[0m  2.5827\n","     16        \u001b[36m0.0699\u001b[0m       0.9676        \u001b[35m0.1413\u001b[0m  1.6147\n","     17        \u001b[36m0.0648\u001b[0m       0.9676        \u001b[35m0.1403\u001b[0m  1.6456\n","     18        \u001b[36m0.0604\u001b[0m       0.9676        \u001b[35m0.1398\u001b[0m  1.6572\n","     19        \u001b[36m0.0564\u001b[0m       0.9676        \u001b[35m0.1397\u001b[0m  1.6486\n","     20        \u001b[36m0.0529\u001b[0m       0.9676        0.1399  1.6152\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.967 total time=  36.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8385\u001b[0m       \u001b[32m0.4548\u001b[0m        \u001b[35m2.3136\u001b[0m  2.0517\n","      2        \u001b[36m1.4503\u001b[0m       \u001b[32m0.6872\u001b[0m        \u001b[35m1.0068\u001b[0m  2.2280\n","      3        \u001b[36m0.6093\u001b[0m       \u001b[32m0.8888\u001b[0m        \u001b[35m0.4913\u001b[0m  1.6494\n","      4        \u001b[36m0.3425\u001b[0m       \u001b[32m0.9316\u001b[0m        \u001b[35m0.3164\u001b[0m  1.6197\n","      5        \u001b[36m0.2405\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m0.2532\u001b[0m  1.6221\n","      6        \u001b[36m0.1937\u001b[0m       \u001b[32m0.9544\u001b[0m        \u001b[35m0.2236\u001b[0m  1.5897\n","      7        \u001b[36m0.1664\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.2063\u001b[0m  1.6010\n","      8        \u001b[36m0.1471\u001b[0m       \u001b[32m0.9584\u001b[0m        \u001b[35m0.1942\u001b[0m  1.8974\n","      9        \u001b[36m0.1317\u001b[0m       \u001b[32m0.9596\u001b[0m        \u001b[35m0.1848\u001b[0m  2.3881\n","     10        \u001b[36m0.1184\u001b[0m       0.9596        \u001b[35m0.1768\u001b[0m  1.6816\n","     11        \u001b[36m0.1066\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1702\u001b[0m  1.6098\n","     12        \u001b[36m0.0964\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1650\u001b[0m  1.6772\n","     13        \u001b[36m0.0876\u001b[0m       0.9612        \u001b[35m0.1609\u001b[0m  1.6142\n","     14        \u001b[36m0.0800\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1578\u001b[0m  1.6339\n","     15        \u001b[36m0.0735\u001b[0m       0.9616        \u001b[35m0.1556\u001b[0m  1.7654\n","     16        \u001b[36m0.0679\u001b[0m       0.9616        \u001b[35m0.1540\u001b[0m  2.5440\n","     17        \u001b[36m0.0630\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1529\u001b[0m  1.6505\n","     18        \u001b[36m0.0587\u001b[0m       0.9616        \u001b[35m0.1522\u001b[0m  1.6990\n","     19        \u001b[36m0.0549\u001b[0m       0.9616        \u001b[35m0.1519\u001b[0m  1.6839\n","     20        \u001b[36m0.0514\u001b[0m       0.9616        \u001b[35m0.1518\u001b[0m  1.6457\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.965 total time=  36.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7262\u001b[0m       \u001b[32m0.5768\u001b[0m        \u001b[35m2.0442\u001b[0m  1.6192\n","      2        \u001b[36m1.3785\u001b[0m       \u001b[32m0.7560\u001b[0m        \u001b[35m0.8923\u001b[0m  2.3353\n","      3        \u001b[36m0.6151\u001b[0m       \u001b[32m0.9264\u001b[0m        \u001b[35m0.4729\u001b[0m  1.9925\n","      4        \u001b[36m0.3585\u001b[0m       \u001b[32m0.9488\u001b[0m        \u001b[35m0.3121\u001b[0m  1.6852\n","      5        \u001b[36m0.2567\u001b[0m       \u001b[32m0.9524\u001b[0m        \u001b[35m0.2476\u001b[0m  2.6305\n","      6        \u001b[36m0.2066\u001b[0m       \u001b[32m0.9564\u001b[0m        \u001b[35m0.2147\u001b[0m  1.6824\n","      7        \u001b[36m0.1760\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1942\u001b[0m  1.6153\n","      8        \u001b[36m0.1539\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1798\u001b[0m  1.8662\n","      9        \u001b[36m0.1364\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1692\u001b[0m  2.4504\n","     10        \u001b[36m0.1221\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1612\u001b[0m  1.6535\n","     11        \u001b[36m0.1101\u001b[0m       \u001b[32m0.9648\u001b[0m        \u001b[35m0.1554\u001b[0m  1.6176\n","     12        \u001b[36m0.1001\u001b[0m       \u001b[32m0.9652\u001b[0m        \u001b[35m0.1513\u001b[0m  1.6687\n","     13        \u001b[36m0.0914\u001b[0m       \u001b[32m0.9656\u001b[0m        \u001b[35m0.1483\u001b[0m  1.6176\n","     14        \u001b[36m0.0839\u001b[0m       0.9656        \u001b[35m0.1463\u001b[0m  1.6228\n","     15        \u001b[36m0.0773\u001b[0m       0.9656        \u001b[35m0.1450\u001b[0m  1.7402\n","     16        \u001b[36m0.0715\u001b[0m       0.9644        \u001b[35m0.1442\u001b[0m  2.5551\n","     17        \u001b[36m0.0662\u001b[0m       0.9640        \u001b[35m0.1438\u001b[0m  1.6478\n","     18        \u001b[36m0.0616\u001b[0m       0.9640        \u001b[35m0.1437\u001b[0m  1.6322\n","     19        \u001b[36m0.0574\u001b[0m       0.9640        0.1439  1.6119\n","     20        \u001b[36m0.0536\u001b[0m       0.9632        0.1443  1.6334\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.971 total time=  37.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.1788\u001b[0m       \u001b[32m0.4692\u001b[0m        \u001b[35m1.6669\u001b[0m  1.7366\n","      2        \u001b[36m1.5385\u001b[0m       \u001b[32m0.4824\u001b[0m        \u001b[35m1.5334\u001b[0m  2.3467\n","      3        \u001b[36m1.5198\u001b[0m       0.4748        \u001b[35m1.5232\u001b[0m  2.2478\n","      4        \u001b[36m1.5060\u001b[0m       \u001b[32m0.4852\u001b[0m        1.5405  1.7956\n","      5        1.5333       0.4224        1.6434  1.7924\n","      6        1.6822       0.4836        1.6393  1.7897\n","      7        1.5375       \u001b[32m0.4860\u001b[0m        1.6201  1.7646\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.485 total time=  16.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.1558\u001b[0m       \u001b[32m0.3896\u001b[0m        \u001b[35m1.8596\u001b[0m  2.2751\n","      2        \u001b[36m1.9053\u001b[0m       \u001b[32m0.3900\u001b[0m        1.8651  1.7412\n","      3        \u001b[36m1.8625\u001b[0m       0.3596        2.2165  1.7817\n","      4        \u001b[36m1.8619\u001b[0m       \u001b[32m0.3924\u001b[0m        \u001b[35m1.8341\u001b[0m  1.8323\n","      5        \u001b[36m1.8353\u001b[0m       0.3912        1.8402  1.8000\n","      6        \u001b[36m1.8343\u001b[0m       0.3920        1.8392  1.8369\n","      7        1.8730       0.3884        1.8675  2.7992\n","      8        1.8458       0.3892        1.8515  1.7670\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.392 total time=  18.5s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.0025\u001b[0m       \u001b[32m0.4552\u001b[0m        \u001b[35m1.5863\u001b[0m  1.8008\n","      2        \u001b[36m1.6438\u001b[0m       \u001b[32m0.4776\u001b[0m        \u001b[35m1.5841\u001b[0m  1.7765\n","      3        \u001b[36m1.6184\u001b[0m       0.4744        1.6526  1.8100\n","      4        \u001b[36m1.5542\u001b[0m       \u001b[32m0.4876\u001b[0m        1.6097  2.7145\n","      5        1.5578       0.4720        \u001b[35m1.5840\u001b[0m  1.8528\n","      6        1.5703       0.4556        1.6020  1.7997\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.455 total time=  14.4s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8733\u001b[0m       \u001b[32m0.3664\u001b[0m        \u001b[35m2.4750\u001b[0m  2.2134\n","      2        \u001b[36m1.4848\u001b[0m       \u001b[32m0.5792\u001b[0m        \u001b[35m1.5078\u001b[0m  2.5997\n","      3        \u001b[36m0.6277\u001b[0m       \u001b[32m0.8220\u001b[0m        \u001b[35m0.6739\u001b[0m  2.8898\n","      4        \u001b[36m0.3510\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m0.3363\u001b[0m  2.1727\n","      5        \u001b[36m0.2436\u001b[0m       \u001b[32m0.9544\u001b[0m        \u001b[35m0.2528\u001b[0m  2.2200\n","      6        \u001b[36m0.1937\u001b[0m       \u001b[32m0.9568\u001b[0m        \u001b[35m0.2179\u001b[0m  2.2163\n","      7        \u001b[36m0.1650\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1986\u001b[0m  2.2162\n","      8        \u001b[36m0.1452\u001b[0m       0.9592        \u001b[35m0.1860\u001b[0m  3.1943\n","      9        \u001b[36m0.1296\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1767\u001b[0m  2.1815\n","     10        \u001b[36m0.1163\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1693\u001b[0m  2.1567\n","     11        \u001b[36m0.1047\u001b[0m       \u001b[32m0.9628\u001b[0m        \u001b[35m0.1634\u001b[0m  2.2015\n","     12        \u001b[36m0.0945\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1588\u001b[0m  2.1806\n","     13        \u001b[36m0.0857\u001b[0m       0.9632        \u001b[35m0.1555\u001b[0m  3.0102\n","     14        \u001b[36m0.0781\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1531\u001b[0m  2.4384\n","     15        \u001b[36m0.0715\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1516\u001b[0m  2.1836\n","     16        \u001b[36m0.0659\u001b[0m       0.9640        \u001b[35m0.1508\u001b[0m  2.1941\n","     17        \u001b[36m0.0609\u001b[0m       0.9644        \u001b[35m0.1504\u001b[0m  2.1807\n","     18        \u001b[36m0.0565\u001b[0m       0.9644        0.1504  2.5799\n","     19        \u001b[36m0.0526\u001b[0m       \u001b[32m0.9648\u001b[0m        0.1507  2.8596\n","     20        \u001b[36m0.0491\u001b[0m       0.9644        0.1513  2.1427\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.966 total time=  49.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8798\u001b[0m       \u001b[32m0.3920\u001b[0m        \u001b[35m2.4821\u001b[0m  2.2167\n","      2        \u001b[36m1.4556\u001b[0m       \u001b[32m0.6300\u001b[0m        \u001b[35m1.3776\u001b[0m  2.2230\n","      3        \u001b[36m0.6182\u001b[0m       \u001b[32m0.9000\u001b[0m        \u001b[35m0.5059\u001b[0m  2.6726\n","      4        \u001b[36m0.3441\u001b[0m       \u001b[32m0.9476\u001b[0m        \u001b[35m0.3195\u001b[0m  2.7255\n","      5        \u001b[36m0.2418\u001b[0m       \u001b[32m0.9524\u001b[0m        \u001b[35m0.2541\u001b[0m  2.1920\n","      6        \u001b[36m0.1933\u001b[0m       \u001b[32m0.9568\u001b[0m        \u001b[35m0.2232\u001b[0m  2.1712\n","      7        \u001b[36m0.1655\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.2059\u001b[0m  2.1769\n","      8        \u001b[36m0.1467\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1947\u001b[0m  2.1864\n","      9        \u001b[36m0.1320\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1864\u001b[0m  3.1788\n","     10        \u001b[36m0.1195\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1795\u001b[0m  2.2096\n","     11        \u001b[36m0.1084\u001b[0m       0.9624        \u001b[35m0.1735\u001b[0m  2.2093\n","     12        \u001b[36m0.0983\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1683\u001b[0m  2.1883\n","     13        \u001b[36m0.0893\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1640\u001b[0m  2.1806\n","     14        \u001b[36m0.0813\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1605\u001b[0m  3.1158\n","     15        \u001b[36m0.0743\u001b[0m       0.9632        \u001b[35m0.1579\u001b[0m  2.2980\n","     16        \u001b[36m0.0683\u001b[0m       0.9632        \u001b[35m0.1560\u001b[0m  2.2449\n","     17        \u001b[36m0.0629\u001b[0m       0.9632        \u001b[35m0.1546\u001b[0m  2.2311\n","     18        \u001b[36m0.0583\u001b[0m       0.9628        \u001b[35m0.1537\u001b[0m  2.1646\n","     19        \u001b[36m0.0542\u001b[0m       0.9628        \u001b[35m0.1531\u001b[0m  2.7064\n","     20        \u001b[36m0.0505\u001b[0m       0.9632        \u001b[35m0.1529\u001b[0m  2.7168\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.965 total time=  49.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8761\u001b[0m       \u001b[32m0.4364\u001b[0m        \u001b[35m2.2607\u001b[0m  2.1972\n","      2        \u001b[36m1.4348\u001b[0m       \u001b[32m0.7736\u001b[0m        \u001b[35m0.9315\u001b[0m  2.1897\n","      3        \u001b[36m0.5981\u001b[0m       \u001b[32m0.9196\u001b[0m        \u001b[35m0.4549\u001b[0m  2.2074\n","      4        \u001b[36m0.3421\u001b[0m       \u001b[32m0.9388\u001b[0m        \u001b[35m0.3061\u001b[0m  2.8689\n","      5        \u001b[36m0.2484\u001b[0m       \u001b[32m0.9444\u001b[0m        \u001b[35m0.2466\u001b[0m  2.5912\n","      6        \u001b[36m0.2022\u001b[0m       \u001b[32m0.9496\u001b[0m        \u001b[35m0.2180\u001b[0m  2.1910\n","      7        \u001b[36m0.1743\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.2012\u001b[0m  2.1664\n","      8        \u001b[36m0.1542\u001b[0m       \u001b[32m0.9568\u001b[0m        \u001b[35m0.1895\u001b[0m  2.2366\n","      9        \u001b[36m0.1380\u001b[0m       \u001b[32m0.9588\u001b[0m        \u001b[35m0.1802\u001b[0m  2.4354\n","     10        \u001b[36m0.1241\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1722\u001b[0m  2.9666\n","     11        \u001b[36m0.1117\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1654\u001b[0m  2.1947\n","     12        \u001b[36m0.1008\u001b[0m       0.9616        \u001b[35m0.1599\u001b[0m  2.1754\n","     13        \u001b[36m0.0912\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1557\u001b[0m  2.2082\n","     14        \u001b[36m0.0828\u001b[0m       0.9624        \u001b[35m0.1526\u001b[0m  2.2413\n","     15        \u001b[36m0.0755\u001b[0m       0.9624        \u001b[35m0.1504\u001b[0m  3.2259\n","     16        \u001b[36m0.0691\u001b[0m       \u001b[32m0.9628\u001b[0m        \u001b[35m0.1490\u001b[0m  2.2019\n","     17        \u001b[36m0.0634\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1481\u001b[0m  2.2506\n","     18        \u001b[36m0.0585\u001b[0m       0.9628        \u001b[35m0.1476\u001b[0m  2.1728\n","     19        \u001b[36m0.0541\u001b[0m       0.9628        \u001b[35m0.1474\u001b[0m  2.2298\n","     20        \u001b[36m0.0502\u001b[0m       0.9624        \u001b[35m0.1474\u001b[0m  2.9617\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.971 total time=  49.3s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m4.7189\u001b[0m       \u001b[32m0.4292\u001b[0m        \u001b[35m1.9409\u001b[0m  2.6240\n","      2        \u001b[36m1.8466\u001b[0m       0.4216        2.0316  2.6408\n","      3        1.9016       0.4188        2.8267  2.7685\n","      4        1.8865       0.3980        3.0821  4.3579\n","      5        1.8988       0.3996        2.8100  2.8829\n","      6        1.8845       0.4072        2.7191  2.6451\n","      7        \u001b[36m1.8179\u001b[0m       0.4088        2.7413  2.6660\n","      8        \u001b[36m1.8160\u001b[0m       0.4048        2.6792  2.7734\n","      9        \u001b[36m1.8051\u001b[0m       0.4052        2.6770  3.5971\n","     10        \u001b[36m1.7999\u001b[0m       0.4088        2.6631  3.8378\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.408 total time=  35.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m6.5950\u001b[0m       \u001b[32m0.4260\u001b[0m        \u001b[35m1.7066\u001b[0m  3.6092\n","      2        \u001b[36m1.7602\u001b[0m       0.3896        2.3177  2.6021\n","      3        1.8362       \u001b[32m0.4348\u001b[0m        1.8199  2.6101\n","      4        2.3854       0.4036        3.1437  2.6430\n","      5        1.9035       0.4108        1.8701  3.3464\n","      6        2.0923       0.4028        2.2724  2.8665\n","      7        1.9858       0.3992        1.8512  2.6512\n","      8        1.8181       0.4064        2.0068  2.6837\n","      9        2.1994       0.3968        2.0326  2.9947\n","     10        1.8571       0.4016        1.8279  4.4812\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.417 total time=  35.6s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m5.5482\u001b[0m       \u001b[32m0.3672\u001b[0m        \u001b[35m1.9916\u001b[0m  2.6382\n","      2        \u001b[36m2.2932\u001b[0m       0.3144        2.1363  3.6117\n","      3        \u001b[36m2.1611\u001b[0m       0.3096        2.1581  2.6555\n","      4        \u001b[36m2.1525\u001b[0m       0.3124        2.1428  2.6733\n","      5        2.2321       0.3144        2.1308  2.6456\n","      6        \u001b[36m2.1337\u001b[0m       0.3152        2.1621  3.4595\n","      7        2.1387       0.3144        2.7839  2.8180\n","      8        2.2808       0.2764        2.2781  2.6646\n","      9        2.2836       0.2764        2.2742  2.8311\n","     10        2.2816       0.2764        2.2742  4.6935\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.275 total time=  35.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9516\u001b[0m       \u001b[32m0.3980\u001b[0m        \u001b[35m2.5870\u001b[0m  1.6337\n","      2        \u001b[36m1.7133\u001b[0m       \u001b[32m0.5352\u001b[0m        \u001b[35m1.5502\u001b[0m  1.6281\n","      3        \u001b[36m0.7610\u001b[0m       \u001b[32m0.7720\u001b[0m        \u001b[35m0.7856\u001b[0m  1.5943\n","      4        \u001b[36m0.3965\u001b[0m       \u001b[32m0.9204\u001b[0m        \u001b[35m0.3619\u001b[0m  2.5817\n","      5        \u001b[36m0.2647\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m0.2650\u001b[0m  1.7015\n","      6        \u001b[36m0.2072\u001b[0m       \u001b[32m0.9500\u001b[0m        \u001b[35m0.2255\u001b[0m  1.6465\n","      7        \u001b[36m0.1748\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.2040\u001b[0m  1.6345\n","      8        \u001b[36m0.1527\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1902\u001b[0m  1.6335\n","      9        \u001b[36m0.1356\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1801\u001b[0m  1.6406\n","     10        \u001b[36m0.1212\u001b[0m       0.9628        \u001b[35m0.1723\u001b[0m  1.6383\n","     11        \u001b[36m0.1090\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1661\u001b[0m  2.4065\n","     12        \u001b[36m0.0984\u001b[0m       \u001b[32m0.9652\u001b[0m        \u001b[35m0.1615\u001b[0m  1.8538\n","     13        \u001b[36m0.0894\u001b[0m       \u001b[32m0.9664\u001b[0m        \u001b[35m0.1580\u001b[0m  1.6511\n","     14        \u001b[36m0.0816\u001b[0m       \u001b[32m0.9668\u001b[0m        \u001b[35m0.1557\u001b[0m  1.6037\n","     15        \u001b[36m0.0748\u001b[0m       \u001b[32m0.9676\u001b[0m        \u001b[35m0.1541\u001b[0m  1.6215\n","     16        \u001b[36m0.0689\u001b[0m       0.9676        \u001b[35m0.1533\u001b[0m  1.6236\n","     17        \u001b[36m0.0637\u001b[0m       0.9676        \u001b[35m0.1530\u001b[0m  1.6380\n","     18        \u001b[36m0.0591\u001b[0m       0.9676        0.1531  2.2685\n","     19        \u001b[36m0.0551\u001b[0m       0.9676        0.1536  2.0401\n","     20        \u001b[36m0.0515\u001b[0m       0.9668        0.1544  1.6442\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.965 total time=  36.6s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9590\u001b[0m       \u001b[32m0.3556\u001b[0m        \u001b[35m2.5919\u001b[0m  1.6124\n","      2        \u001b[36m1.7195\u001b[0m       \u001b[32m0.5436\u001b[0m        \u001b[35m1.5575\u001b[0m  1.6090\n","      3        \u001b[36m0.7123\u001b[0m       \u001b[32m0.7636\u001b[0m        \u001b[35m0.7873\u001b[0m  1.6390\n","      4        \u001b[36m0.3826\u001b[0m       \u001b[32m0.9180\u001b[0m        \u001b[35m0.3605\u001b[0m  1.6185\n","      5        \u001b[36m0.2535\u001b[0m       \u001b[32m0.9432\u001b[0m        \u001b[35m0.2688\u001b[0m  2.5249\n","      6        \u001b[36m0.1990\u001b[0m       \u001b[32m0.9476\u001b[0m        \u001b[35m0.2332\u001b[0m  1.7061\n","      7        \u001b[36m0.1691\u001b[0m       0.9444        \u001b[35m0.2138\u001b[0m  1.6178\n","      8        \u001b[36m0.1489\u001b[0m       0.9468        \u001b[35m0.2012\u001b[0m  1.6006\n","      9        \u001b[36m0.1332\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.1918\u001b[0m  1.6412\n","     10        \u001b[36m0.1199\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.1841\u001b[0m  1.5971\n","     11        \u001b[36m0.1080\u001b[0m       \u001b[32m0.9604\u001b[0m        \u001b[35m0.1774\u001b[0m  1.6414\n","     12        \u001b[36m0.0974\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1718\u001b[0m  2.3119\n","     13        \u001b[36m0.0881\u001b[0m       0.9608        \u001b[35m0.1673\u001b[0m  1.9592\n","     14        \u001b[36m0.0800\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1639\u001b[0m  1.6726\n","     15        \u001b[36m0.0731\u001b[0m       0.9608        \u001b[35m0.1614\u001b[0m  1.6697\n","     16        \u001b[36m0.0672\u001b[0m       0.9604        \u001b[35m0.1597\u001b[0m  1.6188\n","     17        \u001b[36m0.0620\u001b[0m       0.9604        \u001b[35m0.1586\u001b[0m  1.6627\n","     18        \u001b[36m0.0575\u001b[0m       0.9604        \u001b[35m0.1580\u001b[0m  1.6388\n","     19        \u001b[36m0.0536\u001b[0m       0.9600        \u001b[35m0.1577\u001b[0m  2.2513\n","     20        \u001b[36m0.0502\u001b[0m       0.9600        0.1577  2.0876\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.963 total time=  36.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9509\u001b[0m       \u001b[32m0.4260\u001b[0m        \u001b[35m2.5049\u001b[0m  1.6552\n","      2        \u001b[36m1.6965\u001b[0m       \u001b[32m0.6384\u001b[0m        \u001b[35m1.1496\u001b[0m  1.6346\n","      3        \u001b[36m0.7388\u001b[0m       \u001b[32m0.8708\u001b[0m        \u001b[35m0.5389\u001b[0m  1.6281\n","      4        \u001b[36m0.3871\u001b[0m       \u001b[32m0.9248\u001b[0m        \u001b[35m0.3341\u001b[0m  1.6202\n","      5        \u001b[36m0.2652\u001b[0m       \u001b[32m0.9356\u001b[0m        \u001b[35m0.2590\u001b[0m  1.6881\n","      6        \u001b[36m0.2122\u001b[0m       \u001b[32m0.9472\u001b[0m        \u001b[35m0.2248\u001b[0m  2.5873\n","      7        \u001b[36m0.1815\u001b[0m       \u001b[32m0.9524\u001b[0m        \u001b[35m0.2052\u001b[0m  1.6626\n","      8        \u001b[36m0.1594\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.1916\u001b[0m  1.6399\n","      9        \u001b[36m0.1416\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.1811\u001b[0m  1.6478\n","     10        \u001b[36m0.1263\u001b[0m       \u001b[32m0.9580\u001b[0m        \u001b[35m0.1727\u001b[0m  1.6015\n","     11        \u001b[36m0.1131\u001b[0m       \u001b[32m0.9588\u001b[0m        \u001b[35m0.1660\u001b[0m  1.6442\n","     12        \u001b[36m0.1018\u001b[0m       0.9588        \u001b[35m0.1610\u001b[0m  1.6446\n","     13        \u001b[36m0.0921\u001b[0m       \u001b[32m0.9596\u001b[0m        \u001b[35m0.1573\u001b[0m  2.5561\n","     14        \u001b[36m0.0838\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1547\u001b[0m  1.7738\n","     15        \u001b[36m0.0767\u001b[0m       \u001b[32m0.9604\u001b[0m        \u001b[35m0.1531\u001b[0m  1.6090\n","     16        \u001b[36m0.0704\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1521\u001b[0m  1.6590\n","     17        \u001b[36m0.0649\u001b[0m       0.9608        \u001b[35m0.1516\u001b[0m  1.6333\n","     18        \u001b[36m0.0601\u001b[0m       0.9612        \u001b[35m0.1515\u001b[0m  1.6365\n","     19        \u001b[36m0.0557\u001b[0m       \u001b[32m0.9616\u001b[0m        0.1516  1.6978\n","     20        \u001b[36m0.0519\u001b[0m       0.9616        0.1518  2.4809\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.971 total time=  36.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6966\u001b[0m       \u001b[32m0.5188\u001b[0m        \u001b[35m1.6473\u001b[0m  1.7683\n","      2        \u001b[36m1.6097\u001b[0m       0.5100        1.8255  1.7496\n","      3        \u001b[36m1.4692\u001b[0m       0.5128        1.7220  1.7692\n","      4        \u001b[36m1.3972\u001b[0m       0.5172        1.7099  1.7988\n","      5        1.5442       0.4764        1.8535  1.8096\n","      6        1.5454       0.4812        1.8997  2.4205\n","      7        1.6688       0.4252        2.3369  2.0979\n","      8        1.9130       0.4152        1.8104  1.7612\n","      9        2.3028       0.4020        9.8129  1.8333\n","     10        2.7820       0.3672        2.1302  1.9967\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.363 total time=  22.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.6339\u001b[0m       \u001b[32m0.4816\u001b[0m        \u001b[35m1.6701\u001b[0m  2.6211\n","      2        \u001b[36m1.5949\u001b[0m       0.4600        1.7743  1.9442\n","      3        1.6176       \u001b[32m0.4836\u001b[0m        1.9193  2.3099\n","      4        \u001b[36m1.5875\u001b[0m       0.4732        2.1298  2.2930\n","      5        1.7705       0.4496        \u001b[35m1.6640\u001b[0m  1.8117\n","      6        1.6512       0.4688        \u001b[35m1.6162\u001b[0m  1.7884\n","      7        1.6385       0.4644        1.6961  2.6385\n","      8        1.8556       0.4688        2.2183  1.9251\n","      9        2.2514       0.4744        \u001b[35m1.5706\u001b[0m  1.7908\n","     10        2.2083       0.4796        1.5759  2.0515\n","     11        \u001b[36m1.5358\u001b[0m       0.4828        1.6651  2.1468\n","     12        1.5541       0.4820        1.8717  2.0685\n","     13        1.6348       0.4836        2.4553  2.8750\n","     14        1.6974       \u001b[32m0.4840\u001b[0m        1.6639  2.0653\n","     15        1.5718       0.4492        1.6614  2.1042\n","     16        1.6127       0.4600        1.6187  2.0235\n","     17        1.5953       0.4620        1.5877  2.0267\n","     18        1.5693       0.4728        1.5792  2.0835\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.484 total time=  42.4s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.4262\u001b[0m       \u001b[32m0.6044\u001b[0m        \u001b[35m1.0389\u001b[0m  1.7642\n","      2        \u001b[36m1.0593\u001b[0m       \u001b[32m0.6184\u001b[0m        \u001b[35m1.0276\u001b[0m  1.8009\n","      3        \u001b[36m1.0537\u001b[0m       \u001b[32m0.6312\u001b[0m        1.0388  1.7801\n","      4        1.1309       0.6128        \u001b[35m0.9922\u001b[0m  1.8002\n","      5        1.3014       0.6012        1.1126  1.8403\n","      6        1.0847       0.6160        1.1532  2.7152\n","      7        1.0569       0.6204        1.0300  1.7427\n","      8        \u001b[36m0.9745\u001b[0m       0.6156        1.2182  1.7971\n","      9        0.9942       0.6176        1.1536  1.8280\n","     10        1.0552       0.6200        1.0943  2.1219\n","     11        1.0471       0.6156        1.0141  2.1866\n","     12        0.9786       0.6172        \u001b[35m0.9689\u001b[0m  3.0017\n","     13        1.0215       0.6200        \u001b[35m0.9439\u001b[0m  2.0243\n","     14        1.5821       0.5976        1.1422  2.0386\n","     15        1.0890       0.5928        1.0680  2.0627\n","     16        1.0137       0.5964        1.0714  2.0671\n","     17        1.0256       0.5712        1.1050  2.3018\n","     18        \u001b[36m0.9531\u001b[0m       0.6212        1.0470  2.7137\n","     19        1.0261       0.5892        1.0698  2.0644\n","     20        0.9834       0.5828        1.0819  2.0609\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.588 total time=  42.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6000\u001b[0m       \u001b[32m0.5260\u001b[0m        \u001b[35m1.8348\u001b[0m  2.2050\n","      2        \u001b[36m1.0680\u001b[0m       \u001b[32m0.7540\u001b[0m        \u001b[35m0.8119\u001b[0m  2.2696\n","      3        \u001b[36m0.4818\u001b[0m       \u001b[32m0.9392\u001b[0m        \u001b[35m0.4048\u001b[0m  3.1941\n","      4        \u001b[36m0.2993\u001b[0m       \u001b[32m0.9512\u001b[0m        \u001b[35m0.2834\u001b[0m  2.1946\n","      5        \u001b[36m0.2200\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.2303\u001b[0m  2.2188\n","      6        \u001b[36m0.1776\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.2016\u001b[0m  2.2534\n","      7        \u001b[36m0.1510\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1837\u001b[0m  2.2482\n","      8        \u001b[36m0.1318\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1715\u001b[0m  3.3208\n","      9        \u001b[36m0.1169\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1628\u001b[0m  2.3216\n","     10        \u001b[36m0.1050\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1568\u001b[0m  2.2267\n","     11        \u001b[36m0.0952\u001b[0m       0.9636        \u001b[35m0.1524\u001b[0m  2.2395\n","     12        \u001b[36m0.0869\u001b[0m       0.9640        \u001b[35m0.1494\u001b[0m  2.2329\n","     13        \u001b[36m0.0798\u001b[0m       0.9640        \u001b[35m0.1473\u001b[0m  3.0691\n","     14        \u001b[36m0.0735\u001b[0m       \u001b[32m0.9648\u001b[0m        \u001b[35m0.1458\u001b[0m  2.4548\n","     15        \u001b[36m0.0679\u001b[0m       \u001b[32m0.9668\u001b[0m        \u001b[35m0.1449\u001b[0m  2.2729\n","     16        \u001b[36m0.0629\u001b[0m       \u001b[32m0.9676\u001b[0m        \u001b[35m0.1444\u001b[0m  2.2696\n","     17        \u001b[36m0.0584\u001b[0m       0.9676        \u001b[35m0.1444\u001b[0m  2.2811\n","     18        \u001b[36m0.0544\u001b[0m       \u001b[32m0.9680\u001b[0m        0.1445  2.8252\n","     19        \u001b[36m0.0509\u001b[0m       0.9680        0.1449  2.7012\n","     20        \u001b[36m0.0477\u001b[0m       0.9680        0.1455  2.2756\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.968 total time=  50.2s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.5687\u001b[0m       \u001b[32m0.4888\u001b[0m        \u001b[35m1.8106\u001b[0m  2.2593\n","      2        \u001b[36m1.0502\u001b[0m       \u001b[32m0.7376\u001b[0m        \u001b[35m0.8830\u001b[0m  2.2353\n","      3        \u001b[36m0.4808\u001b[0m       \u001b[32m0.9188\u001b[0m        \u001b[35m0.3974\u001b[0m  3.1398\n","      4        \u001b[36m0.2831\u001b[0m       \u001b[32m0.9432\u001b[0m        \u001b[35m0.2712\u001b[0m  2.3669\n","      5        \u001b[36m0.2091\u001b[0m       \u001b[32m0.9488\u001b[0m        \u001b[35m0.2253\u001b[0m  2.2528\n","      6        \u001b[36m0.1732\u001b[0m       \u001b[32m0.9576\u001b[0m        \u001b[35m0.2026\u001b[0m  2.2882\n","      7        \u001b[36m0.1505\u001b[0m       \u001b[32m0.9604\u001b[0m        \u001b[35m0.1884\u001b[0m  2.2944\n","      8        \u001b[36m0.1336\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1781\u001b[0m  2.9596\n","      9        \u001b[36m0.1196\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1699\u001b[0m  2.6041\n","     10        \u001b[36m0.1078\u001b[0m       \u001b[32m0.9628\u001b[0m        \u001b[35m0.1634\u001b[0m  2.2698\n","     11        \u001b[36m0.0976\u001b[0m       0.9628        \u001b[35m0.1583\u001b[0m  2.2446\n","     12        \u001b[36m0.0889\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1545\u001b[0m  2.2556\n","     13        \u001b[36m0.0815\u001b[0m       0.9632        \u001b[35m0.1517\u001b[0m  2.6932\n","     14        \u001b[36m0.0750\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1497\u001b[0m  2.8854\n","     15        \u001b[36m0.0694\u001b[0m       \u001b[32m0.9648\u001b[0m        \u001b[35m0.1483\u001b[0m  2.2777\n","     16        \u001b[36m0.0645\u001b[0m       \u001b[32m0.9652\u001b[0m        \u001b[35m0.1475\u001b[0m  2.2571\n","     17        \u001b[36m0.0601\u001b[0m       0.9648        \u001b[35m0.1470\u001b[0m  2.3056\n","     18        \u001b[36m0.0562\u001b[0m       \u001b[32m0.9656\u001b[0m        \u001b[35m0.1468\u001b[0m  2.5257\n","     19        \u001b[36m0.0527\u001b[0m       0.9656        0.1468  3.1093\n","     20        \u001b[36m0.0496\u001b[0m       0.9648        0.1471  2.2755\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.965 total time=  50.6s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6146\u001b[0m       \u001b[32m0.6472\u001b[0m        \u001b[35m1.7742\u001b[0m  2.3008\n","      2        \u001b[36m1.0891\u001b[0m       \u001b[32m0.8544\u001b[0m        \u001b[35m0.7063\u001b[0m  2.2838\n","      3        \u001b[36m0.4840\u001b[0m       \u001b[32m0.9368\u001b[0m        \u001b[35m0.3778\u001b[0m  2.9332\n","      4        \u001b[36m0.2974\u001b[0m       \u001b[32m0.9492\u001b[0m        \u001b[35m0.2709\u001b[0m  2.8062\n","      5        \u001b[36m0.2241\u001b[0m       \u001b[32m0.9520\u001b[0m        \u001b[35m0.2271\u001b[0m  5.1503\n","      6        \u001b[36m0.1863\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.2034\u001b[0m  2.2847\n","      7        \u001b[36m0.1616\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1878\u001b[0m  3.1195\n","      8        \u001b[36m0.1428\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1761\u001b[0m  2.4264\n","      9        \u001b[36m0.1273\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1668\u001b[0m  2.2642\n","     10        \u001b[36m0.1142\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1593\u001b[0m  2.2847\n","     11        \u001b[36m0.1030\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1535\u001b[0m  2.3021\n","     12        \u001b[36m0.0935\u001b[0m       0.9640        \u001b[35m0.1490\u001b[0m  2.9532\n","     13        \u001b[36m0.0853\u001b[0m       \u001b[32m0.9656\u001b[0m        \u001b[35m0.1458\u001b[0m  2.6178\n","     14        \u001b[36m0.0782\u001b[0m       0.9652        \u001b[35m0.1434\u001b[0m  3.3083\n","     15        \u001b[36m0.0720\u001b[0m       0.9652        \u001b[35m0.1417\u001b[0m  2.2991\n","     16        \u001b[36m0.0666\u001b[0m       0.9648        \u001b[35m0.1404\u001b[0m  2.2844\n","     17        \u001b[36m0.0617\u001b[0m       0.9656        \u001b[35m0.1395\u001b[0m  3.2975\n","     18        \u001b[36m0.0574\u001b[0m       0.9648        \u001b[35m0.1389\u001b[0m  2.2654\n","     19        \u001b[36m0.0536\u001b[0m       0.9652        \u001b[35m0.1386\u001b[0m  2.2482\n","     20        \u001b[36m0.0502\u001b[0m       0.9648        \u001b[35m0.1385\u001b[0m  2.2358\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.970 total time=  54.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.8522\u001b[0m       \u001b[32m0.2624\u001b[0m        \u001b[35m2.6633\u001b[0m  3.0385\n","      2        \u001b[36m2.2742\u001b[0m       \u001b[32m0.3056\u001b[0m        \u001b[35m2.2057\u001b[0m  3.2688\n","      3        2.4205       0.2340        3.2584  2.6460\n","      4        2.3430       0.2736        2.3001  2.7045\n","      5        2.2861       0.2760        2.2960  2.6279\n","      6        \u001b[36m2.2739\u001b[0m       0.2764        2.2785  3.5901\n","      7        2.2777       0.2764        2.2828  2.6236\n","      8        2.2778       0.2768        2.2931  2.6555\n","      9        2.2854       0.2772        2.2875  2.8507\n","     10        2.2746       0.2772        2.3410  4.5504\n","     11        \u001b[36m2.2723\u001b[0m       0.2772        2.3792  4.0028\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.276 total time=  39.5s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8780\u001b[0m       \u001b[32m0.3796\u001b[0m        \u001b[35m1.9159\u001b[0m  3.6528\n","      2        \u001b[36m1.8939\u001b[0m       \u001b[32m0.3868\u001b[0m        \u001b[35m1.8864\u001b[0m  2.6869\n","      3        1.9204       \u001b[32m0.3888\u001b[0m        \u001b[35m1.8579\u001b[0m  2.6900\n","      4        2.0272       0.3520        2.0056  2.6860\n","      5        1.9801       0.3520        1.9893  3.0312\n","      6        2.0092       0.3512        1.9953  3.2062\n","      7        1.9866       0.3524        1.9957  2.6602\n","      8        1.9981       0.3488        2.0099  2.6176\n","      9        2.1114       0.3124        2.1413  2.7705\n","     10        2.6403       0.2716        2.3095  4.4369\n","     11        2.4441       0.2652        2.3462  3.7344\n","     12        2.3566       0.2720        2.3017  3.5316\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.275 total time=  43.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9838\u001b[0m       \u001b[32m0.3864\u001b[0m        \u001b[35m1.8754\u001b[0m  2.6760\n","      2        \u001b[36m1.8890\u001b[0m       \u001b[32m0.3904\u001b[0m        \u001b[35m1.8526\u001b[0m  2.7012\n","      3        \u001b[36m1.8587\u001b[0m       0.3904        \u001b[35m1.8519\u001b[0m  2.6855\n","      4        1.9083       0.3512        2.0395  3.6291\n","      5        1.9882       0.3524        1.9914  2.6362\n","      6        1.9829       0.3524        1.9909  2.6805\n","      7        1.9815       0.3524        1.9908  2.6243\n","      8        1.9816       0.3524        1.9908  3.0804\n","      9        1.9817       0.3524        1.9907  3.3301\n","     10        1.9820       0.3524        1.9908  3.9089\n","     11        1.9822       0.3524        1.9908  4.0749\n","     12        1.9826       0.3524        1.9908  4.6184\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.354 total time=  43.6s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7811\u001b[0m       \u001b[32m0.4692\u001b[0m        \u001b[35m2.1379\u001b[0m  1.7039\n","      2        \u001b[36m1.3744\u001b[0m       \u001b[32m0.6912\u001b[0m        \u001b[35m1.0125\u001b[0m  1.6814\n","      3        \u001b[36m0.6285\u001b[0m       \u001b[32m0.8788\u001b[0m        \u001b[35m0.5102\u001b[0m  2.6244\n","      4        \u001b[36m0.3568\u001b[0m       \u001b[32m0.9312\u001b[0m        \u001b[35m0.3214\u001b[0m  1.6598\n","      5        \u001b[36m0.2485\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.2542\u001b[0m  1.6469\n","      6        \u001b[36m0.1986\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.2228\u001b[0m  1.6390\n","      7        \u001b[36m0.1697\u001b[0m       \u001b[32m0.9596\u001b[0m        \u001b[35m0.2045\u001b[0m  1.6535\n","      8        \u001b[36m0.1495\u001b[0m       \u001b[32m0.9604\u001b[0m        \u001b[35m0.1920\u001b[0m  1.6556\n","      9        \u001b[36m0.1336\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1823\u001b[0m  1.6682\n","     10        \u001b[36m0.1201\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1744\u001b[0m  2.5736\n","     11        \u001b[36m0.1084\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1679\u001b[0m  1.7815\n","     12        \u001b[36m0.0982\u001b[0m       \u001b[32m0.9652\u001b[0m        \u001b[35m0.1627\u001b[0m  1.6146\n","     13        \u001b[36m0.0895\u001b[0m       \u001b[32m0.9656\u001b[0m        \u001b[35m0.1587\u001b[0m  1.6416\n","     14        \u001b[36m0.0819\u001b[0m       \u001b[32m0.9660\u001b[0m        \u001b[35m0.1558\u001b[0m  1.6833\n","     15        \u001b[36m0.0753\u001b[0m       \u001b[32m0.9668\u001b[0m        \u001b[35m0.1538\u001b[0m  1.6243\n","     16        \u001b[36m0.0695\u001b[0m       0.9664        \u001b[35m0.1524\u001b[0m  1.6554\n","     17        \u001b[36m0.0644\u001b[0m       0.9664        \u001b[35m0.1516\u001b[0m  2.4900\n","     18        \u001b[36m0.0598\u001b[0m       0.9660        \u001b[35m0.1512\u001b[0m  1.8049\n","     19        \u001b[36m0.0557\u001b[0m       0.9664        \u001b[35m0.1512\u001b[0m  1.6167\n","     20        \u001b[36m0.0520\u001b[0m       0.9660        0.1515  1.6357\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.968 total time=  37.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7654\u001b[0m       \u001b[32m0.4408\u001b[0m        \u001b[35m2.1658\u001b[0m  1.6795\n","      2        \u001b[36m1.4693\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m1.0682\u001b[0m  1.6550\n","      3        \u001b[36m0.6540\u001b[0m       \u001b[32m0.8980\u001b[0m        \u001b[35m0.5096\u001b[0m  1.9448\n","      4        \u001b[36m0.3503\u001b[0m       \u001b[32m0.9392\u001b[0m        \u001b[35m0.3150\u001b[0m  2.3583\n","      5        \u001b[36m0.2406\u001b[0m       \u001b[32m0.9504\u001b[0m        \u001b[35m0.2490\u001b[0m  1.6229\n","      6        \u001b[36m0.1923\u001b[0m       \u001b[32m0.9528\u001b[0m        \u001b[35m0.2190\u001b[0m  1.6077\n","      7        \u001b[36m0.1646\u001b[0m       \u001b[32m0.9552\u001b[0m        \u001b[35m0.2016\u001b[0m  1.6364\n","      8        \u001b[36m0.1451\u001b[0m       \u001b[32m0.9580\u001b[0m        \u001b[35m0.1897\u001b[0m  1.6553\n","      9        \u001b[36m0.1295\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1805\u001b[0m  1.6508\n","     10        \u001b[36m0.1163\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1732\u001b[0m  1.8048\n","     11        \u001b[36m0.1051\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1675\u001b[0m  2.5136\n","     12        \u001b[36m0.0956\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1632\u001b[0m  1.6362\n","     13        \u001b[36m0.0875\u001b[0m       0.9620        \u001b[35m0.1599\u001b[0m  1.6710\n","     14        \u001b[36m0.0805\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1576\u001b[0m  1.6549\n","     15        \u001b[36m0.0745\u001b[0m       0.9624        \u001b[35m0.1559\u001b[0m  1.6337\n","     16        \u001b[36m0.0692\u001b[0m       0.9624        \u001b[35m0.1548\u001b[0m  1.6832\n","     17        \u001b[36m0.0645\u001b[0m       0.9612        \u001b[35m0.1540\u001b[0m  1.7717\n","     18        \u001b[36m0.0604\u001b[0m       0.9616        \u001b[35m0.1536\u001b[0m  2.8875\n","     19        \u001b[36m0.0566\u001b[0m       0.9616        \u001b[35m0.1535\u001b[0m  2.5353\n","     20        \u001b[36m0.0533\u001b[0m       0.9624        0.1537  1.6702\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.963 total time=  38.2s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7802\u001b[0m       \u001b[32m0.5552\u001b[0m        \u001b[35m2.1252\u001b[0m  1.6180\n","      2        \u001b[36m1.3933\u001b[0m       \u001b[32m0.7468\u001b[0m        \u001b[35m0.8986\u001b[0m  1.6145\n","      3        \u001b[36m0.6308\u001b[0m       \u001b[32m0.8852\u001b[0m        \u001b[35m0.4963\u001b[0m  1.6644\n","      4        \u001b[36m0.3667\u001b[0m       \u001b[32m0.9332\u001b[0m        \u001b[35m0.3206\u001b[0m  2.4045\n","      5        \u001b[36m0.2580\u001b[0m       \u001b[32m0.9452\u001b[0m        \u001b[35m0.2516\u001b[0m  1.9128\n","      6        \u001b[36m0.2066\u001b[0m       \u001b[32m0.9520\u001b[0m        \u001b[35m0.2187\u001b[0m  1.6763\n","      7        \u001b[36m0.1763\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.1992\u001b[0m  1.6361\n","      8        \u001b[36m0.1549\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.1858\u001b[0m  1.6817\n","      9        \u001b[36m0.1379\u001b[0m       \u001b[32m0.9612\u001b[0m        \u001b[35m0.1755\u001b[0m  1.6673\n","     10        \u001b[36m0.1236\u001b[0m       0.9608        \u001b[35m0.1675\u001b[0m  1.6579\n","     11        \u001b[36m0.1114\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1613\u001b[0m  2.3829\n","     12        \u001b[36m0.1010\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1567\u001b[0m  1.9465\n","     13        \u001b[36m0.0921\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1533\u001b[0m  1.6556\n","     14        \u001b[36m0.0844\u001b[0m       0.9624        \u001b[35m0.1509\u001b[0m  1.6512\n","     15        \u001b[36m0.0777\u001b[0m       \u001b[32m0.9632\u001b[0m        \u001b[35m0.1493\u001b[0m  1.6523\n","     16        \u001b[36m0.0719\u001b[0m       \u001b[32m0.9640\u001b[0m        \u001b[35m0.1483\u001b[0m  1.6299\n","     17        \u001b[36m0.0667\u001b[0m       0.9632        \u001b[35m0.1477\u001b[0m  1.6395\n","     18        \u001b[36m0.0620\u001b[0m       0.9632        \u001b[35m0.1474\u001b[0m  2.2845\n","     19        \u001b[36m0.0579\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1474\u001b[0m  1.9898\n","     20        \u001b[36m0.0542\u001b[0m       0.9632        0.1476  1.6455\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.968 total time=  37.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.2463\u001b[0m       \u001b[32m0.4036\u001b[0m        \u001b[35m1.8704\u001b[0m  1.8170\n","      2        \u001b[36m1.7467\u001b[0m       \u001b[32m0.4616\u001b[0m        \u001b[35m1.5865\u001b[0m  1.8187\n","      3        \u001b[36m1.5671\u001b[0m       0.4552        1.6629  1.7650\n","      4        1.6144       \u001b[32m0.4796\u001b[0m        \u001b[35m1.5701\u001b[0m  2.2890\n","      5        \u001b[36m1.4919\u001b[0m       \u001b[32m0.4864\u001b[0m        \u001b[35m1.5518\u001b[0m  2.3706\n","      6        1.5198       0.4676        1.5888  1.8130\n","      7        1.5499       0.4796        1.7008  1.8234\n","      8        1.5534       \u001b[32m0.4872\u001b[0m        1.5581  1.7205\n","      9        1.5639       0.4696        1.6196  1.7576\n","     10        1.5095       \u001b[32m0.4888\u001b[0m        1.6639  1.9008\n","     11        1.5209       0.4840        1.6727  2.8863\n","     12        1.5956       0.4576        1.8278  1.9315\n","     13        1.5933       0.4568        1.6849  1.9342\n","     14        1.5804       0.4848        1.6017  1.9253\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.487 total time=  30.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.8656\u001b[0m       \u001b[32m0.4752\u001b[0m        \u001b[35m1.4798\u001b[0m  2.2407\n","      2        \u001b[36m1.3952\u001b[0m       \u001b[32m0.4988\u001b[0m        \u001b[35m1.2986\u001b[0m  2.4360\n","      3        \u001b[36m1.3169\u001b[0m       0.4808        1.3778  1.8356\n","      4        1.3412       0.4884        1.3559  1.7503\n","      5        1.3938       0.4968        1.6975  1.7702\n","      6        1.3605       \u001b[32m0.5148\u001b[0m        1.6709  1.7691\n","      7        1.4030       \u001b[32m0.5424\u001b[0m        \u001b[35m1.2530\u001b[0m  1.7947\n","      8        1.3346       0.5276        1.4713  2.6018\n","      9        1.3842       0.5396        1.5288  1.9198\n","     10        \u001b[36m1.3158\u001b[0m       0.5320        1.3406  1.8908\n","     11        \u001b[36m1.2566\u001b[0m       0.5232        1.3271  1.9495\n","     12        1.4152       0.5220        1.3085  1.9404\n","     13        1.4025       0.5048        1.4157  1.8940\n","     14        1.7643       0.4520        1.6722  2.5370\n","     15        1.6372       0.4504        1.6410  2.2874\n","     16        1.6265       0.4500        1.6477  1.9822\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.455 total time=  35.5s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.0386\u001b[0m       \u001b[32m0.4552\u001b[0m        \u001b[35m1.5905\u001b[0m  1.7705\n","      2        \u001b[36m1.5847\u001b[0m       \u001b[32m0.4608\u001b[0m        \u001b[35m1.5766\u001b[0m  1.7975\n","      3        \u001b[36m1.5243\u001b[0m       \u001b[32m0.4708\u001b[0m        \u001b[35m1.5443\u001b[0m  2.6316\n","      4        1.5971       0.4192        1.6984  1.9319\n","      5        1.8243       0.4620        1.6082  1.8044\n","      6        1.5301       \u001b[32m0.4728\u001b[0m        \u001b[35m1.5192\u001b[0m  1.7556\n","      7        1.6347       \u001b[32m0.4732\u001b[0m        1.5717  1.7985\n","      8        1.6561       0.4284        1.7112  1.7397\n","      9        1.7203       0.4348        1.6881  2.0047\n","     10        1.6603       0.4416        1.8475  2.6181\n","     11        1.7233       0.4452        1.6452  1.9745\n","     12        1.6352       0.4296        1.7411  1.9551\n","     13        1.6371       0.4516        1.6140  1.9607\n","     14        1.6466       0.4352        1.6476  2.0109\n","     15        1.6224       0.4460        1.6341  2.2465\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.444 total time=  33.5s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.0994\u001b[0m       \u001b[32m0.7088\u001b[0m        \u001b[35m1.0682\u001b[0m  3.3361\n","      2        \u001b[36m0.5690\u001b[0m       \u001b[32m0.9371\u001b[0m        \u001b[35m0.3804\u001b[0m  3.3544\n","      3        \u001b[36m0.2683\u001b[0m       \u001b[32m0.9565\u001b[0m        \u001b[35m0.2354\u001b[0m  4.2516\n","      4        \u001b[36m0.1902\u001b[0m       \u001b[32m0.9613\u001b[0m        \u001b[35m0.1926\u001b[0m  3.4786\n","      5        \u001b[36m0.1561\u001b[0m       \u001b[32m0.9635\u001b[0m        \u001b[35m0.1716\u001b[0m  3.3978\n","      6        \u001b[36m0.1343\u001b[0m       \u001b[32m0.9643\u001b[0m        \u001b[35m0.1581\u001b[0m  3.3146\n","      7        \u001b[36m0.1179\u001b[0m       0.9643        \u001b[35m0.1488\u001b[0m  4.4374\n","      8        \u001b[36m0.1053\u001b[0m       \u001b[32m0.9656\u001b[0m        \u001b[35m0.1426\u001b[0m  3.3786\n","      9        \u001b[36m0.0953\u001b[0m       \u001b[32m0.9659\u001b[0m        \u001b[35m0.1386\u001b[0m  3.3754\n","     10        \u001b[36m0.0872\u001b[0m       0.9659        \u001b[35m0.1359\u001b[0m  4.2875\n","     11        \u001b[36m0.0804\u001b[0m       \u001b[32m0.9667\u001b[0m        \u001b[35m0.1342\u001b[0m  3.4502\n","     12        \u001b[36m0.0744\u001b[0m       0.9661        \u001b[35m0.1331\u001b[0m  3.3433\n","     13        \u001b[36m0.0692\u001b[0m       0.9664        \u001b[35m0.1325\u001b[0m  3.4031\n","     14        \u001b[36m0.0646\u001b[0m       0.9661        \u001b[35m0.1322\u001b[0m  4.4355\n","     15        \u001b[36m0.0604\u001b[0m       0.9659        \u001b[35m0.1322\u001b[0m  3.3700\n","     16        \u001b[36m0.0566\u001b[0m       0.9659        0.1324  3.3277\n","     17        \u001b[36m0.0533\u001b[0m       0.9656        0.1328  4.3314\n","     18        \u001b[36m0.0502\u001b[0m       0.9653        0.1333  3.4149\n","     19        \u001b[36m0.0475\u001b[0m       0.9653        0.1340  3.4283\n","     20        \u001b[36m0.0450\u001b[0m       0.9656        0.1348  3.8077\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=3,\n","             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n","  module=<class '__main__.ClassifierModule'>,\n","),\n","             param_grid={'callbacks__earlystopping__patience': [5, 10],\n","                         'module__nonlin': [<function relu at 0x7ffa9858a560>,\n","                                            <function tanh at 0x7ffa9858af80>],\n","                         'module__num_units': [800, 200],\n","                         'optimizer': [<class 'torch.optim.sgd.SGD'>,\n","                                       <class 'torch.optim.adam.Adam'>]},\n","             scoring='accuracy', verbose=3)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n","             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n","  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n","),\n","             param_grid={&#x27;callbacks__earlystopping__patience&#x27;: [5, 10],\n","                         &#x27;module__nonlin&#x27;: [&lt;function relu at 0x7ffa9858a560&gt;,\n","                                            &lt;function tanh at 0x7ffa9858af80&gt;],\n","                         &#x27;module__num_units&#x27;: [800, 200],\n","                         &#x27;optimizer&#x27;: [&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;,\n","                                       &lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;]},\n","             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n","             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n","  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n","),\n","             param_grid={&#x27;callbacks__earlystopping__patience&#x27;: [5, 10],\n","                         &#x27;module__nonlin&#x27;: [&lt;function relu at 0x7ffa9858a560&gt;,\n","                                            &lt;function tanh at 0x7ffa9858af80&gt;],\n","                         &#x27;module__num_units&#x27;: [800, 200],\n","                         &#x27;optimizer&#x27;: [&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;,\n","                                       &lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;]},\n","             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n","  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n",")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n","  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n",")</pre></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","# First, we extract some simple features as input for the neural network\n","# import package:\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","X_test = vectorizer.transform(sub_testdf['text'].to_numpy())\n","\n","X_test = X_test.astype(np.float32)\n","y_test = y_test.astype(np.int64)\n","y_pred = gs.predict(X_test)\n","\n","print(classification_report(y_test , y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDyUXkePyC5t","executionInfo":{"status":"ok","timestamp":1696786120356,"user_tz":-480,"elapsed":2793,"user":{"displayName":"Haozhe Luo","userId":"17359668240613124024"}},"outputId":"18305956-3eb4-429f-ab1a-fba1e40196ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99       250\n","           1       0.97      0.97      0.97       250\n","           2       0.94      0.96      0.95       250\n","           3       1.00      0.98      0.99       250\n","           4       0.86      0.97      0.91       250\n","           5       0.98      0.97      0.97       250\n","           6       0.97      0.98      0.98       250\n","           7       0.99      0.97      0.98       250\n","           8       1.00      1.00      1.00       250\n","           9       1.00      0.98      0.99       250\n","          10       0.96      0.98      0.97       250\n","          11       0.98      0.76      0.86       250\n","          12       1.00      0.98      0.99       250\n","          13       0.95      0.96      0.96       250\n","          14       0.98      0.99      0.99       250\n","          15       0.99      0.94      0.97       250\n","          16       0.98      1.00      0.99       250\n","          17       0.96      0.97      0.96       250\n","          18       1.00      1.00      1.00       250\n","          19       1.00      0.98      0.99       250\n","          20       1.00      0.99      0.99       250\n","          21       0.99      0.98      0.98       250\n","          22       1.00      0.98      0.99       250\n","          23       0.99      0.99      0.99       250\n","          24       0.79      0.97      0.87       250\n","\n","    accuracy                           0.97      6250\n","   macro avg       0.97      0.97      0.97      6250\n","weighted avg       0.97      0.97      0.97      6250\n","\n"]}]},{"cell_type":"code","source":["# max_feature is 100 here(ablation)\n","class ClassifierModule(nn.Module):\n","    def __init__(\n","            self,\n","            num_units=200,\n","            nonlin=F.relu,\n","    ):\n","        super(ClassifierModule, self).__init__()\n","        self.num_units = num_units\n","        self.nonlin = nonlin\n","\n","        self.dense0 = nn.Linear(100, num_units)\n","        self.nonlin = nonlin\n","        self.dense1 = nn.Linear(num_units, 50)\n","        self.output = nn.Linear(50, 25)\n","\n","    def forward(self, X, **kwargs):\n","      X = self.nonlin(self.dense0(X))\n","      X = F.relu(self.dense1(X))\n","      X = self.output(X)\n","      return X.squeeze(dim=1)\n","\n","net2 = NeuralNetClassifier(\n","    ClassifierModule,\n","    max_epochs=20,\n","    criterion=nn.CrossEntropyLoss(),\n","    callbacks=[('earlystopping', EarlyStopping(patience=5))],\n","    lr=0.1,\n","    #device='cuda',  # comment this to train with CPU\n",")\n","params2 = {\n","    'optimizer': [torch.optim.SGD, torch.optim.Adam],\n","    'module__nonlin':[F.relu, F.tanh],\n","    'module__num_units': [800,200],\n","    'callbacks__earlystopping__patience':[5,10]\n","}\n","vectorizer2 = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=100, binary=True)\n","X_100 = vectorizer2.fit_transform(sub_traindf['text'].to_numpy())\n","X_100 = X_100.astype(np.float32)\n","y = y_train_dev.astype(np.int64)\n","# Note: Consider using StratifiedKFold for classification tasks\n","gs2 = GridSearchCV(net2, params2, refit=True, cv=3, scoring='accuracy', verbose=3)\n","gs2.fit(X_100, y_train_dev)"],"metadata":{"id":"fe6W3RUjBoCs","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1696791914683,"user_tz":-480,"elapsed":1451250,"user":{"displayName":"Haozhe Luo","userId":"17359668240613124024"}},"outputId":"04a0a572-e8b9-4a29-a576-add0e38a8e16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 16 candidates, totalling 48 fits\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9187\u001b[0m       \u001b[32m0.1332\u001b[0m        \u001b[35m2.8896\u001b[0m  2.0389\n","      2        \u001b[36m2.3096\u001b[0m       \u001b[32m0.2028\u001b[0m        \u001b[35m2.3778\u001b[0m  1.5750\n","      3        \u001b[36m1.8023\u001b[0m       \u001b[32m0.2696\u001b[0m        \u001b[35m1.9711\u001b[0m  1.6166\n","      4        \u001b[36m1.5523\u001b[0m       \u001b[32m0.3812\u001b[0m        \u001b[35m1.7371\u001b[0m  1.5557\n","      5        \u001b[36m1.3838\u001b[0m       \u001b[32m0.4268\u001b[0m        \u001b[35m1.6145\u001b[0m  1.5697\n","      6        \u001b[36m1.2665\u001b[0m       \u001b[32m0.4736\u001b[0m        \u001b[35m1.5108\u001b[0m  1.5597\n","      7        \u001b[36m1.1934\u001b[0m       \u001b[32m0.4984\u001b[0m        \u001b[35m1.4275\u001b[0m  1.8590\n","      8        \u001b[36m1.1447\u001b[0m       \u001b[32m0.5152\u001b[0m        \u001b[35m1.3647\u001b[0m  2.3187\n","      9        \u001b[36m1.1098\u001b[0m       \u001b[32m0.5428\u001b[0m        \u001b[35m1.3164\u001b[0m  1.5771\n","     10        \u001b[36m1.0829\u001b[0m       \u001b[32m0.5520\u001b[0m        \u001b[35m1.2757\u001b[0m  1.5797\n","     11        \u001b[36m1.0613\u001b[0m       \u001b[32m0.5652\u001b[0m        \u001b[35m1.2418\u001b[0m  1.6053\n","     12        \u001b[36m1.0436\u001b[0m       \u001b[32m0.5712\u001b[0m        \u001b[35m1.2136\u001b[0m  1.6046\n","     13        \u001b[36m1.0285\u001b[0m       \u001b[32m0.5788\u001b[0m        \u001b[35m1.1912\u001b[0m  1.6038\n","     14        \u001b[36m1.0158\u001b[0m       \u001b[32m0.5820\u001b[0m        \u001b[35m1.1733\u001b[0m  1.5447\n","     15        \u001b[36m1.0047\u001b[0m       \u001b[32m0.5884\u001b[0m        \u001b[35m1.1600\u001b[0m  2.4168\n","     16        \u001b[36m0.9948\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m1.1487\u001b[0m  1.7489\n","     17        \u001b[36m0.9860\u001b[0m       \u001b[32m0.5916\u001b[0m        \u001b[35m1.1410\u001b[0m  1.5679\n","     18        \u001b[36m0.9779\u001b[0m       \u001b[32m0.5952\u001b[0m        \u001b[35m1.1340\u001b[0m  1.5549\n","     19        \u001b[36m0.9705\u001b[0m       \u001b[32m0.5972\u001b[0m        \u001b[35m1.1274\u001b[0m  1.5988\n","     20        \u001b[36m0.9636\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m1.1230\u001b[0m  1.5992\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.610 total time=  35.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9315\u001b[0m       \u001b[32m0.1160\u001b[0m        \u001b[35m2.8848\u001b[0m  1.6281\n","      2        \u001b[36m2.3272\u001b[0m       \u001b[32m0.1980\u001b[0m        \u001b[35m2.4539\u001b[0m  2.5040\n","      3        \u001b[36m1.7835\u001b[0m       \u001b[32m0.2828\u001b[0m        \u001b[35m2.0236\u001b[0m  1.6087\n","      4        \u001b[36m1.5044\u001b[0m       \u001b[32m0.3840\u001b[0m        \u001b[35m1.6962\u001b[0m  1.5740\n","      5        \u001b[36m1.3300\u001b[0m       \u001b[32m0.4640\u001b[0m        \u001b[35m1.5000\u001b[0m  1.5748\n","      6        \u001b[36m1.2299\u001b[0m       \u001b[32m0.5204\u001b[0m        \u001b[35m1.3854\u001b[0m  1.6105\n","      7        \u001b[36m1.1708\u001b[0m       \u001b[32m0.5432\u001b[0m        \u001b[35m1.3079\u001b[0m  1.5803\n","      8        \u001b[36m1.1299\u001b[0m       \u001b[32m0.5748\u001b[0m        \u001b[35m1.2532\u001b[0m  1.5687\n","      9        \u001b[36m1.0994\u001b[0m       \u001b[32m0.5868\u001b[0m        \u001b[35m1.2114\u001b[0m  2.2186\n","     10        \u001b[36m1.0755\u001b[0m       \u001b[32m0.5948\u001b[0m        \u001b[35m1.1826\u001b[0m  1.9775\n","     11        \u001b[36m1.0561\u001b[0m       \u001b[32m0.6028\u001b[0m        \u001b[35m1.1624\u001b[0m  1.9904\n","     12        \u001b[36m1.0401\u001b[0m       \u001b[32m0.6044\u001b[0m        \u001b[35m1.1482\u001b[0m  1.5532\n","     13        \u001b[36m1.0265\u001b[0m       \u001b[32m0.6084\u001b[0m        \u001b[35m1.1373\u001b[0m  1.5972\n","     14        \u001b[36m1.0147\u001b[0m       0.6084        \u001b[35m1.1288\u001b[0m  1.5680\n","     15        \u001b[36m1.0045\u001b[0m       \u001b[32m0.6088\u001b[0m        \u001b[35m1.1222\u001b[0m  1.5813\n","     16        \u001b[36m0.9955\u001b[0m       \u001b[32m0.6100\u001b[0m        \u001b[35m1.1173\u001b[0m  2.1267\n","     17        \u001b[36m0.9873\u001b[0m       \u001b[32m0.6108\u001b[0m        \u001b[35m1.1127\u001b[0m  2.0387\n","     18        \u001b[36m0.9799\u001b[0m       \u001b[32m0.6112\u001b[0m        \u001b[35m1.1096\u001b[0m  1.5864\n","     19        \u001b[36m0.9729\u001b[0m       \u001b[32m0.6236\u001b[0m        \u001b[35m1.1074\u001b[0m  1.6203\n","     20        \u001b[36m0.9663\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.1061\u001b[0m  1.5796\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.612 total time=  36.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9321\u001b[0m       \u001b[32m0.1212\u001b[0m        \u001b[35m2.7459\u001b[0m  1.6262\n","      2        \u001b[36m2.4058\u001b[0m       \u001b[32m0.2276\u001b[0m        \u001b[35m2.2002\u001b[0m  1.6167\n","      3        \u001b[36m1.8695\u001b[0m       \u001b[32m0.3796\u001b[0m        \u001b[35m1.8044\u001b[0m  2.3072\n","      4        \u001b[36m1.5784\u001b[0m       \u001b[32m0.4648\u001b[0m        \u001b[35m1.5583\u001b[0m  1.8856\n","      5        \u001b[36m1.3931\u001b[0m       \u001b[32m0.4996\u001b[0m        \u001b[35m1.3932\u001b[0m  1.5734\n","      6        \u001b[36m1.2699\u001b[0m       \u001b[32m0.5412\u001b[0m        \u001b[35m1.2997\u001b[0m  1.5973\n","      7        \u001b[36m1.1969\u001b[0m       \u001b[32m0.5720\u001b[0m        \u001b[35m1.2474\u001b[0m  1.5900\n","      8        \u001b[36m1.1505\u001b[0m       \u001b[32m0.5772\u001b[0m        \u001b[35m1.2150\u001b[0m  1.6134\n","      9        \u001b[36m1.1175\u001b[0m       \u001b[32m0.5836\u001b[0m        \u001b[35m1.1921\u001b[0m  1.5826\n","     10        \u001b[36m1.0922\u001b[0m       0.5836        \u001b[35m1.1748\u001b[0m  2.4631\n","     11        \u001b[36m1.0714\u001b[0m       \u001b[32m0.5876\u001b[0m        \u001b[35m1.1602\u001b[0m  2.5974\n","     12        \u001b[36m1.0539\u001b[0m       \u001b[32m0.5940\u001b[0m        \u001b[35m1.1480\u001b[0m  1.7977\n","     13        \u001b[36m1.0387\u001b[0m       \u001b[32m0.5968\u001b[0m        \u001b[35m1.1393\u001b[0m  1.5717\n","     14        \u001b[36m1.0256\u001b[0m       \u001b[32m0.5984\u001b[0m        \u001b[35m1.1309\u001b[0m  1.5764\n","     15        \u001b[36m1.0140\u001b[0m       \u001b[32m0.6028\u001b[0m        \u001b[35m1.1252\u001b[0m  1.5620\n","     16        \u001b[36m1.0038\u001b[0m       0.6028        \u001b[35m1.1201\u001b[0m  1.5696\n","     17        \u001b[36m0.9945\u001b[0m       \u001b[32m0.6192\u001b[0m        \u001b[35m1.1150\u001b[0m  1.6193\n","     18        \u001b[36m0.9859\u001b[0m       \u001b[32m0.6228\u001b[0m        \u001b[35m1.1116\u001b[0m  1.9861\n","     19        \u001b[36m0.9779\u001b[0m       \u001b[32m0.6248\u001b[0m        \u001b[35m1.1072\u001b[0m  2.1823\n","     20        \u001b[36m0.9704\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.1046\u001b[0m  1.6056\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.622 total time=  36.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m5.6748\u001b[0m       \u001b[32m0.0400\u001b[0m        \u001b[35m3.2241\u001b[0m  1.6504\n","      2        \u001b[36m3.2346\u001b[0m       0.0400        \u001b[35m3.2239\u001b[0m  1.7131\n","      3        3.2358       \u001b[32m0.0404\u001b[0m        \u001b[35m3.2238\u001b[0m  1.6975\n","      4        \u001b[36m3.2324\u001b[0m       0.0400        3.2244  1.6295\n","      5        3.2326       0.0400        3.2245  2.4817\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  11.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m6.1944\u001b[0m       \u001b[32m0.1720\u001b[0m        \u001b[35m2.5765\u001b[0m  1.6460\n","      2        \u001b[36m2.5822\u001b[0m       0.1384        2.7053  1.6185\n","      3        \u001b[36m2.5491\u001b[0m       \u001b[32m0.1764\u001b[0m        \u001b[35m2.5500\u001b[0m  1.6519\n","      4        \u001b[36m2.5404\u001b[0m       \u001b[32m0.1788\u001b[0m        2.5530  1.6136\n","      5        2.5407       0.1752        \u001b[35m2.5293\u001b[0m  1.8623\n","      6        \u001b[36m2.5234\u001b[0m       0.1740        2.5645  2.4228\n","      7        2.5466       0.1644        2.5777  1.6470\n","      8        2.5584       0.1628        2.5512  1.6615\n","      9        \u001b[36m2.5130\u001b[0m       \u001b[32m0.1808\u001b[0m        \u001b[35m2.4856\u001b[0m  1.6503\n","     10        \u001b[36m2.4953\u001b[0m       0.1704        2.5293  1.8769\n","     11        2.5016       \u001b[32m0.1916\u001b[0m        \u001b[35m2.4818\u001b[0m  1.8808\n","     12        2.5711       0.1792        2.5077  2.3164\n","     13        \u001b[36m2.4752\u001b[0m       0.1768        2.5161  2.3761\n","     14        2.5288       0.1408        2.6249  1.8069\n","     15        2.5886       0.1584        2.5769  1.8833\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.144 total time=  30.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m6.8839\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m3.0836\u001b[0m  1.6802\n","      2        \u001b[36m3.0756\u001b[0m       0.0488        \u001b[35m3.0728\u001b[0m  2.0159\n","      3        \u001b[36m3.0648\u001b[0m       \u001b[32m0.0552\u001b[0m        \u001b[35m3.0610\u001b[0m  2.3014\n","      4        \u001b[36m3.0561\u001b[0m       \u001b[32m0.0664\u001b[0m        \u001b[35m3.0524\u001b[0m  1.7797\n","      5        \u001b[36m3.0488\u001b[0m       \u001b[32m0.0696\u001b[0m        3.0592  2.0955\n","      6        \u001b[36m3.0465\u001b[0m       0.0652        \u001b[35m3.0465\u001b[0m  1.6471\n","      7        \u001b[36m3.0350\u001b[0m       \u001b[32m0.0708\u001b[0m        \u001b[35m2.9619\u001b[0m  1.6301\n","      8        3.9860       0.0640        3.1120  1.6966\n","      9        3.1337       0.0668        3.1105  2.3063\n","     10        3.0977       0.0616        3.1100  2.1840\n","     11        3.0886       0.0500        3.0900  1.9103\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.075 total time=  24.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0335\u001b[0m       \u001b[32m0.0904\u001b[0m        \u001b[35m2.9154\u001b[0m  1.4329\n","      2        \u001b[36m2.7013\u001b[0m       \u001b[32m0.1700\u001b[0m        \u001b[35m2.6736\u001b[0m  1.4541\n","      3        \u001b[36m2.2175\u001b[0m       \u001b[32m0.1912\u001b[0m        \u001b[35m2.3088\u001b[0m  1.5173\n","      4        \u001b[36m1.8137\u001b[0m       \u001b[32m0.2832\u001b[0m        \u001b[35m1.9929\u001b[0m  2.3687\n","      5        \u001b[36m1.5726\u001b[0m       \u001b[32m0.3720\u001b[0m        \u001b[35m1.7309\u001b[0m  1.5010\n","      6        \u001b[36m1.4099\u001b[0m       \u001b[32m0.4404\u001b[0m        \u001b[35m1.5712\u001b[0m  1.4146\n","      7        \u001b[36m1.3073\u001b[0m       \u001b[32m0.4744\u001b[0m        \u001b[35m1.4842\u001b[0m  1.4393\n","      8        \u001b[36m1.2446\u001b[0m       \u001b[32m0.4996\u001b[0m        \u001b[35m1.4214\u001b[0m  1.4484\n","      9        \u001b[36m1.2007\u001b[0m       \u001b[32m0.5136\u001b[0m        \u001b[35m1.3691\u001b[0m  1.4419\n","     10        \u001b[36m1.1667\u001b[0m       \u001b[32m0.5272\u001b[0m        \u001b[35m1.3238\u001b[0m  1.4373\n","     11        \u001b[36m1.1388\u001b[0m       \u001b[32m0.5360\u001b[0m        \u001b[35m1.2876\u001b[0m  1.5026\n","     12        \u001b[36m1.1157\u001b[0m       \u001b[32m0.5468\u001b[0m        \u001b[35m1.2594\u001b[0m  2.3270\n","     13        \u001b[36m1.0963\u001b[0m       \u001b[32m0.5708\u001b[0m        \u001b[35m1.2345\u001b[0m  1.6037\n","     14        \u001b[36m1.0798\u001b[0m       \u001b[32m0.5756\u001b[0m        \u001b[35m1.2143\u001b[0m  1.4110\n","     15        \u001b[36m1.0654\u001b[0m       \u001b[32m0.5792\u001b[0m        \u001b[35m1.1998\u001b[0m  1.4765\n","     16        \u001b[36m1.0528\u001b[0m       \u001b[32m0.5812\u001b[0m        \u001b[35m1.1869\u001b[0m  1.3984\n","     17        \u001b[36m1.0415\u001b[0m       \u001b[32m0.5844\u001b[0m        \u001b[35m1.1759\u001b[0m  1.4757\n","     18        \u001b[36m1.0314\u001b[0m       0.5844        \u001b[35m1.1670\u001b[0m  1.4530\n","     19        \u001b[36m1.0222\u001b[0m       \u001b[32m0.5880\u001b[0m        \u001b[35m1.1600\u001b[0m  1.4014\n","     20        \u001b[36m1.0138\u001b[0m       0.5880        \u001b[35m1.1549\u001b[0m  2.2673\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.599 total time=  32.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0241\u001b[0m       \u001b[32m0.0760\u001b[0m        \u001b[35m2.9088\u001b[0m  1.4184\n","      2        \u001b[36m2.7057\u001b[0m       \u001b[32m0.1632\u001b[0m        \u001b[35m2.6543\u001b[0m  1.4885\n","      3        \u001b[36m2.2199\u001b[0m       \u001b[32m0.2000\u001b[0m        \u001b[35m2.2839\u001b[0m  1.4289\n","      4        \u001b[36m1.8378\u001b[0m       \u001b[32m0.2352\u001b[0m        \u001b[35m2.0591\u001b[0m  1.4294\n","      5        \u001b[36m1.6215\u001b[0m       \u001b[32m0.3244\u001b[0m        \u001b[35m1.9054\u001b[0m  1.4250\n","      6        \u001b[36m1.4599\u001b[0m       \u001b[32m0.3752\u001b[0m        \u001b[35m1.7667\u001b[0m  1.4644\n","      7        \u001b[36m1.3321\u001b[0m       \u001b[32m0.4224\u001b[0m        \u001b[35m1.6302\u001b[0m  1.8432\n","      8        \u001b[36m1.2494\u001b[0m       \u001b[32m0.4668\u001b[0m        \u001b[35m1.5275\u001b[0m  2.1022\n","      9        \u001b[36m1.1990\u001b[0m       \u001b[32m0.4928\u001b[0m        \u001b[35m1.4523\u001b[0m  1.4832\n","     10        \u001b[36m1.1636\u001b[0m       \u001b[32m0.5144\u001b[0m        \u001b[35m1.3916\u001b[0m  1.4636\n","     11        \u001b[36m1.1363\u001b[0m       \u001b[32m0.5292\u001b[0m        \u001b[35m1.3440\u001b[0m  1.4336\n","     12        \u001b[36m1.1141\u001b[0m       \u001b[32m0.5388\u001b[0m        \u001b[35m1.3050\u001b[0m  1.4693\n","     13        \u001b[36m1.0958\u001b[0m       \u001b[32m0.5648\u001b[0m        \u001b[35m1.2713\u001b[0m  1.4696\n","     14        \u001b[36m1.0799\u001b[0m       \u001b[32m0.5764\u001b[0m        \u001b[35m1.2448\u001b[0m  1.4349\n","     15        \u001b[36m1.0658\u001b[0m       \u001b[32m0.5828\u001b[0m        \u001b[35m1.2221\u001b[0m  1.7742\n","     16        \u001b[36m1.0533\u001b[0m       \u001b[32m0.5872\u001b[0m        \u001b[35m1.2049\u001b[0m  2.1258\n","     17        \u001b[36m1.0421\u001b[0m       \u001b[32m0.5952\u001b[0m        \u001b[35m1.1881\u001b[0m  1.4576\n","     18        \u001b[36m1.0320\u001b[0m       0.5948        \u001b[35m1.1749\u001b[0m  1.4402\n","     19        \u001b[36m1.0228\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.1623\u001b[0m  1.4699\n","     20        \u001b[36m1.0145\u001b[0m       \u001b[32m0.6040\u001b[0m        \u001b[35m1.1547\u001b[0m  1.4573\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.593 total time=  31.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0467\u001b[0m       \u001b[32m0.1156\u001b[0m        \u001b[35m2.8927\u001b[0m  1.4266\n","      2        \u001b[36m2.7242\u001b[0m       \u001b[32m0.2304\u001b[0m        \u001b[35m2.5605\u001b[0m  1.4284\n","      3        \u001b[36m2.2372\u001b[0m       \u001b[32m0.2672\u001b[0m        \u001b[35m2.1080\u001b[0m  2.1744\n","      4        \u001b[36m1.8345\u001b[0m       \u001b[32m0.3484\u001b[0m        \u001b[35m1.8362\u001b[0m  1.7424\n","      5        \u001b[36m1.6095\u001b[0m       \u001b[32m0.4540\u001b[0m        \u001b[35m1.6354\u001b[0m  1.4290\n","      6        \u001b[36m1.4414\u001b[0m       \u001b[32m0.4916\u001b[0m        \u001b[35m1.4770\u001b[0m  1.5166\n","      7        \u001b[36m1.3186\u001b[0m       \u001b[32m0.5080\u001b[0m        \u001b[35m1.3792\u001b[0m  1.4317\n","      8        \u001b[36m1.2451\u001b[0m       \u001b[32m0.5240\u001b[0m        \u001b[35m1.3171\u001b[0m  1.4766\n","      9        \u001b[36m1.1986\u001b[0m       \u001b[32m0.5472\u001b[0m        \u001b[35m1.2702\u001b[0m  1.4449\n","     10        \u001b[36m1.1650\u001b[0m       \u001b[32m0.5616\u001b[0m        \u001b[35m1.2344\u001b[0m  1.4191\n","     11        \u001b[36m1.1385\u001b[0m       \u001b[32m0.5728\u001b[0m        \u001b[35m1.2107\u001b[0m  2.1040\n","     12        \u001b[36m1.1165\u001b[0m       \u001b[32m0.5832\u001b[0m        \u001b[35m1.1936\u001b[0m  1.7784\n","     13        \u001b[36m1.0977\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.1810\u001b[0m  1.4666\n","     14        \u001b[36m1.0811\u001b[0m       \u001b[32m0.5928\u001b[0m        \u001b[35m1.1703\u001b[0m  1.4997\n","     15        \u001b[36m1.0665\u001b[0m       \u001b[32m0.5948\u001b[0m        \u001b[35m1.1615\u001b[0m  1.4716\n","     16        \u001b[36m1.0533\u001b[0m       \u001b[32m0.5972\u001b[0m        \u001b[35m1.1534\u001b[0m  1.4460\n","     17        \u001b[36m1.0416\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m1.1462\u001b[0m  1.4587\n","     18        \u001b[36m1.0312\u001b[0m       \u001b[32m0.6020\u001b[0m        \u001b[35m1.1404\u001b[0m  1.4258\n","     19        \u001b[36m1.0217\u001b[0m       \u001b[32m0.6048\u001b[0m        \u001b[35m1.1358\u001b[0m  2.0992\n","     20        \u001b[36m1.0131\u001b[0m       \u001b[32m0.6184\u001b[0m        \u001b[35m1.1316\u001b[0m  1.7851\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.609 total time=  32.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9693\u001b[0m       \u001b[32m0.2512\u001b[0m        \u001b[35m2.3625\u001b[0m  1.4875\n","      2        \u001b[36m1.9762\u001b[0m       \u001b[32m0.2676\u001b[0m        2.3668  1.4709\n","      3        1.9872       \u001b[32m0.2836\u001b[0m        \u001b[35m2.2302\u001b[0m  2.2397\n","      4        \u001b[36m1.8710\u001b[0m       \u001b[32m0.3196\u001b[0m        \u001b[35m1.9779\u001b[0m  1.7830\n","      5        \u001b[36m1.8204\u001b[0m       \u001b[32m0.3360\u001b[0m        \u001b[35m1.9239\u001b[0m  1.5705\n","      6        \u001b[36m1.7729\u001b[0m       \u001b[32m0.3480\u001b[0m        \u001b[35m1.8447\u001b[0m  2.3647\n","      7        1.7782       \u001b[32m0.3712\u001b[0m        \u001b[35m1.7455\u001b[0m  1.5356\n","      8        \u001b[36m1.7653\u001b[0m       0.3424        1.8336  1.5337\n","      9        1.7836       0.3564        1.7544  1.4832\n","     10        \u001b[36m1.7318\u001b[0m       0.3672        1.8340  1.5612\n","     11        1.7612       0.3528        1.7537  1.5070\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.358 total time=  21.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9083\u001b[0m       \u001b[32m0.2128\u001b[0m        \u001b[35m2.3009\u001b[0m  2.2964\n","      2        \u001b[36m2.2078\u001b[0m       \u001b[32m0.2404\u001b[0m        \u001b[35m2.2026\u001b[0m  1.6818\n","      3        \u001b[36m2.0599\u001b[0m       \u001b[32m0.2868\u001b[0m        \u001b[35m2.1139\u001b[0m  1.5344\n","      4        \u001b[36m2.0450\u001b[0m       0.2716        \u001b[35m2.0559\u001b[0m  1.5110\n","      5        \u001b[36m2.0342\u001b[0m       0.2808        \u001b[35m2.0398\u001b[0m  1.4967\n","      6        \u001b[36m1.9824\u001b[0m       \u001b[32m0.2968\u001b[0m        \u001b[35m2.0284\u001b[0m  1.4906\n","      7        \u001b[36m1.9433\u001b[0m       0.2720        \u001b[35m2.0220\u001b[0m  1.4946\n","      8        1.9503       0.2772        2.1238  1.6014\n","      9        \u001b[36m1.9315\u001b[0m       0.2824        2.1078  2.4152\n","     10        2.0194       0.2916        2.0722  1.5448\n","     11        2.0078       0.2832        2.0450  1.5237\n","     12        1.9855       0.2776        \u001b[35m2.0097\u001b[0m  1.5405\n","     13        1.9867       0.2736        2.1256  1.5405\n","     14        2.1054       0.2576        2.1530  1.5768\n","     15        2.0442       0.2884        2.0364  1.5178\n","     16        2.0099       0.2688        2.1015  2.1134\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.263 total time=  29.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.3895\u001b[0m       \u001b[32m0.1276\u001b[0m        \u001b[35m2.5665\u001b[0m  1.4879\n","      2        \u001b[36m2.5057\u001b[0m       \u001b[32m0.1420\u001b[0m        \u001b[35m2.4798\u001b[0m  1.4835\n","      3        \u001b[36m2.4332\u001b[0m       \u001b[32m0.1716\u001b[0m        \u001b[35m2.4025\u001b[0m  1.5139\n","      4        \u001b[36m2.4232\u001b[0m       0.1684        2.4451  1.4907\n","      5        \u001b[36m2.3916\u001b[0m       \u001b[32m0.1824\u001b[0m        2.5378  1.5328\n","      6        2.4484       0.1612        2.4364  1.7493\n","      7        2.4089       0.1516        2.4287  2.2454\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.148 total time=  13.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8003\u001b[0m       \u001b[32m0.1868\u001b[0m        \u001b[35m2.5721\u001b[0m  1.6129\n","      2        \u001b[36m2.0483\u001b[0m       \u001b[32m0.3072\u001b[0m        \u001b[35m1.9314\u001b[0m  1.6521\n","      3        \u001b[36m1.5768\u001b[0m       \u001b[32m0.4280\u001b[0m        \u001b[35m1.5724\u001b[0m  1.6145\n","      4        \u001b[36m1.3355\u001b[0m       \u001b[32m0.5232\u001b[0m        \u001b[35m1.3790\u001b[0m  1.5976\n","      5        \u001b[36m1.2169\u001b[0m       \u001b[32m0.5584\u001b[0m        \u001b[35m1.2900\u001b[0m  1.9723\n","      6        \u001b[36m1.1534\u001b[0m       \u001b[32m0.5684\u001b[0m        \u001b[35m1.2401\u001b[0m  2.2939\n","      7        \u001b[36m1.1126\u001b[0m       \u001b[32m0.5796\u001b[0m        \u001b[35m1.2069\u001b[0m  1.5656\n","      8        \u001b[36m1.0836\u001b[0m       \u001b[32m0.5876\u001b[0m        \u001b[35m1.1828\u001b[0m  1.5795\n","      9        \u001b[36m1.0618\u001b[0m       \u001b[32m0.5940\u001b[0m        \u001b[35m1.1653\u001b[0m  1.5894\n","     10        \u001b[36m1.0445\u001b[0m       \u001b[32m0.5992\u001b[0m        \u001b[35m1.1504\u001b[0m  1.5556\n","     11        \u001b[36m1.0303\u001b[0m       \u001b[32m0.6024\u001b[0m        \u001b[35m1.1377\u001b[0m  1.5911\n","     12        \u001b[36m1.0183\u001b[0m       \u001b[32m0.6040\u001b[0m        \u001b[35m1.1270\u001b[0m  1.6117\n","     13        \u001b[36m1.0079\u001b[0m       0.6008        \u001b[35m1.1191\u001b[0m  2.5467\n","     14        \u001b[36m0.9990\u001b[0m       \u001b[32m0.6044\u001b[0m        \u001b[35m1.1121\u001b[0m  1.6630\n","     15        \u001b[36m0.9911\u001b[0m       0.6044        \u001b[35m1.1081\u001b[0m  1.5667\n","     16        \u001b[36m0.9841\u001b[0m       \u001b[32m0.6064\u001b[0m        \u001b[35m1.1041\u001b[0m  1.6212\n","     17        \u001b[36m0.9778\u001b[0m       \u001b[32m0.6076\u001b[0m        \u001b[35m1.1014\u001b[0m  1.5655\n","     18        \u001b[36m0.9719\u001b[0m       \u001b[32m0.6084\u001b[0m        \u001b[35m1.0972\u001b[0m  1.5711\n","     19        \u001b[36m0.9665\u001b[0m       0.6072        \u001b[35m1.0959\u001b[0m  1.6031\n","     20        \u001b[36m0.9615\u001b[0m       \u001b[32m0.6092\u001b[0m        \u001b[35m1.0947\u001b[0m  2.2805\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.614 total time=  35.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8044\u001b[0m       \u001b[32m0.1784\u001b[0m        \u001b[35m2.6416\u001b[0m  1.5746\n","      2        \u001b[36m2.0102\u001b[0m       \u001b[32m0.2904\u001b[0m        \u001b[35m1.9595\u001b[0m  1.5934\n","      3        \u001b[36m1.5470\u001b[0m       \u001b[32m0.4692\u001b[0m        \u001b[35m1.5675\u001b[0m  1.5956\n","      4        \u001b[36m1.3171\u001b[0m       \u001b[32m0.5436\u001b[0m        \u001b[35m1.3727\u001b[0m  1.6215\n","      5        \u001b[36m1.2048\u001b[0m       \u001b[32m0.5736\u001b[0m        \u001b[35m1.2775\u001b[0m  1.5954\n","      6        \u001b[36m1.1429\u001b[0m       \u001b[32m0.5932\u001b[0m        \u001b[35m1.2211\u001b[0m  1.6234\n","      7        \u001b[36m1.1038\u001b[0m       \u001b[32m0.6012\u001b[0m        \u001b[35m1.1845\u001b[0m  2.3832\n","      8        \u001b[36m1.0765\u001b[0m       \u001b[32m0.6056\u001b[0m        \u001b[35m1.1593\u001b[0m  1.8190\n","      9        \u001b[36m1.0560\u001b[0m       \u001b[32m0.6116\u001b[0m        \u001b[35m1.1421\u001b[0m  1.6055\n","     10        \u001b[36m1.0401\u001b[0m       \u001b[32m0.6132\u001b[0m        \u001b[35m1.1293\u001b[0m  1.6015\n","     11        \u001b[36m1.0271\u001b[0m       \u001b[32m0.6164\u001b[0m        \u001b[35m1.1201\u001b[0m  1.5901\n","     12        \u001b[36m1.0163\u001b[0m       \u001b[32m0.6188\u001b[0m        \u001b[35m1.1133\u001b[0m  1.5851\n","     13        \u001b[36m1.0069\u001b[0m       \u001b[32m0.6204\u001b[0m        \u001b[35m1.1084\u001b[0m  1.5456\n","     14        \u001b[36m0.9988\u001b[0m       \u001b[32m0.6212\u001b[0m        \u001b[35m1.1052\u001b[0m  2.0771\n","     15        \u001b[36m0.9917\u001b[0m       \u001b[32m0.6232\u001b[0m        \u001b[35m1.1027\u001b[0m  2.1555\n","     16        \u001b[36m0.9853\u001b[0m       0.6224        \u001b[35m1.1008\u001b[0m  1.6063\n","     17        \u001b[36m0.9795\u001b[0m       \u001b[32m0.6244\u001b[0m        \u001b[35m1.0996\u001b[0m  1.6007\n","     18        \u001b[36m0.9741\u001b[0m       0.6240        \u001b[35m1.0990\u001b[0m  1.6506\n","     19        \u001b[36m0.9692\u001b[0m       0.6244        \u001b[35m1.0988\u001b[0m  1.6220\n","     20        \u001b[36m0.9645\u001b[0m       \u001b[32m0.6256\u001b[0m        \u001b[35m1.0987\u001b[0m  1.6270\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.608 total time=  35.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7854\u001b[0m       \u001b[32m0.2168\u001b[0m        \u001b[35m2.4271\u001b[0m  2.4275\n","      2        \u001b[36m2.0215\u001b[0m       \u001b[32m0.3696\u001b[0m        \u001b[35m1.8438\u001b[0m  1.8513\n","      3        \u001b[36m1.5675\u001b[0m       \u001b[32m0.4932\u001b[0m        \u001b[35m1.5065\u001b[0m  1.6459\n","      4        \u001b[36m1.3326\u001b[0m       \u001b[32m0.5320\u001b[0m        \u001b[35m1.3378\u001b[0m  1.6133\n","      5        \u001b[36m1.2225\u001b[0m       \u001b[32m0.5612\u001b[0m        \u001b[35m1.2583\u001b[0m  1.6181\n","      6        \u001b[36m1.1642\u001b[0m       \u001b[32m0.5744\u001b[0m        \u001b[35m1.2139\u001b[0m  1.6436\n","      7        \u001b[36m1.1266\u001b[0m       \u001b[32m0.5804\u001b[0m        \u001b[35m1.1869\u001b[0m  1.6056\n","      8        \u001b[36m1.0992\u001b[0m       \u001b[32m0.5888\u001b[0m        \u001b[35m1.1673\u001b[0m  2.2570\n","      9        \u001b[36m1.0778\u001b[0m       \u001b[32m0.5920\u001b[0m        \u001b[35m1.1517\u001b[0m  2.0140\n","     10        \u001b[36m1.0603\u001b[0m       \u001b[32m0.5972\u001b[0m        \u001b[35m1.1414\u001b[0m  1.6465\n","     11        \u001b[36m1.0459\u001b[0m       \u001b[32m0.6060\u001b[0m        \u001b[35m1.1330\u001b[0m  1.5428\n","     12        \u001b[36m1.0337\u001b[0m       \u001b[32m0.6064\u001b[0m        \u001b[35m1.1268\u001b[0m  1.6085\n","     13        \u001b[36m1.0232\u001b[0m       \u001b[32m0.6072\u001b[0m        \u001b[35m1.1215\u001b[0m  1.6132\n","     14        \u001b[36m1.0140\u001b[0m       \u001b[32m0.6080\u001b[0m        \u001b[35m1.1175\u001b[0m  1.6203\n","     15        \u001b[36m1.0058\u001b[0m       \u001b[32m0.6088\u001b[0m        \u001b[35m1.1143\u001b[0m  2.0217\n","     16        \u001b[36m0.9984\u001b[0m       0.6064        \u001b[35m1.1115\u001b[0m  2.2351\n","     17        \u001b[36m0.9916\u001b[0m       \u001b[32m0.6232\u001b[0m        \u001b[35m1.1087\u001b[0m  1.6295\n","     18        \u001b[36m0.9853\u001b[0m       0.6184        \u001b[35m1.1068\u001b[0m  1.5952\n","     19        \u001b[36m0.9795\u001b[0m       0.6196        \u001b[35m1.1053\u001b[0m  1.5930\n","     20        \u001b[36m0.9740\u001b[0m       0.6212        \u001b[35m1.1035\u001b[0m  1.5946\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.622 total time=  36.3s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m4.4681\u001b[0m       \u001b[32m0.0400\u001b[0m        \u001b[35m3.2235\u001b[0m  1.6564\n","      2        \u001b[36m3.2309\u001b[0m       0.0400        3.2238  2.3635\n","      3        3.2318       0.0400        3.2241  1.9413\n","      4        3.2323       0.0400        3.2242  1.6635\n","      5        3.2326       0.0400        3.2243  1.6583\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  11.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m5.2557\u001b[0m       \u001b[32m0.0400\u001b[0m        \u001b[35m3.2232\u001b[0m  1.7336\n","      2        \u001b[36m3.2322\u001b[0m       0.0400        3.2233  1.9105\n","      3        3.2329       0.0400        3.2235  2.5135\n","      4        3.2334       0.0400        3.2237  1.6892\n","      5        3.2337       0.0400        3.2238  1.7222\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  13.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m4.2493\u001b[0m       \u001b[32m0.0400\u001b[0m        \u001b[35m3.2267\u001b[0m  1.7263\n","      2        \u001b[36m3.2319\u001b[0m       0.0400        3.2273  2.0908\n","      3        3.2326       0.0400        3.2280  2.2876\n","      4        3.2330       0.0400        3.2283  1.6620\n","      5        3.2332       0.0400        3.2286  1.6530\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  12.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9784\u001b[0m       \u001b[32m0.1448\u001b[0m        \u001b[35m2.7974\u001b[0m  1.4345\n","      2        \u001b[36m2.4538\u001b[0m       \u001b[32m0.2104\u001b[0m        \u001b[35m2.2838\u001b[0m  1.4244\n","      3        \u001b[36m1.9578\u001b[0m       \u001b[32m0.3148\u001b[0m        \u001b[35m1.9599\u001b[0m  1.8668\n","      4        \u001b[36m1.6673\u001b[0m       \u001b[32m0.3896\u001b[0m        \u001b[35m1.7101\u001b[0m  2.0193\n","      5        \u001b[36m1.4509\u001b[0m       \u001b[32m0.4728\u001b[0m        \u001b[35m1.5050\u001b[0m  1.4754\n","      6        \u001b[36m1.3107\u001b[0m       \u001b[32m0.5188\u001b[0m        \u001b[35m1.3890\u001b[0m  1.4576\n","      7        \u001b[36m1.2320\u001b[0m       \u001b[32m0.5356\u001b[0m        \u001b[35m1.3220\u001b[0m  1.4576\n","      8        \u001b[36m1.1831\u001b[0m       \u001b[32m0.5488\u001b[0m        \u001b[35m1.2789\u001b[0m  1.4542\n","      9        \u001b[36m1.1488\u001b[0m       \u001b[32m0.5680\u001b[0m        \u001b[35m1.2496\u001b[0m  1.4454\n","     10        \u001b[36m1.1227\u001b[0m       \u001b[32m0.5744\u001b[0m        \u001b[35m1.2258\u001b[0m  1.4495\n","     11        \u001b[36m1.1016\u001b[0m       \u001b[32m0.5812\u001b[0m        \u001b[35m1.2049\u001b[0m  1.8927\n","     12        \u001b[36m1.0837\u001b[0m       \u001b[32m0.5904\u001b[0m        \u001b[35m1.1877\u001b[0m  2.0431\n","     13        \u001b[36m1.0685\u001b[0m       \u001b[32m0.5940\u001b[0m        \u001b[35m1.1720\u001b[0m  1.4169\n","     14        \u001b[36m1.0553\u001b[0m       \u001b[32m0.5972\u001b[0m        \u001b[35m1.1592\u001b[0m  1.5178\n","     15        \u001b[36m1.0439\u001b[0m       \u001b[32m0.5980\u001b[0m        \u001b[35m1.1473\u001b[0m  1.4368\n","     16        \u001b[36m1.0338\u001b[0m       0.5980        \u001b[35m1.1383\u001b[0m  1.4390\n","     17        \u001b[36m1.0247\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m1.1306\u001b[0m  1.4695\n","     18        \u001b[36m1.0167\u001b[0m       \u001b[32m0.6032\u001b[0m        \u001b[35m1.1250\u001b[0m  1.4160\n","     19        \u001b[36m1.0093\u001b[0m       \u001b[32m0.6040\u001b[0m        \u001b[35m1.1196\u001b[0m  1.8433\n","     20        \u001b[36m1.0026\u001b[0m       \u001b[32m0.6048\u001b[0m        \u001b[35m1.1145\u001b[0m  2.0661\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.604 total time=  32.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9911\u001b[0m       \u001b[32m0.1100\u001b[0m        \u001b[35m2.8258\u001b[0m  1.4538\n","      2        \u001b[36m2.5272\u001b[0m       \u001b[32m0.1852\u001b[0m        \u001b[35m2.3522\u001b[0m  1.4460\n","      3        \u001b[36m2.0159\u001b[0m       \u001b[32m0.3040\u001b[0m        \u001b[35m1.9593\u001b[0m  1.4130\n","      4        \u001b[36m1.6858\u001b[0m       \u001b[32m0.4080\u001b[0m        \u001b[35m1.6669\u001b[0m  1.4953\n","      5        \u001b[36m1.4508\u001b[0m       \u001b[32m0.4824\u001b[0m        \u001b[35m1.4727\u001b[0m  1.5193\n","      6        \u001b[36m1.3103\u001b[0m       \u001b[32m0.5248\u001b[0m        \u001b[35m1.3749\u001b[0m  1.4985\n","      7        \u001b[36m1.2332\u001b[0m       \u001b[32m0.5392\u001b[0m        \u001b[35m1.3209\u001b[0m  2.3210\n","      8        \u001b[36m1.1840\u001b[0m       \u001b[32m0.5512\u001b[0m        \u001b[35m1.2808\u001b[0m  1.5233\n","      9        \u001b[36m1.1487\u001b[0m       \u001b[32m0.5612\u001b[0m        \u001b[35m1.2495\u001b[0m  1.4676\n","     10        \u001b[36m1.1221\u001b[0m       \u001b[32m0.5864\u001b[0m        \u001b[35m1.2236\u001b[0m  1.4497\n","     11        \u001b[36m1.1011\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.2028\u001b[0m  1.4631\n","     12        \u001b[36m1.0835\u001b[0m       \u001b[32m0.5968\u001b[0m        \u001b[35m1.1845\u001b[0m  1.4948\n","     13        \u001b[36m1.0688\u001b[0m       \u001b[32m0.6012\u001b[0m        \u001b[35m1.1697\u001b[0m  1.4565\n","     14        \u001b[36m1.0561\u001b[0m       \u001b[32m0.6028\u001b[0m        \u001b[35m1.1569\u001b[0m  1.4712\n","     15        \u001b[36m1.0453\u001b[0m       \u001b[32m0.6084\u001b[0m        \u001b[35m1.1468\u001b[0m  2.3005\n","     16        \u001b[36m1.0356\u001b[0m       \u001b[32m0.6108\u001b[0m        \u001b[35m1.1375\u001b[0m  1.5704\n","     17        \u001b[36m1.0270\u001b[0m       \u001b[32m0.6128\u001b[0m        \u001b[35m1.1296\u001b[0m  1.4781\n","     18        \u001b[36m1.0195\u001b[0m       \u001b[32m0.6140\u001b[0m        \u001b[35m1.1238\u001b[0m  1.4190\n","     19        \u001b[36m1.0127\u001b[0m       \u001b[32m0.6148\u001b[0m        \u001b[35m1.1192\u001b[0m  1.4568\n","     20        \u001b[36m1.0066\u001b[0m       \u001b[32m0.6160\u001b[0m        \u001b[35m1.1154\u001b[0m  1.5125\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.605 total time=  32.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9881\u001b[0m       \u001b[32m0.1800\u001b[0m        \u001b[35m2.7909\u001b[0m  1.4491\n","      2        \u001b[36m2.5271\u001b[0m       \u001b[32m0.2964\u001b[0m        \u001b[35m2.2598\u001b[0m  1.9608\n","      3        \u001b[36m2.0160\u001b[0m       \u001b[32m0.4120\u001b[0m        \u001b[35m1.8615\u001b[0m  1.9613\n","      4        \u001b[36m1.6940\u001b[0m       \u001b[32m0.4960\u001b[0m        \u001b[35m1.6037\u001b[0m  1.4414\n","      5        \u001b[36m1.4704\u001b[0m       \u001b[32m0.5324\u001b[0m        \u001b[35m1.4156\u001b[0m  1.4563\n","      6        \u001b[36m1.3242\u001b[0m       \u001b[32m0.5472\u001b[0m        \u001b[35m1.3126\u001b[0m  1.4327\n","      7        \u001b[36m1.2427\u001b[0m       \u001b[32m0.5660\u001b[0m        \u001b[35m1.2589\u001b[0m  1.4670\n","      8        \u001b[36m1.1935\u001b[0m       \u001b[32m0.5832\u001b[0m        \u001b[35m1.2261\u001b[0m  1.4536\n","      9        \u001b[36m1.1592\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m1.2043\u001b[0m  1.4373\n","     10        \u001b[36m1.1333\u001b[0m       \u001b[32m0.5928\u001b[0m        \u001b[35m1.1873\u001b[0m  1.9454\n","     11        \u001b[36m1.1124\u001b[0m       0.5920        \u001b[35m1.1736\u001b[0m  2.0112\n","     12        \u001b[36m1.0946\u001b[0m       \u001b[32m0.5952\u001b[0m        \u001b[35m1.1615\u001b[0m  1.4584\n","     13        \u001b[36m1.0792\u001b[0m       \u001b[32m0.6004\u001b[0m        \u001b[35m1.1511\u001b[0m  1.4723\n","     14        \u001b[36m1.0655\u001b[0m       0.6000        \u001b[35m1.1415\u001b[0m  1.4648\n","     15        \u001b[36m1.0532\u001b[0m       \u001b[32m0.6056\u001b[0m        \u001b[35m1.1334\u001b[0m  1.5046\n","     16        \u001b[36m1.0423\u001b[0m       \u001b[32m0.6072\u001b[0m        \u001b[35m1.1265\u001b[0m  1.4951\n","     17        \u001b[36m1.0325\u001b[0m       \u001b[32m0.6084\u001b[0m        \u001b[35m1.1202\u001b[0m  1.4304\n","     18        \u001b[36m1.0237\u001b[0m       \u001b[32m0.6108\u001b[0m        \u001b[35m1.1159\u001b[0m  1.9842\n","     19        \u001b[36m1.0159\u001b[0m       \u001b[32m0.6248\u001b[0m        \u001b[35m1.1118\u001b[0m  1.9769\n","     20        \u001b[36m1.0086\u001b[0m       \u001b[32m0.6296\u001b[0m        \u001b[35m1.1086\u001b[0m  1.4434\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.619 total time=  33.2s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.1547\u001b[0m       \u001b[32m0.1072\u001b[0m        \u001b[35m2.6841\u001b[0m  1.5455\n","      2        \u001b[36m2.7198\u001b[0m       0.1008        2.7489  1.4775\n","      3        2.8867       \u001b[32m0.1096\u001b[0m        2.7523  1.4852\n","      4        \u001b[36m2.7123\u001b[0m       0.0652        2.9924  1.5190\n","      5        3.0986       0.0728        2.8544  1.7741\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.085 total time=  10.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9904\u001b[0m       \u001b[32m0.0908\u001b[0m        \u001b[35m2.9661\u001b[0m  1.4695\n","      2        \u001b[36m2.9099\u001b[0m       0.0896        \u001b[35m2.8451\u001b[0m  1.5284\n","      3        \u001b[36m2.8616\u001b[0m       0.0860        \u001b[35m2.8098\u001b[0m  1.4716\n","      4        2.8697       \u001b[32m0.0980\u001b[0m        \u001b[35m2.7670\u001b[0m  1.4984\n","      5        \u001b[36m2.8468\u001b[0m       0.0844        2.8086  1.4930\n","      6        \u001b[36m2.8318\u001b[0m       0.0844        2.9106  1.4962\n","      7        2.8487       0.0976        \u001b[35m2.7451\u001b[0m  2.3895\n","      8        \u001b[36m2.8041\u001b[0m       0.0876        2.7796  1.6520\n","      9        \u001b[36m2.7932\u001b[0m       0.0864        2.7652  1.4957\n","     10        2.8044       0.0952        \u001b[35m2.7291\u001b[0m  1.4872\n","     11        \u001b[36m2.7761\u001b[0m       \u001b[32m0.1084\u001b[0m        \u001b[35m2.7079\u001b[0m  1.5303\n","     12        \u001b[36m2.7407\u001b[0m       0.0920        2.7626  1.4986\n","     13        \u001b[36m2.7261\u001b[0m       0.0796        2.8727  1.5185\n","     14        2.7889       \u001b[32m0.1128\u001b[0m        2.7383  1.7381\n","     15        \u001b[36m2.7084\u001b[0m       0.0852        2.7314  2.2824\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.103 total time=  26.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.2316\u001b[0m       \u001b[32m0.0776\u001b[0m        \u001b[35m2.7510\u001b[0m  1.5396\n","      2        \u001b[36m2.7911\u001b[0m       \u001b[32m0.0924\u001b[0m        2.7819  1.4569\n","      3        \u001b[36m2.6768\u001b[0m       0.0448        6.1572  1.5289\n","      4        3.3464       0.0400        3.2275  1.5414\n","      5        3.2326       0.0400        3.2279  1.5579\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=5, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  11.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9510\u001b[0m       \u001b[32m0.1152\u001b[0m        \u001b[35m2.8423\u001b[0m  1.5472\n","      2        \u001b[36m2.2918\u001b[0m       \u001b[32m0.1912\u001b[0m        \u001b[35m2.3922\u001b[0m  1.6187\n","      3        \u001b[36m1.7710\u001b[0m       \u001b[32m0.2532\u001b[0m        \u001b[35m2.0936\u001b[0m  1.6039\n","      4        \u001b[36m1.5158\u001b[0m       \u001b[32m0.3568\u001b[0m        \u001b[35m1.7646\u001b[0m  1.6081\n","      5        \u001b[36m1.3440\u001b[0m       \u001b[32m0.4436\u001b[0m        \u001b[35m1.5843\u001b[0m  1.6159\n","      6        \u001b[36m1.2418\u001b[0m       \u001b[32m0.4776\u001b[0m        \u001b[35m1.4795\u001b[0m  1.8985\n","      7        \u001b[36m1.1817\u001b[0m       \u001b[32m0.5048\u001b[0m        \u001b[35m1.4088\u001b[0m  2.2600\n","      8        \u001b[36m1.1410\u001b[0m       \u001b[32m0.5328\u001b[0m        \u001b[35m1.3528\u001b[0m  1.5395\n","      9        \u001b[36m1.1104\u001b[0m       \u001b[32m0.5476\u001b[0m        \u001b[35m1.3029\u001b[0m  1.5398\n","     10        \u001b[36m1.0856\u001b[0m       \u001b[32m0.5600\u001b[0m        \u001b[35m1.2623\u001b[0m  1.5519\n","     11        \u001b[36m1.0649\u001b[0m       \u001b[32m0.5724\u001b[0m        \u001b[35m1.2279\u001b[0m  1.5519\n","     12        \u001b[36m1.0471\u001b[0m       \u001b[32m0.5784\u001b[0m        \u001b[35m1.2024\u001b[0m  1.5362\n","     13        \u001b[36m1.0318\u001b[0m       \u001b[32m0.5840\u001b[0m        \u001b[35m1.1818\u001b[0m  1.5623\n","     14        \u001b[36m1.0186\u001b[0m       \u001b[32m0.5892\u001b[0m        \u001b[35m1.1664\u001b[0m  2.2723\n","     15        \u001b[36m1.0070\u001b[0m       \u001b[32m0.5912\u001b[0m        \u001b[35m1.1544\u001b[0m  1.8351\n","     16        \u001b[36m0.9966\u001b[0m       \u001b[32m0.5924\u001b[0m        \u001b[35m1.1452\u001b[0m  1.5953\n","     17        \u001b[36m0.9873\u001b[0m       \u001b[32m0.5936\u001b[0m        \u001b[35m1.1397\u001b[0m  2.5111\n","     18        \u001b[36m0.9789\u001b[0m       \u001b[32m0.5960\u001b[0m        \u001b[35m1.1346\u001b[0m  1.6604\n","     19        \u001b[36m0.9712\u001b[0m       \u001b[32m0.5992\u001b[0m        \u001b[35m1.1309\u001b[0m  1.6134\n","     20        \u001b[36m0.9641\u001b[0m       \u001b[32m0.6008\u001b[0m        \u001b[35m1.1265\u001b[0m  1.5781\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.606 total time=  35.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9247\u001b[0m       \u001b[32m0.1252\u001b[0m        \u001b[35m2.8708\u001b[0m  2.0851\n","      2        \u001b[36m2.3679\u001b[0m       \u001b[32m0.1908\u001b[0m        \u001b[35m2.4042\u001b[0m  1.5802\n","      3        \u001b[36m1.8047\u001b[0m       \u001b[32m0.2828\u001b[0m        \u001b[35m2.0097\u001b[0m  1.5339\n","      4        \u001b[36m1.4946\u001b[0m       \u001b[32m0.3680\u001b[0m        \u001b[35m1.7579\u001b[0m  1.5665\n","      5        \u001b[36m1.3171\u001b[0m       \u001b[32m0.4572\u001b[0m        \u001b[35m1.5716\u001b[0m  1.5628\n","      6        \u001b[36m1.2214\u001b[0m       \u001b[32m0.5052\u001b[0m        \u001b[35m1.4225\u001b[0m  1.5966\n","      7        \u001b[36m1.1654\u001b[0m       \u001b[32m0.5372\u001b[0m        \u001b[35m1.3183\u001b[0m  1.5712\n","      8        \u001b[36m1.1280\u001b[0m       \u001b[32m0.5604\u001b[0m        \u001b[35m1.2495\u001b[0m  2.5100\n","      9        \u001b[36m1.1001\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.2061\u001b[0m  1.6229\n","     10        \u001b[36m1.0778\u001b[0m       \u001b[32m0.5968\u001b[0m        \u001b[35m1.1789\u001b[0m  1.5746\n","     11        \u001b[36m1.0588\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m1.1586\u001b[0m  1.6210\n","     12        \u001b[36m1.0429\u001b[0m       \u001b[32m0.6028\u001b[0m        \u001b[35m1.1453\u001b[0m  1.5550\n","     13        \u001b[36m1.0293\u001b[0m       \u001b[32m0.6080\u001b[0m        \u001b[35m1.1351\u001b[0m  1.5684\n","     14        \u001b[36m1.0174\u001b[0m       \u001b[32m0.6108\u001b[0m        \u001b[35m1.1279\u001b[0m  1.6134\n","     15        \u001b[36m1.0070\u001b[0m       \u001b[32m0.6128\u001b[0m        \u001b[35m1.1208\u001b[0m  2.1848\n","     16        \u001b[36m0.9977\u001b[0m       \u001b[32m0.6136\u001b[0m        \u001b[35m1.1165\u001b[0m  1.9496\n","     17        \u001b[36m0.9892\u001b[0m       \u001b[32m0.6176\u001b[0m        \u001b[35m1.1121\u001b[0m  1.5579\n","     18        \u001b[36m0.9814\u001b[0m       \u001b[32m0.6180\u001b[0m        \u001b[35m1.1089\u001b[0m  1.5805\n","     19        \u001b[36m0.9743\u001b[0m       \u001b[32m0.6232\u001b[0m        \u001b[35m1.1065\u001b[0m  1.6032\n","     20        \u001b[36m0.9674\u001b[0m       0.6232        \u001b[35m1.1047\u001b[0m  1.5582\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.607 total time=  34.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9370\u001b[0m       \u001b[32m0.1772\u001b[0m        \u001b[35m2.7186\u001b[0m  1.5611\n","      2        \u001b[36m2.3580\u001b[0m       \u001b[32m0.2648\u001b[0m        \u001b[35m2.1581\u001b[0m  2.2956\n","      3        \u001b[36m1.8104\u001b[0m       \u001b[32m0.3948\u001b[0m        \u001b[35m1.7734\u001b[0m  1.9700\n","      4        \u001b[36m1.5155\u001b[0m       \u001b[32m0.4960\u001b[0m        \u001b[35m1.5357\u001b[0m  1.5940\n","      5        \u001b[36m1.3372\u001b[0m       \u001b[32m0.5144\u001b[0m        \u001b[35m1.3989\u001b[0m  1.5649\n","      6        \u001b[36m1.2334\u001b[0m       \u001b[32m0.5404\u001b[0m        \u001b[35m1.3073\u001b[0m  1.6123\n","      7        \u001b[36m1.1743\u001b[0m       \u001b[32m0.5608\u001b[0m        \u001b[35m1.2417\u001b[0m  1.5839\n","      8        \u001b[36m1.1347\u001b[0m       \u001b[32m0.5840\u001b[0m        \u001b[35m1.1975\u001b[0m  1.5905\n","      9        \u001b[36m1.1052\u001b[0m       \u001b[32m0.5980\u001b[0m        \u001b[35m1.1722\u001b[0m  1.9908\n","     10        \u001b[36m1.0816\u001b[0m       0.5972        \u001b[35m1.1557\u001b[0m  2.2384\n","     11        \u001b[36m1.0619\u001b[0m       0.5932        \u001b[35m1.1444\u001b[0m  1.5673\n","     12        \u001b[36m1.0452\u001b[0m       0.5924        \u001b[35m1.1362\u001b[0m  1.5933\n","     13        \u001b[36m1.0308\u001b[0m       0.5940        \u001b[35m1.1303\u001b[0m  1.6193\n","     14        \u001b[36m1.0183\u001b[0m       0.5952        \u001b[35m1.1253\u001b[0m  1.5968\n","     15        \u001b[36m1.0074\u001b[0m       0.5964        \u001b[35m1.1216\u001b[0m  1.5837\n","     16        \u001b[36m0.9977\u001b[0m       \u001b[32m0.6116\u001b[0m        \u001b[35m1.1181\u001b[0m  1.6540\n","     17        \u001b[36m0.9889\u001b[0m       \u001b[32m0.6200\u001b[0m        \u001b[35m1.1153\u001b[0m  2.5141\n","     18        \u001b[36m0.9809\u001b[0m       0.6156        \u001b[35m1.1129\u001b[0m  1.5571\n","     19        \u001b[36m0.9735\u001b[0m       0.6152        \u001b[35m1.1107\u001b[0m  1.5949\n","     20        \u001b[36m0.9667\u001b[0m       0.6160        \u001b[35m1.1089\u001b[0m  1.6165\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.619 total time=  35.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m5.4331\u001b[0m       \u001b[32m0.1060\u001b[0m        \u001b[35m2.5452\u001b[0m  1.6738\n","      2        \u001b[36m2.4160\u001b[0m       \u001b[32m0.1716\u001b[0m        \u001b[35m2.3548\u001b[0m  1.6557\n","      3        \u001b[36m2.2744\u001b[0m       \u001b[32m0.1964\u001b[0m        \u001b[35m2.2331\u001b[0m  2.0690\n","      4        \u001b[36m2.1863\u001b[0m       \u001b[32m0.2312\u001b[0m        \u001b[35m2.1462\u001b[0m  2.3321\n","      5        \u001b[36m2.1443\u001b[0m       0.2100        2.1768  1.7196\n","      6        2.2234       0.1788        2.9176  1.6644\n","      7        2.1771       0.2140        2.2546  1.6727\n","      8        \u001b[36m2.0944\u001b[0m       0.2188        2.1585  1.6517\n","      9        2.1098       0.1868        2.2151  1.6450\n","     10        \u001b[36m2.0916\u001b[0m       \u001b[32m0.2616\u001b[0m        \u001b[35m2.1359\u001b[0m  2.2682\n","     11        2.1230       0.2432        \u001b[35m2.0670\u001b[0m  2.4217\n","     12        2.1364       \u001b[32m0.2656\u001b[0m        2.0834  1.8358\n","     13        \u001b[36m2.0416\u001b[0m       \u001b[32m0.3232\u001b[0m        \u001b[35m1.9997\u001b[0m  1.8958\n","     14        \u001b[36m1.9824\u001b[0m       0.2880        2.0505  1.8340\n","     15        \u001b[36m1.9774\u001b[0m       0.2952        2.2261  1.8126\n","     16        2.1022       0.2632        2.1334  2.0120\n","     17        2.0438       0.2920        2.0054  2.6490\n","     18        1.9985       0.3168        \u001b[35m1.9670\u001b[0m  1.8472\n","     19        \u001b[36m1.9580\u001b[0m       0.2860        2.0158  1.8901\n","     20        \u001b[36m1.8973\u001b[0m       0.2868        2.0875  1.8180\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.296 total time=  39.3s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m5.0123\u001b[0m       \u001b[32m0.1280\u001b[0m        \u001b[35m2.5659\u001b[0m  1.6730\n","      2        \u001b[36m2.5970\u001b[0m       \u001b[32m0.1484\u001b[0m        2.6108  1.7238\n","      3        \u001b[36m2.5698\u001b[0m       0.1344        2.5816  2.6002\n","      4        \u001b[36m2.5544\u001b[0m       \u001b[32m0.1672\u001b[0m        \u001b[35m2.5495\u001b[0m  1.6957\n","      5        2.6053       0.1524        2.5594  1.6522\n","      6        \u001b[36m2.5480\u001b[0m       0.1404        2.5736  1.6927\n","      7        \u001b[36m2.5189\u001b[0m       0.1368        \u001b[35m2.5405\u001b[0m  1.6701\n","      8        \u001b[36m2.5017\u001b[0m       0.1424        \u001b[35m2.5346\u001b[0m  1.6847\n","      9        2.5268       0.1480        \u001b[35m2.5146\u001b[0m  1.7433\n","     10        2.5505       0.1544        2.5640  2.7459\n","     11        2.5560       0.1636        2.5317  1.9030\n","     12        2.5416       0.1560        2.5232  1.9006\n","     13        \u001b[36m2.4995\u001b[0m       0.1600        \u001b[35m2.5061\u001b[0m  1.8708\n","     14        \u001b[36m2.4839\u001b[0m       0.1548        \u001b[35m2.4986\u001b[0m  1.8080\n","     15        \u001b[36m2.4751\u001b[0m       0.1460        \u001b[35m2.4978\u001b[0m  1.8574\n","     16        2.4844       0.1656        \u001b[35m2.4905\u001b[0m  2.5426\n","     17        2.5163       0.1476        2.5481  2.0215\n","     18        2.5137       0.1492        2.5635  1.8583\n","     19        2.5265       0.1588        2.4911  1.8327\n","     20        2.5421       0.1168        2.6909  1.9150\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.119 total time=  39.3s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m5.5402\u001b[0m       \u001b[32m0.0488\u001b[0m        \u001b[35m3.1967\u001b[0m  1.6793\n","      2        \u001b[36m3.1071\u001b[0m       \u001b[32m0.0692\u001b[0m        \u001b[35m3.0703\u001b[0m  2.3707\n","      3        \u001b[36m3.0763\u001b[0m       0.0468        3.0886  2.0065\n","      4        3.1008       0.0636        3.0905  1.6692\n","      5        \u001b[36m3.0711\u001b[0m       0.0624        \u001b[35m3.0684\u001b[0m  1.6451\n","      6        \u001b[36m3.0655\u001b[0m       0.0628        3.0786  1.6436\n","      7        3.0675       0.0664        \u001b[35m3.0635\u001b[0m  1.6356\n","      8        \u001b[36m3.0498\u001b[0m       0.0668        \u001b[35m3.0465\u001b[0m  1.6642\n","      9        \u001b[36m3.0453\u001b[0m       0.0688        3.0557  2.3726\n","     10        \u001b[36m3.0212\u001b[0m       \u001b[32m0.0716\u001b[0m        \u001b[35m3.0375\u001b[0m  2.1476\n","     11        \u001b[36m3.0117\u001b[0m       0.0672        \u001b[35m3.0124\u001b[0m  1.9530\n","     12        3.0131       \u001b[32m0.0772\u001b[0m        \u001b[35m2.9732\u001b[0m  1.8276\n","     13        \u001b[36m2.9043\u001b[0m       0.0768        \u001b[35m2.9011\u001b[0m  1.8417\n","     14        \u001b[36m2.8236\u001b[0m       \u001b[32m0.1060\u001b[0m        \u001b[35m2.7833\u001b[0m  1.7945\n","     15        \u001b[36m2.8057\u001b[0m       \u001b[32m0.1280\u001b[0m        2.9088  2.0956\n","     16        \u001b[36m2.8016\u001b[0m       0.0864        \u001b[35m2.7608\u001b[0m  3.0999\n","     17        \u001b[36m2.7780\u001b[0m       0.0896        2.7944  2.2812\n","     18        \u001b[36m2.7532\u001b[0m       0.1036        2.8120  1.8444\n","     19        2.7833       0.1184        2.7675  1.8240\n","     20        \u001b[36m2.7303\u001b[0m       0.1232        \u001b[35m2.7583\u001b[0m  1.8287\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.124 total time=  40.2s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0130\u001b[0m       \u001b[32m0.1108\u001b[0m        \u001b[35m2.9025\u001b[0m  1.7591\n","      2        \u001b[36m2.6936\u001b[0m       \u001b[32m0.1724\u001b[0m        \u001b[35m2.6180\u001b[0m  2.1667\n","      3        \u001b[36m2.2163\u001b[0m       \u001b[32m0.2024\u001b[0m        \u001b[35m2.2651\u001b[0m  1.4702\n","      4        \u001b[36m1.8482\u001b[0m       \u001b[32m0.2916\u001b[0m        \u001b[35m1.9608\u001b[0m  1.4680\n","      5        \u001b[36m1.6062\u001b[0m       \u001b[32m0.3812\u001b[0m        \u001b[35m1.7009\u001b[0m  1.4306\n","      6        \u001b[36m1.4305\u001b[0m       \u001b[32m0.4512\u001b[0m        \u001b[35m1.5361\u001b[0m  1.4839\n","      7        \u001b[36m1.3224\u001b[0m       \u001b[32m0.4836\u001b[0m        \u001b[35m1.4559\u001b[0m  1.4618\n","      8        \u001b[36m1.2555\u001b[0m       \u001b[32m0.5100\u001b[0m        \u001b[35m1.4039\u001b[0m  1.4936\n","      9        \u001b[36m1.2097\u001b[0m       \u001b[32m0.5236\u001b[0m        \u001b[35m1.3661\u001b[0m  1.7683\n","     10        \u001b[36m1.1744\u001b[0m       \u001b[32m0.5416\u001b[0m        \u001b[35m1.3365\u001b[0m  2.1740\n","     11        \u001b[36m1.1459\u001b[0m       \u001b[32m0.5484\u001b[0m        \u001b[35m1.3100\u001b[0m  1.3907\n","     12        \u001b[36m1.1222\u001b[0m       \u001b[32m0.5568\u001b[0m        \u001b[35m1.2836\u001b[0m  1.4193\n","     13        \u001b[36m1.1023\u001b[0m       \u001b[32m0.5652\u001b[0m        \u001b[35m1.2538\u001b[0m  1.4703\n","     14        \u001b[36m1.0855\u001b[0m       \u001b[32m0.5724\u001b[0m        \u001b[35m1.2311\u001b[0m  1.4488\n","     15        \u001b[36m1.0708\u001b[0m       \u001b[32m0.5796\u001b[0m        \u001b[35m1.2104\u001b[0m  1.4473\n","     16        \u001b[36m1.0578\u001b[0m       \u001b[32m0.5824\u001b[0m        \u001b[35m1.1951\u001b[0m  1.4163\n","     17        \u001b[36m1.0465\u001b[0m       \u001b[32m0.5864\u001b[0m        \u001b[35m1.1819\u001b[0m  1.6275\n","     18        \u001b[36m1.0364\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.1692\u001b[0m  2.2742\n","     19        \u001b[36m1.0272\u001b[0m       \u001b[32m0.5916\u001b[0m        \u001b[35m1.1599\u001b[0m  1.4872\n","     20        \u001b[36m1.0189\u001b[0m       \u001b[32m0.5936\u001b[0m        \u001b[35m1.1533\u001b[0m  1.4869\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.597 total time=  33.0s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0189\u001b[0m       \u001b[32m0.0728\u001b[0m        \u001b[35m2.8792\u001b[0m  1.4600\n","      2        \u001b[36m2.5932\u001b[0m       \u001b[32m0.1752\u001b[0m        \u001b[35m2.5317\u001b[0m  1.4562\n","      3        \u001b[36m2.0869\u001b[0m       \u001b[32m0.2236\u001b[0m        \u001b[35m2.2054\u001b[0m  1.4719\n","      4        \u001b[36m1.7757\u001b[0m       \u001b[32m0.2972\u001b[0m        \u001b[35m1.9146\u001b[0m  1.4783\n","      5        \u001b[36m1.5657\u001b[0m       \u001b[32m0.3856\u001b[0m        \u001b[35m1.6946\u001b[0m  2.1650\n","      6        \u001b[36m1.4034\u001b[0m       \u001b[32m0.4608\u001b[0m        \u001b[35m1.5429\u001b[0m  1.8281\n","      7        \u001b[36m1.2997\u001b[0m       \u001b[32m0.5004\u001b[0m        \u001b[35m1.4437\u001b[0m  1.4260\n","      8        \u001b[36m1.2360\u001b[0m       \u001b[32m0.5240\u001b[0m        \u001b[35m1.3769\u001b[0m  1.4484\n","      9        \u001b[36m1.1925\u001b[0m       \u001b[32m0.5388\u001b[0m        \u001b[35m1.3248\u001b[0m  1.4588\n","     10        \u001b[36m1.1591\u001b[0m       \u001b[32m0.5532\u001b[0m        \u001b[35m1.2811\u001b[0m  1.4369\n","     11        \u001b[36m1.1324\u001b[0m       \u001b[32m0.5632\u001b[0m        \u001b[35m1.2462\u001b[0m  1.4398\n","     12        \u001b[36m1.1102\u001b[0m       \u001b[32m0.5868\u001b[0m        \u001b[35m1.2199\u001b[0m  1.4839\n","     13        \u001b[36m1.0918\u001b[0m       \u001b[32m0.5908\u001b[0m        \u001b[35m1.1981\u001b[0m  2.1030\n","     14        \u001b[36m1.0760\u001b[0m       \u001b[32m0.5972\u001b[0m        \u001b[35m1.1820\u001b[0m  1.7827\n","     15        \u001b[36m1.0625\u001b[0m       \u001b[32m0.6028\u001b[0m        \u001b[35m1.1693\u001b[0m  1.4463\n","     16        \u001b[36m1.0505\u001b[0m       \u001b[32m0.6052\u001b[0m        \u001b[35m1.1592\u001b[0m  1.4366\n","     17        \u001b[36m1.0400\u001b[0m       \u001b[32m0.6072\u001b[0m        \u001b[35m1.1513\u001b[0m  1.4685\n","     18        \u001b[36m1.0306\u001b[0m       \u001b[32m0.6096\u001b[0m        \u001b[35m1.1446\u001b[0m  1.4807\n","     19        \u001b[36m1.0221\u001b[0m       0.6084        \u001b[35m1.1394\u001b[0m  1.4497\n","     20        \u001b[36m1.0143\u001b[0m       \u001b[32m0.6148\u001b[0m        \u001b[35m1.1348\u001b[0m  1.4375\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.600 total time=  32.2s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0435\u001b[0m       \u001b[32m0.0788\u001b[0m        \u001b[35m2.8880\u001b[0m  2.2705\n","      2        \u001b[36m2.7025\u001b[0m       \u001b[32m0.2048\u001b[0m        \u001b[35m2.5377\u001b[0m  1.4174\n","      3        \u001b[36m2.1961\u001b[0m       \u001b[32m0.2792\u001b[0m        \u001b[35m2.0638\u001b[0m  1.4887\n","      4        \u001b[36m1.8145\u001b[0m       \u001b[32m0.3764\u001b[0m        \u001b[35m1.8085\u001b[0m  1.4393\n","      5        \u001b[36m1.5930\u001b[0m       \u001b[32m0.4248\u001b[0m        \u001b[35m1.6531\u001b[0m  1.4589\n","      6        \u001b[36m1.4327\u001b[0m       \u001b[32m0.4532\u001b[0m        \u001b[35m1.5221\u001b[0m  1.4416\n","      7        \u001b[36m1.3287\u001b[0m       \u001b[32m0.4700\u001b[0m        \u001b[35m1.4409\u001b[0m  1.4198\n","      8        \u001b[36m1.2663\u001b[0m       \u001b[32m0.5060\u001b[0m        \u001b[35m1.3842\u001b[0m  1.5432\n","      9        \u001b[36m1.2237\u001b[0m       \u001b[32m0.5212\u001b[0m        \u001b[35m1.3456\u001b[0m  2.3233\n","     10        \u001b[36m1.1902\u001b[0m       \u001b[32m0.5456\u001b[0m        \u001b[35m1.3135\u001b[0m  1.4999\n","     11        \u001b[36m1.1625\u001b[0m       \u001b[32m0.5556\u001b[0m        \u001b[35m1.2820\u001b[0m  1.4233\n","     12        \u001b[36m1.1382\u001b[0m       \u001b[32m0.5636\u001b[0m        \u001b[35m1.2549\u001b[0m  1.4576\n","     13        \u001b[36m1.1172\u001b[0m       \u001b[32m0.5728\u001b[0m        \u001b[35m1.2318\u001b[0m  1.4553\n","     14        \u001b[36m1.0986\u001b[0m       \u001b[32m0.5780\u001b[0m        \u001b[35m1.2057\u001b[0m  1.4701\n","     15        \u001b[36m1.0817\u001b[0m       \u001b[32m0.5820\u001b[0m        \u001b[35m1.1865\u001b[0m  1.4508\n","     16        \u001b[36m1.0665\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.1721\u001b[0m  1.5406\n","     17        \u001b[36m1.0530\u001b[0m       \u001b[32m0.5912\u001b[0m        \u001b[35m1.1596\u001b[0m  2.3224\n","     18        \u001b[36m1.0409\u001b[0m       \u001b[32m0.5928\u001b[0m        \u001b[35m1.1501\u001b[0m  1.5339\n","     19        \u001b[36m1.0302\u001b[0m       \u001b[32m0.5956\u001b[0m        \u001b[35m1.1436\u001b[0m  1.4459\n","     20        \u001b[36m1.0206\u001b[0m       \u001b[32m0.6012\u001b[0m        \u001b[35m1.1378\u001b[0m  1.4319\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.597 total time=  32.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9938\u001b[0m       \u001b[32m0.2228\u001b[0m        \u001b[35m2.2859\u001b[0m  1.5158\n","      2        \u001b[36m1.9748\u001b[0m       \u001b[32m0.2700\u001b[0m        \u001b[35m2.0118\u001b[0m  1.5265\n","      3        \u001b[36m1.8906\u001b[0m       \u001b[32m0.3296\u001b[0m        \u001b[35m1.9275\u001b[0m  1.4891\n","      4        \u001b[36m1.8181\u001b[0m       0.3096        1.9689  2.1063\n","      5        \u001b[36m1.8014\u001b[0m       \u001b[32m0.3464\u001b[0m        \u001b[35m1.8492\u001b[0m  1.8518\n","      6        \u001b[36m1.7717\u001b[0m       \u001b[32m0.3748\u001b[0m        \u001b[35m1.8462\u001b[0m  1.5125\n","      7        \u001b[36m1.7444\u001b[0m       0.3728        \u001b[35m1.7927\u001b[0m  1.4984\n","      8        1.7509       0.3608        1.8476  1.4706\n","      9        1.7577       0.3692        1.8389  1.4697\n","     10        \u001b[36m1.7412\u001b[0m       \u001b[32m0.3752\u001b[0m        1.8392  1.5419\n","     11        \u001b[36m1.7172\u001b[0m       \u001b[32m0.3788\u001b[0m        1.7939  1.5774\n","     12        1.7599       0.3676        1.8111  2.4359\n","     13        1.7183       \u001b[32m0.3836\u001b[0m        1.8694  1.7277\n","     14        1.7320       0.3832        1.8662  1.5281\n","     15        1.7422       0.3504        1.9517  1.5616\n","     16        1.7889       0.3156        2.1319  1.5338\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.383 total time=  28.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.3369\u001b[0m       \u001b[32m0.1804\u001b[0m        \u001b[35m2.3032\u001b[0m  1.4892\n","      2        \u001b[36m2.2333\u001b[0m       \u001b[32m0.2456\u001b[0m        2.5922  2.2778\n","      3        \u001b[36m2.2051\u001b[0m       0.2220        \u001b[35m2.2096\u001b[0m  1.7126\n","      4        \u001b[36m2.1099\u001b[0m       \u001b[32m0.2492\u001b[0m        \u001b[35m2.0940\u001b[0m  1.4982\n","      5        \u001b[36m2.0476\u001b[0m       0.2208        2.2213  1.4653\n","      6        2.1208       0.2472        2.1224  1.4642\n","      7        \u001b[36m2.0136\u001b[0m       \u001b[32m0.2856\u001b[0m        \u001b[35m2.0207\u001b[0m  1.4710\n","      8        \u001b[36m1.9998\u001b[0m       \u001b[32m0.2868\u001b[0m        2.0714  1.5294\n","      9        2.0116       0.2656        2.0718  1.5174\n","     10        \u001b[36m1.9779\u001b[0m       0.2732        2.0524  2.4500\n","     11        2.0232       \u001b[32m0.2968\u001b[0m        \u001b[35m2.0086\u001b[0m  1.6586\n","     12        \u001b[36m1.9426\u001b[0m       \u001b[32m0.3088\u001b[0m        \u001b[35m1.9952\u001b[0m  1.5426\n","     13        1.9474       0.2904        2.0265  1.5457\n","     14        1.9453       0.2684        2.0546  1.5507\n","     15        \u001b[36m1.9054\u001b[0m       \u001b[32m0.3152\u001b[0m        \u001b[35m1.9050\u001b[0m  1.5471\n","     16        \u001b[36m1.8558\u001b[0m       0.3084        1.9535  1.5185\n","     17        1.8798       0.3116        1.9525  1.9550\n","     18        1.8852       0.3116        1.9408  2.1298\n","     19        1.8583       0.2984        1.9418  1.5491\n","     20        1.9089       0.3088        1.9182  1.5945\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.303 total time=  34.4s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.3916\u001b[0m       \u001b[32m0.1360\u001b[0m        \u001b[35m2.4625\u001b[0m  1.5159\n","      2        \u001b[36m2.4593\u001b[0m       \u001b[32m0.1628\u001b[0m        \u001b[35m2.4250\u001b[0m  1.5452\n","      3        \u001b[36m2.4216\u001b[0m       0.1560        \u001b[35m2.4117\u001b[0m  1.5207\n","      4        2.5004       0.1556        2.4881  1.7586\n","      5        2.4516       0.1388        2.4384  2.2095\n","      6        \u001b[36m2.4077\u001b[0m       0.1580        2.4740  1.4838\n","      7        \u001b[36m2.3915\u001b[0m       0.1616        \u001b[35m2.4040\u001b[0m  1.5248\n","      8        \u001b[36m2.3665\u001b[0m       0.1572        \u001b[35m2.3931\u001b[0m  1.4723\n","      9        \u001b[36m2.3567\u001b[0m       0.1628        2.4482  1.7546\n","     10        \u001b[36m2.3425\u001b[0m       \u001b[32m0.1912\u001b[0m        \u001b[35m2.3425\u001b[0m  2.3326\n","     11        \u001b[36m2.3222\u001b[0m       \u001b[32m0.1936\u001b[0m        2.3609  1.8340\n","     12        2.3352       \u001b[32m0.1948\u001b[0m        2.3527  2.3011\n","     13        2.4104       0.1624        2.5529  1.5459\n","     14        2.3950       0.1416        2.4187  1.5377\n","     15        2.4015       0.1416        2.4153  1.5010\n","     16        2.3650       0.1556        2.4323  1.5332\n","     17        2.3860       0.1364        2.4381  1.5170\n","     18        2.4376       0.1340        2.4672  1.5510\n","     19        2.4147       0.1360        2.4577  2.1420\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function relu at 0x7ffa9858a560>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.137 total time=  35.5s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7632\u001b[0m       \u001b[32m0.1912\u001b[0m        \u001b[35m2.5660\u001b[0m  1.6362\n","      2        \u001b[36m2.0098\u001b[0m       \u001b[32m0.2860\u001b[0m        \u001b[35m1.9672\u001b[0m  1.6045\n","      3        \u001b[36m1.5622\u001b[0m       \u001b[32m0.4248\u001b[0m        \u001b[35m1.6055\u001b[0m  1.5745\n","      4        \u001b[36m1.3328\u001b[0m       \u001b[32m0.5040\u001b[0m        \u001b[35m1.4219\u001b[0m  1.6365\n","      5        \u001b[36m1.2153\u001b[0m       \u001b[32m0.5280\u001b[0m        \u001b[35m1.3315\u001b[0m  1.6441\n","      6        \u001b[36m1.1518\u001b[0m       \u001b[32m0.5504\u001b[0m        \u001b[35m1.2755\u001b[0m  2.4116\n","      7        \u001b[36m1.1118\u001b[0m       \u001b[32m0.5640\u001b[0m        \u001b[35m1.2382\u001b[0m  1.8328\n","      8        \u001b[36m1.0838\u001b[0m       \u001b[32m0.5728\u001b[0m        \u001b[35m1.2115\u001b[0m  1.5807\n","      9        \u001b[36m1.0628\u001b[0m       \u001b[32m0.5804\u001b[0m        \u001b[35m1.1895\u001b[0m  1.6204\n","     10        \u001b[36m1.0463\u001b[0m       \u001b[32m0.5844\u001b[0m        \u001b[35m1.1730\u001b[0m  1.6142\n","     11        \u001b[36m1.0329\u001b[0m       \u001b[32m0.5884\u001b[0m        \u001b[35m1.1600\u001b[0m  1.6260\n","     12        \u001b[36m1.0217\u001b[0m       \u001b[32m0.5928\u001b[0m        \u001b[35m1.1497\u001b[0m  1.6151\n","     13        \u001b[36m1.0120\u001b[0m       \u001b[32m0.5960\u001b[0m        \u001b[35m1.1411\u001b[0m  2.2321\n","     14        \u001b[36m1.0036\u001b[0m       \u001b[32m0.5980\u001b[0m        \u001b[35m1.1345\u001b[0m  2.0212\n","     15        \u001b[36m0.9961\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m1.1292\u001b[0m  1.5792\n","     16        \u001b[36m0.9893\u001b[0m       0.6000        \u001b[35m1.1243\u001b[0m  1.5600\n","     17        \u001b[36m0.9831\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m1.1207\u001b[0m  1.6393\n","     18        \u001b[36m0.9774\u001b[0m       \u001b[32m0.6020\u001b[0m        \u001b[35m1.1181\u001b[0m  1.5956\n","     19        \u001b[36m0.9723\u001b[0m       0.6020        \u001b[35m1.1160\u001b[0m  1.6249\n","     20        \u001b[36m0.9674\u001b[0m       \u001b[32m0.6024\u001b[0m        \u001b[35m1.1144\u001b[0m  1.9913\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.612 total time=  36.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8243\u001b[0m       \u001b[32m0.1704\u001b[0m        \u001b[35m2.6455\u001b[0m  1.7755\n","      2        \u001b[36m2.0672\u001b[0m       \u001b[32m0.2864\u001b[0m        \u001b[35m2.0562\u001b[0m  1.6115\n","      3        \u001b[36m1.5724\u001b[0m       \u001b[32m0.3996\u001b[0m        \u001b[35m1.6545\u001b[0m  1.6280\n","      4        \u001b[36m1.3212\u001b[0m       \u001b[32m0.4912\u001b[0m        \u001b[35m1.4227\u001b[0m  1.6210\n","      5        \u001b[36m1.2053\u001b[0m       \u001b[32m0.5388\u001b[0m        \u001b[35m1.3078\u001b[0m  1.6337\n","      6        \u001b[36m1.1456\u001b[0m       \u001b[32m0.5596\u001b[0m        \u001b[35m1.2426\u001b[0m  1.6422\n","      7        \u001b[36m1.1085\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.2010\u001b[0m  2.2246\n","      8        \u001b[36m1.0824\u001b[0m       \u001b[32m0.5980\u001b[0m        \u001b[35m1.1742\u001b[0m  2.0121\n","      9        \u001b[36m1.0626\u001b[0m       \u001b[32m0.6032\u001b[0m        \u001b[35m1.1553\u001b[0m  1.6142\n","     10        \u001b[36m1.0468\u001b[0m       \u001b[32m0.6060\u001b[0m        \u001b[35m1.1417\u001b[0m  1.6679\n","     11        \u001b[36m1.0338\u001b[0m       \u001b[32m0.6108\u001b[0m        \u001b[35m1.1318\u001b[0m  1.6281\n","     12        \u001b[36m1.0229\u001b[0m       \u001b[32m0.6132\u001b[0m        \u001b[35m1.1246\u001b[0m  1.5965\n","     13        \u001b[36m1.0136\u001b[0m       \u001b[32m0.6152\u001b[0m        \u001b[35m1.1191\u001b[0m  1.7204\n","     14        \u001b[36m1.0053\u001b[0m       \u001b[32m0.6184\u001b[0m        \u001b[35m1.1147\u001b[0m  2.0549\n","     15        \u001b[36m0.9979\u001b[0m       \u001b[32m0.6200\u001b[0m        \u001b[35m1.1111\u001b[0m  2.1738\n","     16        \u001b[36m0.9912\u001b[0m       \u001b[32m0.6224\u001b[0m        \u001b[35m1.1087\u001b[0m  1.6394\n","     17        \u001b[36m0.9851\u001b[0m       \u001b[32m0.6228\u001b[0m        \u001b[35m1.1068\u001b[0m  1.6018\n","     18        \u001b[36m0.9794\u001b[0m       0.6216        \u001b[35m1.1053\u001b[0m  1.6061\n","     19        \u001b[36m0.9743\u001b[0m       \u001b[32m0.6232\u001b[0m        \u001b[35m1.1042\u001b[0m  1.6329\n","     20        \u001b[36m0.9693\u001b[0m       \u001b[32m0.6248\u001b[0m        \u001b[35m1.1041\u001b[0m  1.6161\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.610 total time=  35.6s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.8285\u001b[0m       \u001b[32m0.2208\u001b[0m        \u001b[35m2.5170\u001b[0m  2.2843\n","      2        \u001b[36m2.0939\u001b[0m       \u001b[32m0.3916\u001b[0m        \u001b[35m1.8713\u001b[0m  1.9364\n","      3        \u001b[36m1.5807\u001b[0m       \u001b[32m0.4976\u001b[0m        \u001b[35m1.4920\u001b[0m  1.5979\n","      4        \u001b[36m1.3288\u001b[0m       \u001b[32m0.5588\u001b[0m        \u001b[35m1.3192\u001b[0m  1.6551\n","      5        \u001b[36m1.2152\u001b[0m       \u001b[32m0.5832\u001b[0m        \u001b[35m1.2460\u001b[0m  1.6233\n","      6        \u001b[36m1.1568\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.2067\u001b[0m  1.6121\n","      7        \u001b[36m1.1201\u001b[0m       \u001b[32m0.5928\u001b[0m        \u001b[35m1.1822\u001b[0m  1.6185\n","      8        \u001b[36m1.0935\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.1653\u001b[0m  2.0723\n","      9        \u001b[36m1.0728\u001b[0m       \u001b[32m0.6004\u001b[0m        \u001b[35m1.1524\u001b[0m  2.1444\n","     10        \u001b[36m1.0562\u001b[0m       \u001b[32m0.6080\u001b[0m        \u001b[35m1.1433\u001b[0m  1.6069\n","     11        \u001b[36m1.0423\u001b[0m       0.6080        \u001b[35m1.1361\u001b[0m  1.6755\n","     12        \u001b[36m1.0304\u001b[0m       \u001b[32m0.6084\u001b[0m        \u001b[35m1.1303\u001b[0m  1.5741\n","     13        \u001b[36m1.0202\u001b[0m       0.6072        \u001b[35m1.1254\u001b[0m  1.6086\n","     14        \u001b[36m1.0112\u001b[0m       0.6060        \u001b[35m1.1218\u001b[0m  1.5984\n","     15        \u001b[36m1.0032\u001b[0m       0.6060        \u001b[35m1.1191\u001b[0m  1.7933\n","     16        \u001b[36m0.9960\u001b[0m       0.6076        \u001b[35m1.1166\u001b[0m  2.4030\n","     17        \u001b[36m0.9894\u001b[0m       0.6060        \u001b[35m1.1145\u001b[0m  1.5642\n","     18        \u001b[36m0.9833\u001b[0m       \u001b[32m0.6232\u001b[0m        \u001b[35m1.1130\u001b[0m  1.5763\n","     19        \u001b[36m0.9778\u001b[0m       \u001b[32m0.6248\u001b[0m        \u001b[35m1.1123\u001b[0m  1.5873\n","     20        \u001b[36m0.9726\u001b[0m       0.6196        \u001b[35m1.1113\u001b[0m  1.6587\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.624 total time=  36.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m6.3614\u001b[0m       \u001b[32m0.0400\u001b[0m        \u001b[35m3.2206\u001b[0m  1.6529\n","      2        \u001b[36m3.2286\u001b[0m       0.0400        3.2210  2.1650\n","      3        3.2299       0.0400        3.2215  2.2216\n","      4        3.2307       0.0400        3.2219  1.7284\n","      5        3.2313       0.0400        3.2223  1.6546\n","      6        3.2317       0.0400        3.2225  1.6810\n","      7        3.2321       0.0400        3.2228  1.6431\n","      8        3.2324       0.0400        3.2230  1.7107\n","      9        3.2326       0.0400        3.2232  2.2605\n","     10        3.2328       0.0400        3.2233  2.2804\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  21.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m4.4389\u001b[0m       \u001b[32m0.0400\u001b[0m        \u001b[35m3.2229\u001b[0m  1.7317\n","      2        \u001b[36m3.2325\u001b[0m       0.0400        3.2231  1.6593\n","      3        3.2331       0.0400        3.2234  1.6847\n","      4        3.2335       0.0400        3.2236  2.1698\n","      5        3.2338       0.0400        3.2238  2.2857\n","      6        3.2340       0.0400        3.2239  1.6638\n","      7        3.2342       0.0400        3.2241  1.6678\n","      8        3.2343       0.0400        3.2241  1.7126\n","      9        3.2344       0.0400        3.2242  1.6693\n","     10        3.2345       0.0400        3.2243  1.8240\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  21.8s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m4.6135\u001b[0m       \u001b[32m0.0400\u001b[0m        \u001b[35m3.2272\u001b[0m  1.6410\n","      2        \u001b[36m3.2316\u001b[0m       0.0400        3.2282  1.6507\n","      3        3.2323       0.0400        3.2287  1.7084\n","      4        3.2327       0.0400        3.2291  1.6299\n","      5        3.2330       0.0400        3.2293  1.6870\n","      6        3.2332       0.0400        3.2295  1.8433\n","      7        3.2334       0.0400        3.2296  2.7219\n","      8        3.2335       0.0400        3.2297  2.4946\n","      9        3.2336       0.0400        3.2298  1.6999\n","     10        3.2337       0.0400        3.2299  1.8484\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=800, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  21.7s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9867\u001b[0m       \u001b[32m0.1056\u001b[0m        \u001b[35m2.8252\u001b[0m  1.5129\n","      2        \u001b[36m2.5367\u001b[0m       \u001b[32m0.2012\u001b[0m        \u001b[35m2.3693\u001b[0m  2.1576\n","      3        \u001b[36m2.0464\u001b[0m       \u001b[32m0.3000\u001b[0m        \u001b[35m1.9804\u001b[0m  1.7289\n","      4        \u001b[36m1.7321\u001b[0m       \u001b[32m0.3852\u001b[0m        \u001b[35m1.7292\u001b[0m  1.4761\n","      5        \u001b[36m1.5091\u001b[0m       \u001b[32m0.4660\u001b[0m        \u001b[35m1.5249\u001b[0m  1.4177\n","      6        \u001b[36m1.3547\u001b[0m       \u001b[32m0.5120\u001b[0m        \u001b[35m1.4059\u001b[0m  1.5002\n","      7        \u001b[36m1.2643\u001b[0m       \u001b[32m0.5308\u001b[0m        \u001b[35m1.3380\u001b[0m  1.4317\n","      8        \u001b[36m1.2075\u001b[0m       \u001b[32m0.5480\u001b[0m        \u001b[35m1.2915\u001b[0m  1.4626\n","      9        \u001b[36m1.1674\u001b[0m       \u001b[32m0.5672\u001b[0m        \u001b[35m1.2567\u001b[0m  1.4416\n","     10        \u001b[36m1.1370\u001b[0m       \u001b[32m0.5760\u001b[0m        \u001b[35m1.2298\u001b[0m  2.1421\n","     11        \u001b[36m1.1128\u001b[0m       \u001b[32m0.5816\u001b[0m        \u001b[35m1.2073\u001b[0m  1.8134\n","     12        \u001b[36m1.0930\u001b[0m       \u001b[32m0.5824\u001b[0m        \u001b[35m1.1883\u001b[0m  1.4626\n","     13        \u001b[36m1.0762\u001b[0m       \u001b[32m0.5884\u001b[0m        \u001b[35m1.1729\u001b[0m  1.4521\n","     14        \u001b[36m1.0617\u001b[0m       \u001b[32m0.5944\u001b[0m        \u001b[35m1.1537\u001b[0m  1.4405\n","     15        \u001b[36m1.0489\u001b[0m       \u001b[32m0.5968\u001b[0m        \u001b[35m1.1427\u001b[0m  1.4438\n","     16        \u001b[36m1.0377\u001b[0m       \u001b[32m0.5972\u001b[0m        \u001b[35m1.1343\u001b[0m  1.4529\n","     17        \u001b[36m1.0278\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m1.1275\u001b[0m  1.4413\n","     18        \u001b[36m1.0189\u001b[0m       \u001b[32m0.6012\u001b[0m        \u001b[35m1.1219\u001b[0m  2.0811\n","     19        \u001b[36m1.0110\u001b[0m       \u001b[32m0.6028\u001b[0m        \u001b[35m1.1176\u001b[0m  1.8633\n","     20        \u001b[36m1.0038\u001b[0m       \u001b[32m0.6044\u001b[0m        \u001b[35m1.1136\u001b[0m  1.4382\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.611 total time=  33.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9835\u001b[0m       \u001b[32m0.1216\u001b[0m        \u001b[35m2.8351\u001b[0m  1.4334\n","      2        \u001b[36m2.5449\u001b[0m       \u001b[32m0.2160\u001b[0m        \u001b[35m2.3560\u001b[0m  1.4896\n","      3        \u001b[36m2.0237\u001b[0m       \u001b[32m0.2960\u001b[0m        \u001b[35m1.9703\u001b[0m  1.5100\n","      4        \u001b[36m1.6972\u001b[0m       \u001b[32m0.3872\u001b[0m        \u001b[35m1.6979\u001b[0m  1.4293\n","      5        \u001b[36m1.4727\u001b[0m       \u001b[32m0.4728\u001b[0m        \u001b[35m1.4914\u001b[0m  1.8323\n","      6        \u001b[36m1.3320\u001b[0m       \u001b[32m0.5368\u001b[0m        \u001b[35m1.3720\u001b[0m  2.1622\n","      7        \u001b[36m1.2516\u001b[0m       \u001b[32m0.5568\u001b[0m        \u001b[35m1.3025\u001b[0m  1.4123\n","      8        \u001b[36m1.1985\u001b[0m       \u001b[32m0.5652\u001b[0m        \u001b[35m1.2565\u001b[0m  1.4548\n","      9        \u001b[36m1.1597\u001b[0m       \u001b[32m0.5736\u001b[0m        \u001b[35m1.2215\u001b[0m  1.4520\n","     10        \u001b[36m1.1300\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.1951\u001b[0m  1.4418\n","     11        \u001b[36m1.1063\u001b[0m       \u001b[32m0.6052\u001b[0m        \u001b[35m1.1752\u001b[0m  1.4624\n","     12        \u001b[36m1.0869\u001b[0m       \u001b[32m0.6092\u001b[0m        \u001b[35m1.1597\u001b[0m  1.4677\n","     13        \u001b[36m1.0706\u001b[0m       \u001b[32m0.6116\u001b[0m        \u001b[35m1.1476\u001b[0m  1.6905\n","     14        \u001b[36m1.0569\u001b[0m       \u001b[32m0.6144\u001b[0m        \u001b[35m1.1379\u001b[0m  2.2317\n","     15        \u001b[36m1.0451\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m1.1304\u001b[0m  1.4797\n","     16        \u001b[36m1.0348\u001b[0m       \u001b[32m0.6204\u001b[0m        \u001b[35m1.1245\u001b[0m  1.4196\n","     17        \u001b[36m1.0259\u001b[0m       \u001b[32m0.6212\u001b[0m        \u001b[35m1.1203\u001b[0m  1.4207\n","     18        \u001b[36m1.0180\u001b[0m       \u001b[32m0.6228\u001b[0m        \u001b[35m1.1166\u001b[0m  1.4822\n","     19        \u001b[36m1.0110\u001b[0m       \u001b[32m0.6348\u001b[0m        \u001b[35m1.1139\u001b[0m  1.4689\n","     20        \u001b[36m1.0046\u001b[0m       \u001b[32m0.6352\u001b[0m        \u001b[35m1.1113\u001b[0m  1.4520\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.614 total time=  32.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9639\u001b[0m       \u001b[32m0.1292\u001b[0m        \u001b[35m2.7976\u001b[0m  2.2054\n","      2        \u001b[36m2.5494\u001b[0m       \u001b[32m0.2964\u001b[0m        \u001b[35m2.2952\u001b[0m  1.7598\n","      3        \u001b[36m2.0190\u001b[0m       \u001b[32m0.3836\u001b[0m        \u001b[35m1.8790\u001b[0m  1.4650\n","      4        \u001b[36m1.6982\u001b[0m       \u001b[32m0.4488\u001b[0m        \u001b[35m1.6377\u001b[0m  1.4307\n","      5        \u001b[36m1.4972\u001b[0m       \u001b[32m0.4904\u001b[0m        \u001b[35m1.4569\u001b[0m  1.4318\n","      6        \u001b[36m1.3560\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m1.3426\u001b[0m  1.4847\n","      7        \u001b[36m1.2696\u001b[0m       \u001b[32m0.5608\u001b[0m        \u001b[35m1.2793\u001b[0m  1.4605\n","      8        \u001b[36m1.2149\u001b[0m       \u001b[32m0.5660\u001b[0m        \u001b[35m1.2407\u001b[0m  1.4647\n","      9        \u001b[36m1.1764\u001b[0m       \u001b[32m0.5824\u001b[0m        \u001b[35m1.2147\u001b[0m  2.1995\n","     10        \u001b[36m1.1474\u001b[0m       \u001b[32m0.5888\u001b[0m        \u001b[35m1.1962\u001b[0m  1.7239\n","     11        \u001b[36m1.1241\u001b[0m       \u001b[32m0.5924\u001b[0m        \u001b[35m1.1807\u001b[0m  1.4825\n","     12        \u001b[36m1.1043\u001b[0m       \u001b[32m0.5960\u001b[0m        \u001b[35m1.1681\u001b[0m  1.4846\n","     13        \u001b[36m1.0872\u001b[0m       \u001b[32m0.5980\u001b[0m        \u001b[35m1.1565\u001b[0m  1.4759\n","     14        \u001b[36m1.0724\u001b[0m       \u001b[32m0.6012\u001b[0m        \u001b[35m1.1465\u001b[0m  1.5325\n","     15        \u001b[36m1.0594\u001b[0m       \u001b[32m0.6024\u001b[0m        \u001b[35m1.1379\u001b[0m  1.4196\n","     16        \u001b[36m1.0480\u001b[0m       \u001b[32m0.6048\u001b[0m        \u001b[35m1.1307\u001b[0m  1.4374\n","     17        \u001b[36m1.0380\u001b[0m       0.6012        \u001b[35m1.1243\u001b[0m  2.1942\n","     18        \u001b[36m1.0290\u001b[0m       0.6032        \u001b[35m1.1190\u001b[0m  1.7466\n","     19        \u001b[36m1.0209\u001b[0m       \u001b[32m0.6064\u001b[0m        \u001b[35m1.1147\u001b[0m  1.4618\n","     20        \u001b[36m1.0136\u001b[0m       \u001b[32m0.6088\u001b[0m        \u001b[35m1.1109\u001b[0m  1.5093\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.sgd.SGD'>;, score=0.609 total time=  33.3s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.4039\u001b[0m       \u001b[32m0.0608\u001b[0m        \u001b[35m3.1406\u001b[0m  1.5433\n","      2        \u001b[36m3.0995\u001b[0m       \u001b[32m0.0628\u001b[0m        \u001b[35m3.0982\u001b[0m  1.5085\n","      3        \u001b[36m3.0853\u001b[0m       0.0600        \u001b[35m3.0908\u001b[0m  1.5042\n","      4        \u001b[36m3.0779\u001b[0m       \u001b[32m0.0648\u001b[0m        \u001b[35m3.0750\u001b[0m  2.0048\n","      5        3.0781       0.0620        3.1254  1.9994\n","      6        3.1903       0.0400        3.2242  1.5123\n","      7        3.2330       0.0400        3.2245  1.5298\n","      8        3.2332       0.0400        3.2245  1.4915\n","      9        3.2333       0.0400        3.2246  1.4574\n","     10        3.2334       0.0400        3.2246  1.5767\n","     11        3.2335       0.0400        3.2246  1.6041\n","     12        3.2336       0.0400        3.2246  2.3482\n","     13        3.2337       0.0400        3.2246  1.6775\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 1/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  24.2s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.1775\u001b[0m       \u001b[32m0.0812\u001b[0m        \u001b[35m2.9203\u001b[0m  1.5353\n","      2        \u001b[36m2.8888\u001b[0m       0.0800        \u001b[35m2.8815\u001b[0m  1.4924\n","      3        \u001b[36m2.8675\u001b[0m       \u001b[32m0.0888\u001b[0m        3.0243  1.5304\n","      4        \u001b[36m2.8539\u001b[0m       0.0796        \u001b[35m2.8301\u001b[0m  1.4873\n","      5        2.9248       0.0400        3.5285  2.1617\n","      6        3.2696       0.0400        3.2238  1.8389\n","      7        3.2337       0.0400        3.2241  1.4817\n","      8        3.2339       0.0400        3.2242  1.5146\n","      9        3.2341       0.0400        3.2242  1.5205\n","     10        3.2343       0.0400        3.2243  1.5067\n","     11        3.2344       0.0400        3.2244  1.5096\n","     12        3.2345       0.0400        3.2244  1.5288\n","     13        3.2346       0.0400        3.2244  2.4398\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 2/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  24.1s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9782\u001b[0m       \u001b[32m0.1008\u001b[0m        \u001b[35m2.7371\u001b[0m  1.5327\n","      2        3.0042       0.0400        3.2298  1.5881\n","      3        3.2322       0.0400        3.2267  1.5381\n","      4        3.2330       0.0400        3.2272  1.5645\n","      5        3.2333       0.0400        3.2276  1.5215\n","      6        3.2335       0.0400        3.2279  2.3915\n","      7        3.2337       0.0400        3.2282  1.6832\n","      8        3.2338       0.0400        3.2284  1.5308\n","      9        3.2339       0.0400        3.2285  1.5164\n","     10        3.2340       0.0400        3.2287  1.6057\n","Stopping since valid_loss has not improved in the last 10 epochs.\n","[CV 3/3] END callbacks__earlystopping__patience=10, module__nonlin=<function tanh at 0x7ffa9858af80>, module__num_units=200, optimizer=<class 'torch.optim.adam.Adam'>;, score=0.040 total time=  18.9s\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6087\u001b[0m       \u001b[32m0.2947\u001b[0m        \u001b[35m2.1067\u001b[0m  3.0149\n","      2        \u001b[36m1.6518\u001b[0m       \u001b[32m0.5061\u001b[0m        \u001b[35m1.5011\u001b[0m  2.8984\n","      3        \u001b[36m1.2931\u001b[0m       \u001b[32m0.5688\u001b[0m        \u001b[35m1.2969\u001b[0m  2.4415\n","      4        \u001b[36m1.1738\u001b[0m       \u001b[32m0.5837\u001b[0m        \u001b[35m1.2210\u001b[0m  3.4630\n","      5        \u001b[36m1.1185\u001b[0m       \u001b[32m0.5995\u001b[0m        \u001b[35m1.1814\u001b[0m  2.4578\n","      6        \u001b[36m1.0846\u001b[0m       \u001b[32m0.6077\u001b[0m        \u001b[35m1.1542\u001b[0m  3.4621\n","      7        \u001b[36m1.0610\u001b[0m       \u001b[32m0.6107\u001b[0m        \u001b[35m1.1367\u001b[0m  2.4188\n","      8        \u001b[36m1.0437\u001b[0m       \u001b[32m0.6141\u001b[0m        \u001b[35m1.1230\u001b[0m  2.4144\n","      9        \u001b[36m1.0303\u001b[0m       \u001b[32m0.6147\u001b[0m        \u001b[35m1.1123\u001b[0m  2.4571\n","     10        \u001b[36m1.0194\u001b[0m       \u001b[32m0.6157\u001b[0m        \u001b[35m1.1046\u001b[0m  2.6044\n","     11        \u001b[36m1.0101\u001b[0m       \u001b[32m0.6283\u001b[0m        \u001b[35m1.0986\u001b[0m  3.3406\n","     12        \u001b[36m1.0024\u001b[0m       \u001b[32m0.6317\u001b[0m        \u001b[35m1.0942\u001b[0m  2.4278\n","     13        \u001b[36m0.9955\u001b[0m       \u001b[32m0.6339\u001b[0m        \u001b[35m1.0898\u001b[0m  2.4463\n","     14        \u001b[36m0.9894\u001b[0m       \u001b[32m0.6347\u001b[0m        \u001b[35m1.0869\u001b[0m  2.4480\n","     15        \u001b[36m0.9838\u001b[0m       \u001b[32m0.6355\u001b[0m        \u001b[35m1.0844\u001b[0m  3.0065\n","     16        \u001b[36m0.9787\u001b[0m       \u001b[32m0.6360\u001b[0m        \u001b[35m1.0817\u001b[0m  2.8576\n","     17        \u001b[36m0.9740\u001b[0m       \u001b[32m0.6381\u001b[0m        \u001b[35m1.0806\u001b[0m  2.4315\n","     18        \u001b[36m0.9698\u001b[0m       \u001b[32m0.6395\u001b[0m        \u001b[35m1.0793\u001b[0m  2.4488\n","     19        \u001b[36m0.9656\u001b[0m       \u001b[32m0.6403\u001b[0m        \u001b[35m1.0788\u001b[0m  2.4445\n","     20        \u001b[36m0.9617\u001b[0m       \u001b[32m0.6416\u001b[0m        \u001b[35m1.0778\u001b[0m  3.2023\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=3,\n","             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n","  module=<class '__main__.ClassifierModule'>,\n","),\n","             param_grid={'callbacks__earlystopping__patience': [5, 10],\n","                         'module__nonlin': [<function relu at 0x7ffa9858a560>,\n","                                            <function tanh at 0x7ffa9858af80>],\n","                         'module__num_units': [800, 200],\n","                         'optimizer': [<class 'torch.optim.sgd.SGD'>,\n","                                       <class 'torch.optim.adam.Adam'>]},\n","             scoring='accuracy', verbose=3)"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n","             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n","  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n","),\n","             param_grid={&#x27;callbacks__earlystopping__patience&#x27;: [5, 10],\n","                         &#x27;module__nonlin&#x27;: [&lt;function relu at 0x7ffa9858a560&gt;,\n","                                            &lt;function tanh at 0x7ffa9858af80&gt;],\n","                         &#x27;module__num_units&#x27;: [800, 200],\n","                         &#x27;optimizer&#x27;: [&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;,\n","                                       &lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;]},\n","             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n","             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n","  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n","),\n","             param_grid={&#x27;callbacks__earlystopping__patience&#x27;: [5, 10],\n","                         &#x27;module__nonlin&#x27;: [&lt;function relu at 0x7ffa9858a560&gt;,\n","                                            &lt;function tanh at 0x7ffa9858af80&gt;],\n","                         &#x27;module__num_units&#x27;: [800, 200],\n","                         &#x27;optimizer&#x27;: [&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;,\n","                                       &lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;]},\n","             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n","  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n",")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n","  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n",")</pre></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","# First, we extract some simple features as input for the neural network\n","# import package:\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","X_test_2 = vectorizer2.transform(sub_testdf['text'].to_numpy())\n","\n","X_test_2 = X_test_2.astype(np.float32)\n","y_test = y_test.astype(np.int64)\n","y_pred = gs2.predict(X_test_2)\n","\n","print(classification_report(y_test , y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kyeamx5lZPw","executionInfo":{"status":"ok","timestamp":1696793396776,"user_tz":-480,"elapsed":4258,"user":{"displayName":"Haozhe Luo","userId":"17359668240613124024"}},"outputId":"dafcbda7-99c6-4e99-8dd0-c00036eb7308"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.30      0.46      0.36       250\n","           1       0.90      0.80      0.84       250\n","           2       0.92      0.78      0.85       250\n","           3       0.32      0.05      0.09       250\n","           4       0.82      0.83      0.82       250\n","           5       0.77      0.96      0.86       250\n","           6       0.90      0.91      0.90       250\n","           7       0.45      0.29      0.35       250\n","           8       0.26      0.06      0.10       250\n","           9       0.43      0.49      0.46       250\n","          10       0.92      0.91      0.91       250\n","          11       0.45      0.04      0.07       250\n","          12       0.29      0.62      0.39       250\n","          13       0.83      0.86      0.85       250\n","          14       0.82      0.91      0.86       250\n","          15       0.91      0.85      0.88       250\n","          16       0.24      0.35      0.29       250\n","          17       0.88      0.92      0.90       250\n","          18       0.88      0.96      0.92       250\n","          19       0.77      0.04      0.08       250\n","          20       0.33      0.16      0.22       250\n","          21       0.94      0.93      0.93       250\n","          22       0.44      0.50      0.47       250\n","          23       0.98      0.98      0.98       250\n","          24       0.34      0.91      0.49       250\n","\n","    accuracy                           0.62      6250\n","   macro avg       0.64      0.62      0.60      6250\n","weighted avg       0.64      0.62      0.60      6250\n","\n"]}]},{"cell_type":"code","source":["best_parameters = gs.best_params_\n"],"metadata":{"id":"8wS-XzfvxEKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(best_parameters)"],"metadata":{"id":"Vm_TwsUXyOMg","executionInfo":{"status":"ok","timestamp":1696793695525,"user_tz":-480,"elapsed":252,"user":{"displayName":"Haozhe Luo","userId":"17359668240613124024"}},"outputId":"b894f294-d809-4625-ee50-e7afef7289b2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'callbacks__earlystopping__patience': 10, 'module__nonlin': <function tanh at 0x7ffa9858af80>, 'module__num_units': 800, 'optimizer': <class 'torch.optim.sgd.SGD'>}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JeL1pcLkyRGx"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"bd97b8bffa4d3737e84826bc3d37be3046061822757ce35137ab82ad4c5a2016"}},"colab":{"provenance":[{"file_id":"1wDtacsvGOiJd2SRjqS763isiz2LVziFP","timestamp":1696513597602},{"file_id":"1vwyB2s07x98ecayW6bfAx828qZ67Bgfp","timestamp":1696144289653},{"file_id":"https://github.com/skorch-dev/skorch/blob/master/notebooks/Basic_Usage.ipynb","timestamp":1695936748288}]}},"nbformat":4,"nbformat_minor":0}