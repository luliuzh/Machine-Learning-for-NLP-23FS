{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "lc09sFDe-5kn",
        "iqioi0rG_Dz9"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hENmFU8FmZbl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b339ee7-3c05-4337-e203-a507f6e75c57"
      },
      "source": [
        "!pip install contextualized-topic-models==2.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contextualized-topic-models==2.3.0\n",
            "  Downloading contextualized_topic_models-2.3.0-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models==2.3.0) (1.23.5)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models==2.3.0) (0.16.0+cu121)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models==2.3.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: gensim>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models==2.3.0) (4.3.2)\n",
            "Collecting sentence-transformers>=1.1.1 (from contextualized-topic-models==2.3.0)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wordcloud>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models==2.3.0) (1.9.3)\n",
            "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models==2.3.0) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models==2.3.0) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models==2.3.0) (1.11.4)\n",
            "Collecting ipywidgets==7.5.1 (from contextualized-topic-models==2.3.0)\n",
            "  Downloading ipywidgets-7.5.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==7.16.3 (from contextualized-topic-models==2.3.0)\n",
            "  Downloading ipython-7.16.3-py3-none-any.whl (783 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.1/783.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.16.3->contextualized-topic-models==2.3.0) (67.7.2)\n",
            "Collecting jedi<=0.17.2,>=0.10 (from ipython==7.16.3->contextualized-topic-models==2.3.0)\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==7.16.3->contextualized-topic-models==2.3.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.16.3->contextualized-topic-models==2.3.0) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython==7.16.3->contextualized-topic-models==2.3.0) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.16.3->contextualized-topic-models==2.3.0) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.16.3->contextualized-topic-models==2.3.0) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.16.3->contextualized-topic-models==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.10/dist-packages (from ipython==7.16.3->contextualized-topic-models==2.3.0) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (5.5.6)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (5.9.2)\n",
            "Collecting widgetsnbextension~=3.5.0 (from ipywidgets==7.5.1->contextualized-topic-models==2.3.0)\n",
            "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.3->contextualized-topic-models==2.3.0) (6.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (2.8.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (4.35.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models==2.3.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models==2.3.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models==2.3.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models==2.3.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models==2.3.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models==2.3.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models==2.3.0) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.7.0->contextualized-topic-models==2.3.0) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (6.0.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (6.3.2)\n",
            "Collecting parso<0.8.0,>=0.7.0 (from jedi<=0.17.2,>=0.10->ipython==7.16.3->contextualized-topic-models==2.3.0)\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (5.5.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.16.3->contextualized-topic-models==2.3.0) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->contextualized-topic-models==2.3.0) (1.16.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (0.4.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->contextualized-topic-models==2.3.0) (2.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (1.3.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect->ipython==7.16.3->contextualized-topic-models==2.3.0) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->contextualized-topic-models==2.3.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->contextualized-topic-models==2.3.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->contextualized-topic-models==2.3.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->contextualized-topic-models==2.3.0) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=1.1.1->contextualized-topic-models==2.3.0) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->contextualized-topic-models==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.13.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (4.1.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (21.2.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.3.0) (2.21)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=e44afae8a1bce8c894b73f6208ad8ea8737ef35b8ca7930e68cc8c230de9cf61\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, parso, jedi, ipython, sentence-transformers, widgetsnbextension, ipywidgets, contextualized-topic-models\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.3\n",
            "    Uninstalling parso-0.8.3:\n",
            "      Successfully uninstalled parso-0.8.3\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.16.0 requires ipywidgets>=7.7.1, but you have ipywidgets 7.5.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 7.16.3 which is incompatible.\n",
            "ipyevents 2.0.2 requires ipywidgets>=7.6.0, but you have ipywidgets 7.5.1 which is incompatible.\n",
            "ipyleaflet 0.18.0 requires ipywidgets<9,>=7.6.0, but you have ipywidgets 7.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed contextualized-topic-models-2.3.0 ipython-7.16.3 ipywidgets-7.5.1 jedi-0.17.2 parso-0.7.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 widgetsnbextension-3.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAwbguDJlC1m"
      },
      "source": [
        "## Import General Utility Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci16zWWnlC1n"
      },
      "source": [
        "import re\n",
        "import urllib\n",
        "import gzip\n",
        "import io\n",
        "import csv\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "ZRJwwi6zqRPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "4QbaIEnRZVHP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SacDQZfHWb7t"
      },
      "source": [
        "Where to store the data file. If you want, you can adjust the path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_mkS_zeWbYW"
      },
      "source": [
        "path_before_1990 = '/content/drive/My Drive/titles_before_1990.txt'\n",
        "path_from_1990_to_2009 = '/content/drive/My Drive/titles_from_1990_to_2009.txt'\n",
        "path_from_2010 = '/content/drive/My Drive/titles_from_2010.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohMkrs8AWau"
      },
      "source": [
        "Execute the following cell only once to download the data and write it as a file to your google drive. Afterwards, skip this cell or comment it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUVy4jyGlVH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e803cb4a-3936-4aff-fe96-655bede084e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# to download the data manually or get more information, go to: https://dblp.org/faq/How+can+I+download+the+whole+dblp+dataset.html\n",
        "url = 'https://dblp.uni-trier.de/xml/dblp.xml.gz'\n",
        "# num_titles = 500000  # the (max)number of titles to load\n",
        "\n",
        "\n",
        "def load_gzip_file(url):\n",
        "    \"\"\"Download Gzip-file.\"\"\"\n",
        "    response = urllib.request.urlopen(url)\n",
        "    compressed_file = io.BytesIO(response.read())\n",
        "    decompressed_file = gzip.GzipFile(fileobj=compressed_file)\n",
        "    return decompressed_file\n",
        "\n",
        "def extract_titles(input_file, max_num=50000):\n",
        "    \"\"\"Extract title and publication year of dblp papers, given as input file.\n",
        "\n",
        "    Divide the papers into 3 time periods.\n",
        "\n",
        "    Collect max max_num papers per time period.\n",
        "    \"\"\"\n",
        "    pairs_before_1990 = []\n",
        "    count_before_1990 = 0\n",
        "    pairs_from_1990_to_2009 = []\n",
        "    count_from_1990_to_2009 = 0\n",
        "    pairs_from_2010 = []\n",
        "    count_from_2010 = 0\n",
        "    got_title = False\n",
        "    for line in tqdm(input_file):\n",
        "        line_str = line.decode('utf-8')\n",
        "        if got_title:\n",
        "            # we have a title and check for the corresponding year\n",
        "            year_result = re.search(r'<year>(.*)</year>', line_str)\n",
        "            if year_result:\n",
        "                # we also have the year and thus save the title-year pair\n",
        "                year = int(year_result.group(1))\n",
        "                if year < 1990 and count_before_1990 <= max_num:\n",
        "                    pairs_before_1990.append((title, year))\n",
        "                    count_before_1990 += 1\n",
        "                elif year < 2010 and count_from_1990_to_2009 <= max_num:\n",
        "                    pairs_from_1990_to_2009.append((title, year))\n",
        "                    count_from_1990_to_2009 += 1\n",
        "                elif year >= 2010 and count_from_2010 <= max_num:\n",
        "                    pairs_from_2010.append((title, year))\n",
        "                    count_from_2010 += 1\n",
        "                got_title = False\n",
        "        else:\n",
        "            # we have no title and search for title\n",
        "            result = re.search(r'<title>(.*)</title>', line_str)\n",
        "            if result:\n",
        "                title = result.group(1)\n",
        "                if len(title.split(' ')) < 3:\n",
        "                    # only include titles with at least four words\n",
        "                    continue\n",
        "                got_title = True\n",
        "\n",
        "        if count_before_1990 >= max_num and count_from_1990_to_2009 >= max_num and count_from_2010 >= max_num:\n",
        "            return pairs_before_1990, pairs_from_1990_to_2009, pairs_from_2010\n",
        "\n",
        "    return pairs_before_1990, pairs_from_1990_to_2009, pairs_from_2010\n",
        "\n",
        "def save_data(pairs, file_path):\n",
        "    with open(file_path, 'w') as fout:\n",
        "        writer = csv.writer(fout)\n",
        "        for pair in pairs:\n",
        "            writer.writerow(pair)\n",
        "\n",
        "in_file = load_gzip_file(url)\n",
        "pairs_before_1990, pairs_from_1990_to_2009, pairs_from_2010 = extract_titles(in_file)\n",
        "save_data(pairs_before_1990, path_before_1990)\n",
        "save_data(pairs_from_1990_to_2009, path_from_1990_to_2009)\n",
        "save_data(pairs_from_2010, path_from_2010)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17871458it [00:46, 385083.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYm5UB9bVJXw"
      },
      "source": [
        "Mount your google drive (in case it is not yet mounted) so that the newly created files are available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECGA0pbRlqZi",
        "outputId": "b2d098d2-232b-4d35-b3d5-40e0192ff5c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_before_1990[:10]"
      ],
      "metadata": {
        "id": "tVsruuaRp-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40446e3-45b6-4f86-f0e3-ad8be98ac9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Object Model Capabilities For Distributed Object Management.', 1989),\n",
              " ('Distributed Object Management Technology.', 1988),\n",
              " ('Muffin: A Distributed Database Machine', 1979),\n",
              " ('Algebraical Optimization of FTA-Expressions', 1988),\n",
              " ('Wissensrepr&auml;sentation und Maschinelles Lernen', 1987),\n",
              " ('An Algebraic Characterization of STUF', 1988),\n",
              " ('Zur Systemarchitektur von LILOG', 1987),\n",
              " ('Mengenorientierte Auswertung von Anfragen in der Logikprogrammiersprache PROLOG',\n",
              "  1988),\n",
              " ('Definite Resolution over Constraint Languages', 1988),\n",
              " ('Dokumentation der Syntax der LILOG-Grammatik', 1988)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDhEoD2Tsh3z"
      },
      "source": [
        "# Part1: LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ86sQwo124U"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "num_lda_topics = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc09sFDe-5kn"
      },
      "source": [
        "## Before the 1990s:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rwq6kF7vqUj"
      },
      "source": [
        "with open(path_before_1990) as fin:\n",
        "    reader = csv.reader(fin)\n",
        "    titles = [row[0] for row in reader]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocessing"
      ],
      "metadata": {
        "id": "ISvRUPXZZci3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmKJDHwI2Dnp"
      },
      "source": [
        "Let's perform some simple preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vmu77l62DCp"
      },
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "prepro_titles_1 = [preprocess_text(title) for title in titles]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mulG5Sg2NBZ",
        "outputId": "9254a79d-3416-4cbb-e327-817fe559301c"
      },
      "source": [
        "prepro_titles_1[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['object model capabilities for distributed object management',\n",
              " 'distributed object management technology',\n",
              " 'muffin a distributed database machine',\n",
              " 'algebraical optimization of ftaexpressions',\n",
              " 'wissensrepraumlsentation und maschinelles lernen',\n",
              " 'an algebraic characterization of stuf',\n",
              " 'zur systemarchitektur von lilog',\n",
              " 'mengenorientierte auswertung von anfragen in der logikprogrammiersprache prolog',\n",
              " 'definite resolution over constraint languages',\n",
              " 'dokumentation der syntax der liloggrammatik']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization"
      ],
      "metadata": {
        "id": "WrOklQwqZpCr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGEy1_fR3CpQ"
      },
      "source": [
        "Now we turn the documents (or titles in this case) into a matrix feature representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhgxgCM_01mx"
      },
      "source": [
        "num_features = 10000\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, stop_words='english')\n",
        "tf = tf_vectorizer.fit_transform(prepro_titles_1)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names_out()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the LDA model"
      ],
      "metadata": {
        "id": "NKbjrtpFZt6v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_927CQlk4C27"
      },
      "source": [
        "lda = LatentDirichletAllocation(n_components=num_lda_topics, max_iter=5, learning_method='online', random_state=42).fit(tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate topics"
      ],
      "metadata": {
        "id": "8G68cvjYZ2KB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-8NinuI4kMG",
        "outputId": "685fcaec-2bb8-4f71-bb2b-1b432950ec77"
      },
      "source": [
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f'Topic {topic_idx}:', end=' ')\n",
        "    print(' '.join([tf_feature_names[i] for i in topic.argsort()[:-12 - 1:-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: design algorithm theory networks algorithms application simulation computing fast testing der trees\n",
            "Topic 1: systems logic model linear functions models control distributed complexity time programs comments\n",
            "Topic 2: information note optimal problem network development memory circuits retrieval graphs using automatic\n",
            "Topic 3: computer systems analysis software using problems programming language parallel method approach digital\n",
            "Topic 4: data review languages applications pp machines pattern evaluation science new finite recognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbx0DythfCkP"
      },
      "source": [
        "Topics:\n",
        "0. Systems Design and Control\n",
        "1. Analysis of Parallel Algorithms and Models\n",
        "2. Computer Logic and Programming\n",
        "3. Algorithms and Methods in Machine Learning\n",
        "4. Information Processing and Structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqioi0rG_Dz9"
      },
      "source": [
        "## From 1990 to 2009:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "rMEW3dKXZ85w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Language detection:** detect the language used in the text dataset"
      ],
      "metadata": {
        "id": "yZuzrtwV1pmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-g0L8JbrGem",
        "outputId": "de4bcefc-1868-4195-941f-65c56f3119fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=7a2d3e19a4843f674921fba0bbd44894c868e84c7f96eaf59f0f8b1ed5f15013\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langdetect import detect\n",
        "\n",
        "def detect_language_text(file_path):\n",
        "    detected_languages = set()\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        language = detect(line.strip())\n",
        "        detected_languages.add(language)\n",
        "\n",
        "    return list(detected_languages)"
      ],
      "metadata": {
        "id": "JDt7gGg0uCVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langs_set_2 = detect_language_text(\"/content/drive/MyDrive/titles_from_1990_to_2009.txt\")"
      ],
      "metadata": {
        "id": "MMWlXlg22JMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langs_set_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf1Af1yrA0L6",
        "outputId": "76b80924-714c-4db9-c21b-1851fb81e4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cy',\n",
              " 'af',\n",
              " 'tl',\n",
              " 'it',\n",
              " 'cs',\n",
              " 'de',\n",
              " 'pl',\n",
              " 'vi',\n",
              " 'da',\n",
              " 'sl',\n",
              " 'so',\n",
              " 'hu',\n",
              " 'ro',\n",
              " 'id',\n",
              " 'no',\n",
              " 'ca',\n",
              " 'es',\n",
              " 'et',\n",
              " 'en',\n",
              " 'sk',\n",
              " 'hr',\n",
              " 'fi',\n",
              " 'fr',\n",
              " 'pt',\n",
              " 'sv',\n",
              " 'tr',\n",
              " 'lt',\n",
              " 'nl']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Translation:** translate the dataset into English"
      ],
      "metadata": {
        "id": "yuJuN1Fp2Jfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "id": "HkPz0zqc3miy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f430482e-225d-49e1-c624-710708fcd071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.11.17)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=c957162a4ab1b4ae58659b79187dada033c7100837c4c1c0fc20d0cd981cd548\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "import os\n",
        "\n",
        "def translate_non_english_to_english(file_path, output_file):\n",
        "    translator = Translator()\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print(\"File not found.\")\n",
        "        return\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "        # Split text into sentences or paragraphs (adjust based on your data structure)\n",
        "        sentences = text.split('.')  # Split by sentences, adjust as needed\n",
        "\n",
        "        translated_text = []\n",
        "        for sentence in sentences:\n",
        "            if sentence.strip():  # Check if the sentence is not empty\n",
        "                if not all(ord(char) < 128 for char in sentence):  # Check if the sentence contains non-ASCII characters\n",
        "                    translation = translator.translate(sentence, dest='en').text\n",
        "                    translated_text.append(translation)\n",
        "                else:\n",
        "                    translated_text.append(sentence)  # Keep English sentences unchanged\n",
        "\n",
        "        # Join translated and original English sentences\n",
        "        result = '. '.join(translated_text)  # Adjust joining as per your original data structure\n",
        "\n",
        "        # Write translated result to an output file\n",
        "        with open(output_file, 'w', encoding='utf-8') as output:\n",
        "            output.write(result)"
      ],
      "metadata": {
        "id": "dhvWY2NZHMPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/titles_from_1990_to_2009.txt'\n",
        "output_file = '/content/drive/MyDrive/translated_titles_from_1990_to_2009.txt'\n",
        "\n",
        "translate_non_english_to_english(file_path, output_file)"
      ],
      "metadata": {
        "id": "Ks-bBKchHiQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Normally Preprocessing:** tokenization, stop word removal, lemmatization, numerical characters removal"
      ],
      "metadata": {
        "id": "t94HbwUl3pE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download NLTK resources if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "1K42Vh-V82pT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e75eca-6ecf-4199-d892-1cafffebf0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_titles(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Stop word removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "    # Joining the preprocessed tokens back to form the processed text\n",
        "    processed_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "    # Numerical characters removal\n",
        "    processed_text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    return processed_text"
      ],
      "metadata": {
        "id": "TYKMlfuN87ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"//content/drive/MyDrive/translated_titles_from_1990_to_2009.txt\"\n",
        "prepro_titles_2 = []\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for title in file:\n",
        "        prepro_titles = preprocess_titles(title)\n",
        "        prepro_titles_2.append(prepro_titles)"
      ],
      "metadata": {
        "id": "-RhiXE0VJJEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepro_titles_2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clKT7NERJRgg",
        "outputId": "c612201c-ffae-48a6-a015-5a09fd83763c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['An Evaluation of Object-Oriented DBMS Developments:  Edition. ,\\n',\n",
              " 'DARWIN: On the Incremental Migration of Legacy Information Systems,\\n',\n",
              " '\"Integrating Heterogeneous, Autonomous, Distributed Applications Using the DOM Prototype. \",\\n',\n",
              " 'Integrating Object-Oriented Applications and Middleware with Relational Databases. ,\\n',\n",
              " 'Towards a Transaction Management System for DOM. ,\\n',\n",
              " \"A 'RISC' Object Model for Object System Interoperation: Concepts and Applications. ,\\n\",\n",
              " 'MetaObject Protocol Concepts for a RISC Object Model. ,\\n',\n",
              " 'Object Data Language Facilities for Multimedia Data Types. ,\\n',\n",
              " 'Object Data Model Facilities for Multimedia Data Types. ,\\n',\n",
              " 'Experiments with Dispatching in a Distributed Object System. ,\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization"
      ],
      "metadata": {
        "id": "Cewik1KGaNj9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxza6sDSxgJm"
      },
      "source": [
        "Now we turn the documents (or titles in this case) into a matrix feature representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6I4x4sAxgJm"
      },
      "source": [
        "num_features = 10000\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, stop_words='english')\n",
        "tf = tf_vectorizer.fit_transform(prepro_titles_2)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names_out()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the LDA model"
      ],
      "metadata": {
        "id": "tfJqsQM1aTHI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALNMPO_PxgJm"
      },
      "source": [
        "lda = LatentDirichletAllocation(n_components=num_lda_topics, max_iter=5, learning_method='online', random_state=42).fit(tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate topics"
      ],
      "metadata": {
        "id": "8rRoQdS6aXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5 topics:**"
      ],
      "metadata": {
        "id": "0RH3DpPTai5y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51F5A6CuxgJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84af9d47-4fc1-473c-ea8a-a934795078dc"
      },
      "source": [
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f'Topic {topic_idx}:', end=' ')\n",
        "    print(' '.join([tf_feature_names[i] for i in topic.argsort()[:-12 - 1:-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: based information approach network systems model web current modeling frequency method neural\n",
            "Topic 1: analysis time networks performance digital systems ghz mobile multi wireless single real\n",
            "Topic 2: control cmos design fuzzy using dynamic adaptive phase sub eacute converter oacute\n",
            "Topic 3: using high low voltage study mode speed applications case logic level mw\n",
            "Topic 4: power data based graphs management decision process support knowledge circuit bit systems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrChQNb91fZ3"
      },
      "source": [
        "Topics:\n",
        "0. Information Modeling and Network Systems\n",
        "1. Performance Analysis of Digital Systems\n",
        "2. Control and Design using CMOS and Fuzzy Logic\n",
        "3. Study of Voltage and Logic Speed\n",
        "4. Power Management and Decision Support Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10 topics:**"
      ],
      "metadata": {
        "id": "aWi_ADBCam5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LatentDirichletAllocation(n_components=10, max_iter=5, learning_method='online', random_state=42).fit(tf)"
      ],
      "metadata": {
        "id": "hTmvDzq1MLyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f'Topic {topic_idx}:', end=' ')\n",
        "    print(' '.join([tf_feature_names[i] for i in topic.argsort()[:-12 - 1:-1]]))"
      ],
      "metadata": {
        "id": "EAIP3j17MO_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297fb6b5-9c34-435a-957e-9551773d8c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: neural voltage networks adaptive frequency noise self evaluation sensor retrieval intelligent online\n",
            "Topic 1: control analysis based network performance ghz multi wireless mhz mobile networks detection\n",
            "Topic 2: method architecture problem induction bit filter loop set fully sets controlled large\n",
            "Topic 3: high graphs speed case level memory video scheduling non quality direct band\n",
            "Topic 4: data applications management technology mode image oacute new techniques computer la en\n",
            "Topic 5: information time low systems current sub single support real decision multiple parallel\n",
            "Topic 6: using fuzzy approach dynamic modeling eacute converter study process logic linear scheme\n",
            "Topic 7: systems based phase knowledge learning novel signal active machine research fault cellular\n",
            "Topic 8: cmos design based web model development amplifier implementation software chip dual electronic\n",
            "Topic 9: power digital algorithm simulation integrated models dc circuit service vector analog services\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15 topics:**"
      ],
      "metadata": {
        "id": "OW23k_5Waq9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LatentDirichletAllocation(n_components=15, max_iter=5, learning_method='online', random_state=42).fit(tf)"
      ],
      "metadata": {
        "id": "4VAnjk1mMRHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f'Topic {topic_idx}:', end=' ')\n",
        "    print(' '.join([tf_feature_names[i] for i in topic.argsort()[:-12 - 1:-1]]))"
      ],
      "metadata": {
        "id": "QTb4q5HwMTVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a42a07-a2b5-4ebc-889b-d3fcec6ce348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: information networks process mobile models techniques sensor level vector memory supply use\n",
            "Topic 1: cmos analysis design performance digital multi wireless support problem decision amplifier optimal\n",
            "Topic 2: phase detection estimation filter la machine en loop automatic ac clustering para\n",
            "Topic 3: low sub motor multiple search order service sup receiver services quality feedback\n",
            "Topic 4: based data web management knowledge image channel gb circuits communication multimedia output\n",
            "Topic 5: using time dynamic voltage ghz architecture real mhz retrieval space line language\n",
            "Topic 6: fuzzy application learning study theory nonlinear artificial structure db set transceiver neural\n",
            "Topic 7: control based network neural technology chip speed oacute self parallel technique methods\n",
            "Topic 8: high integrated eacute converter new scheme development classification software intelligent prediction user\n",
            "Topic 9: systems adaptive frequency single hybrid agent environment algorithms modulation pattern behavior group\n",
            "Topic 10: algorithm logic current dc circuit efficient induction genetic framework active mw robust\n",
            "Topic 11: approach modeling method programming selection optimization computer introduction problems sets type diagnosis\n",
            "Topic 12: simulation linear noise distributed discrete range direct band fully source strategy product\n",
            "Topic 13: power model applications graphs bit video recognition finite compensation efficiency object measurement\n",
            "Topic 14: mode evaluation case implementation online research non internet oriented ic database evolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip_z250Z_Mnz"
      },
      "source": [
        "## From 2010 onwards:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_from_2010[:10]"
      ],
      "metadata": {
        "id": "VmilCXnsdQWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c4d692-67e2-4dfa-badf-7c5ffd393aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Spectre Attacks: Exploiting Speculative Execution.', 2018),\n",
              " ('50 Jahre Studiengang Informatik an der RWTH', 2022),\n",
              " ('Computer Science Curricula 2013', 2013),\n",
              " ('Differences in productivity and impact across the different computer science subareas.',\n",
              "  2012),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2013', 2014),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2017', 2018),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2012', 2013),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2020', 2021),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2019', 2020),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2014', 2015),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2018', 2019),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2016', 2017),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2022', 2023),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2015', 2016),\n",
              " ('Schloss Dagstuhl - Jahresbericht / Annual Report 2021', 2022),\n",
              " ('Klaus Tschira Stiftung gemeinn&uuml;tzige GmbH, KTS', 2012),\n",
              " ('E. W. Dijkstra Archive: The manuscripts of Edsger W. Dijkstra 1930-2002',\n",
              "  2021),\n",
              " ('Catchment classification by runoff behaviour with self-organizing maps (SOM)',\n",
              "  2011),\n",
              " ('Analysis of projected hydrological behavior of catchments based on signature indices',\n",
              "  2012),\n",
              " ('Ear Shape for Biometric Identification.', 2011),\n",
              " ('Multi-Threaded Implementation for Cryptography and Cryptanalysis.', 2011),\n",
              " ('Privacy-Preserving Authentication in Wireless Access Networks.', 2011),\n",
              " ('Private Key Cryptosystem.', 2011),\n",
              " ('Multicast Stream Authentication.', 2011),\n",
              " ('Inversion in Galois Fields.', 2011),\n",
              " ('Naccache-Stern Higher Residues Cryptosystem.', 2011),\n",
              " ('Higher Order Derivative Attack.', 2011),\n",
              " ('Biometrics in Video Surveillance.', 2011),\n",
              " ('Computationally Sound Proof System.', 2011),\n",
              " ('Niederreiter Encryption Scheme.', 2011),\n",
              " ('Near Field Communication.', 2011),\n",
              " ('Theorem Proving and Security.', 2011),\n",
              " ('Secure Wireless Mesh Networks.', 2011),\n",
              " ('User Verification Method.', 2011),\n",
              " ('ISMS: A Management Framework for Information Security.', 2011),\n",
              " ('Anonymous Web Browsing and Publishing.', 2011),\n",
              " ('Galois Message Authentication Code.', 2011),\n",
              " ('File System Permissions.', 2011),\n",
              " ('Software-Optimized Encryption Algorithm.', 2011),\n",
              " ('Biometric Information Ethics.', 2011),\n",
              " ('Public Key Proxy Signatures.', 2011),\n",
              " ('Multiple Independent Levels of Security.', 2011),\n",
              " (\"Euler's Totient Function.\", 2011),\n",
              " ('Secure Network Coding for Wireless Mesh Networks.', 2011),\n",
              " ('MDC-2 and MDC-4.', 2011),\n",
              " ('Roles in SQL.', 2011),\n",
              " ('Substitution-Permutation (SP) Network.', 2011),\n",
              " ('TCP SYN Cookies.', 2011),\n",
              " ('Adaptive Chosen Plaintext and Chosen Ciphertext Attack.', 2011),\n",
              " ('Web SSO and Security Assertion Markup Language.', 2011),\n",
              " ('Blum-Blum-Shub Pseudorandom Bit Generator.', 2011),\n",
              " ('Separation of Duties.', 2011),\n",
              " ('Stack (Buffer) Overrun.', 2011),\n",
              " ('Social Perspectives on Information Privacy.', 2011),\n",
              " ('Chosen Ciphertext Attack.', 2011),\n",
              " ('Signed Digit Exponentiation.', 2011),\n",
              " ('Insider Threat Defense.', 2011),\n",
              " ('Biometric Systems Evaluation.', 2011),\n",
              " ('Biometric Passport Security.', 2011),\n",
              " ('TCP SYN Flooding.', 2011),\n",
              " ('Secure Computer System Model.', 2011),\n",
              " ('Integrated Circuit Card.', 2011),\n",
              " ('Secure Hash Algorithm.', 2011),\n",
              " ('Random Bit Generator.', 2011),\n",
              " ('Rivest Cipher 5.', 2011),\n",
              " ('Proof of Knowledge Versus Proof of Membership.', 2011),\n",
              " ('Encyclopedia of Cryptography and Security, 2nd Ed.', 2011),\n",
              " ('Rivest Cipher 6.', 2011),\n",
              " ('Cayley Hash Functions.', 2011),\n",
              " ('Koblitz Elliptic Curves.', 2011),\n",
              " ('Macrodata Disclosure Limitation.', 2011),\n",
              " ('Feige-Fiat-Shamir Signature Scheme.', 2011),\n",
              " ('Secure Data Outsourcing: A Brief Overview.', 2011),\n",
              " ('History-Based Separation of Duties.', 2011),\n",
              " ('Memory and State Exhaustion Denial of Service.', 2011),\n",
              " ('Sieving in Function Fields.', 2011),\n",
              " ('Run-Time Malware Analysis.', 2011),\n",
              " ('PEM, Privacy-Enhanced Mail.', 2011),\n",
              " ('False Data Filtering.', 2011),\n",
              " ('Sliding Window Exponentiation.', 2011),\n",
              " ('Human Ear Biometrics.', 2011),\n",
              " ('Sensor Key Establishment and Maintenance.', 2011),\n",
              " ('Visual Secret Sharing Schemes.', 2011),\n",
              " ('Diffie-Hellman Key Exchange.', 2011),\n",
              " ('Interactive Proof Systems.', 2011),\n",
              " ('Group Key Distribution.', 2011),\n",
              " ('Schemes Based on Rank Codes.', 2011),\n",
              " ('Dictionary Attack (I).', 2011),\n",
              " ('Related Key Attack.', 2011),\n",
              " ('Security Implication in Virtualization.', 2011),\n",
              " ('FPGAs in Cryptography.', 2011),\n",
              " ('Zeta Function Computation.', 2011),\n",
              " ('Dynamic Malware Analysis.', 2011),\n",
              " ('Chaum Blind Signature Scheme.', 2011),\n",
              " ('Universal Integrated Circuit Card.', 2011),\n",
              " ('Miller-Rabin Probabilistic Primality Test.', 2011),\n",
              " ('MD4 Hash Function.', 2011),\n",
              " ('TCP Reset Injection.', 2011),\n",
              " ('False Data Injection Defense.', 2011),\n",
              " ('Multiparty Computation (MPC).', 2011),\n",
              " ('Data Encryption Standard (DES).', 2011),\n",
              " ('Stack (Buffer) Overflow.', 2011),\n",
              " ('Applications of Formal Methods to Web Application Security.', 2011),\n",
              " ('Secure Socket Layer (SSL).', 2011),\n",
              " ('Conference Key Agreement.', 2011),\n",
              " ('Web Browser Security and Privacy.', 2011),\n",
              " ('Temporal Access Control.', 2011),\n",
              " ('Kerberos Authentication Protocol.', 2011),\n",
              " ('Overlay-Based DoS Defenses.', 2011),\n",
              " ('Formal Analysis of Security APIs.', 2011),\n",
              " ('Bell-LaPadula Confidentiality Model.', 2011),\n",
              " ('Biba Mandatory Integrity Policy.', 2011),\n",
              " ('Physical Unclonable Functions (PUFs).', 2011),\n",
              " ('Formal Analysis of Cryptographic Protocols.', 2011),\n",
              " ('Biometric Identification in Video Surveillance.', 2011),\n",
              " ('Platform for Privacy Preferences (P3P).', 2011),\n",
              " ('Anonymity in Data Mining.', 2011),\n",
              " ('IPSec Policy Analysis.', 2011),\n",
              " ('Location Privacy in Wireless Networks.', 2011),\n",
              " ('ISO 19790 2006 Security Requirements for Cryptographic Modules.', 2011),\n",
              " ('Computational Diffie-Hellman Problem.', 2011),\n",
              " ('TCP Modulation Attacks.', 2011),\n",
              " ('Number Field Sieve.', 2011),\n",
              " ('Big Number Squaring.', 2011),\n",
              " ('Radio Frequency Attacks.', 2011),\n",
              " ('Attack by Summation Over an Hypercube.', 2011),\n",
              " ('Network Flooding Attack.', 2011),\n",
              " ('Lamport One-Time Signatures.', 2011),\n",
              " ('Secure Signatures from the \"Strong RSA\" Assumption.', 2011),\n",
              " ('Web 2.0 Security and Privacy.', 2011),\n",
              " ('Secure Time Synchronization.', 2011),\n",
              " ('XML-Based Access Control Languages.', 2011),\n",
              " ('Random Oracle Model.', 2011),\n",
              " ('Perfectly Secure Message Transmission.', 2011),\n",
              " ('Exponential Key Exchange.', 2011),\n",
              " ('Web Security Auditing.', 2011),\n",
              " ('Source Location Privacy.', 2011),\n",
              " ('Chemical Combinatorial Attack.', 2011),\n",
              " ('Authentication, From an Information Theoretic Perspective.', 2011),\n",
              " ('Biometric Key Generation.', 2011),\n",
              " ('Node Clone Defense.', 2011),\n",
              " ('Random Key Predistribution.', 2011),\n",
              " ('Privacy of Outsourced Data.', 2011),\n",
              " ('Chosen Plaintext and Chosen Ciphertext Attack.', 2011),\n",
              " ('Fermat Primality Test.', 2011),\n",
              " ('Web Initial Authentication.', 2011),\n",
              " ('Credential-Based Access Control.', 2011),\n",
              " ('Secret Key Cryptosystem.', 2011),\n",
              " ('Sensor Code Attestation.', 2011),\n",
              " ('Role-Based Access Control.', 2011),\n",
              " ('Reverse Engineering of Malware Emulators.', 2011),\n",
              " ('Cryptographic Algorithm Evaluation.', 2011),\n",
              " ('Certificate-Based Access Control.', 2011),\n",
              " ('Microdata Masking Techniques.', 2011),\n",
              " ('Face Recognition from Still Images and Video.', 2011),\n",
              " ('Group Key Exchange.', 2011),\n",
              " ('Public-Key Authenticated Encryption.', 2011),\n",
              " ('Uncoordinated Direct Sequence Spread Spectrum.', 2011),\n",
              " ('Secure Function Evaluation.', 2011),\n",
              " ('Hardware Security Module.', 2011),\n",
              " ('Synchronous Stream Cipher.', 2011),\n",
              " ('Quadratic Residuosity Problem.', 2011),\n",
              " ('SHA-0, SHA-1, SHA-2 (Secure Hash Algorithm).', 2011),\n",
              " ('Nonlinearity of Boolean Functions.', 2011),\n",
              " ('Metrics of Software Security.', 2011),\n",
              " ('Trusted Third Party.', 2011),\n",
              " ('Maliciously Modified Set of Administrative Tools.', 2011),\n",
              " ('Number Field Sieve for Factoring.', 2011),\n",
              " ('Weak Collision Resistance.', 2011),\n",
              " ('Access Control Rules.', 2011),\n",
              " ('Secure Audit Logs.', 2011),\n",
              " ('De Bruijn Sequence.', 2011),\n",
              " ('Resistance to the Standard Algebraic Attack.', 2011),\n",
              " ('Target Collision Resistant Hash Function.', 2011),\n",
              " ('Botnet Detection in Enterprise Networks.', 2011),\n",
              " ('Smart/Algorithmic Denial of Service.', 2011),\n",
              " ('Operational Separation of Duties.', 2011),\n",
              " ('Radio Interference Attack Defense.', 2011),\n",
              " ('Dynamic Program Analysis.', 2011),\n",
              " ('CPU Denial of Service.', 2011),\n",
              " ('Subscriber Identity Module.', 2011),\n",
              " ('Decentralized Trust Management.', 2011),\n",
              " ('Extended Euclidean Algorithm.', 2011),\n",
              " ('Advanced Encryption Standard.', 2011),\n",
              " ('Applications of Formal Methods to Intrusion Detection.', 2011),\n",
              " ('Physical Obfuscated Key.', 2011),\n",
              " ('Microdata Anonymization Techniques.', 2011),\n",
              " ('Sensor Key Management.', 2011),\n",
              " ('Hand Geometry Verification.', 2011),\n",
              " ('Modes of Operation of a Block Cipher.', 2011),\n",
              " ('Security of Group Communication in Wireless Mesh Networks.', 2011),\n",
              " ('Linear Syndrome Attack.', 2011),\n",
              " ('Biometric Sample Quality.', 2011),\n",
              " (\"Android's Security Framework-Understanding the Security of Mobile Phone Platforms.\",\n",
              "  2011),\n",
              " ('Nearest Vector Problem.', 2011),\n",
              " ('Electronic Voting Schemes.', 2011),\n",
              " ('Efficiency of Hyperelliptic Curve Cryptosystems.', 2011),\n",
              " ('Nonrepudiation of Digital Signatures.', 2011),\n",
              " ('Macrodata Disclosure Protection.', 2011),\n",
              " ('Self-Synchronizing Stream Cipher.', 2011),\n",
              " ('Algebraic Immunity of Boolean Functions.', 2011),\n",
              " ('Microdata Disclosure Limitation.', 2011),\n",
              " ('Threshold Homomorphic Cryptosystems.', 2011),\n",
              " ('Web Initial Sign on.', 2011),\n",
              " (\"Fermat's Little Theorem.\", 2011),\n",
              " ('Smartcard Tamper Resistance.', 2011),\n",
              " ('Propagation Characteristics of Boolean Functions.', 2011),\n",
              " ('Common Criteria, From a Security Policies Perspective.', 2011),\n",
              " ('Elliptic Curve Keys.', 2011),\n",
              " ('Substitutions and Permutations.', 2011),\n",
              " ('Public Key Encryption.', 2011),\n",
              " ('Program Integrity Verification.', 2011),\n",
              " ('Security Evaluation Criteria.', 2011),\n",
              " ('Parallelizable Message Authentication Code.', 2011),\n",
              " ('Wiener, Boneh-Durfee, and May Attacks on the RSA Public Key Cryptosystem.',\n",
              "  2011),\n",
              " ('Trusted Platform Module.', 2011),\n",
              " ('Information Flow Security.', 2011),\n",
              " ('BSP Board Support Package.', 2011),\n",
              " ('RSA Factoring Challenge.', 2011),\n",
              " ('Hash-Based Message Authentication Code.', 2011),\n",
              " ('Probabilistic Public-Key Encryption.', 2011),\n",
              " ('Generalized Mersenne Prime.', 2011),\n",
              " ('Firewall Policy Analysis.', 2011),\n",
              " ('Pairing-Friendly Elliptic Curves.', 2011),\n",
              " ('Product Cipher, Superencryption.', 2011),\n",
              " ('Interactive Theorem Proving and Security.', 2011),\n",
              " ('IC Integrated Circuit.', 2011),\n",
              " ('Location Information (Privacy of).', 2011),\n",
              " ('Root of Trust.', 2011),\n",
              " ('CMVP - Cryptographic Module Validation Program.', 2011),\n",
              " ('Secure Code Dissemination in Wireless Sensor Networks.', 2011),\n",
              " ('Linear Cryptanalysis for Stream Ciphers.', 2011),\n",
              " ('Cryptographic Protocol Verification.', 2011),\n",
              " ('Security of Wireless Mesh Networks (General Overview).', 2011),\n",
              " ('MD5 Hash Function.', 2011),\n",
              " ('Session Hijacking Attacks.', 2011),\n",
              " ('<i>MQ</i> or Multivariate Quadratic Public-Key Cryptosystem (MQPKC).',\n",
              "  2011),\n",
              " ('Jamming Attack Defense.', 2011),\n",
              " ('Dynamic Root of Trust.', 2011),\n",
              " ('TCG Trusted Computing Group.', 2011),\n",
              " ('Elliptic Curve Public-Key Encryption Schemes.', 2011),\n",
              " ('Linear Feedback Shift Register.', 2011),\n",
              " ('FPGA Field Programmable Gate Array.', 2011),\n",
              " ('Primality Proving Algorithm.', 2011),\n",
              " ('Conceptual Design of Secure Databases.', 2011),\n",
              " ('Secure Networks Design.', 2011),\n",
              " ('Web Service Security.', 2011),\n",
              " ('Impossible Differential Attack.', 2011),\n",
              " ('HTTP Session Security.', 2011),\n",
              " ('Second Preimage Resistance.', 2011),\n",
              " ('Secure Multiparty Computation (SMC).', 2011),\n",
              " ('Secure Remote Programming.', 2011),\n",
              " ('Web Single Sign On and SAML.', 2011),\n",
              " ('Trusted Computing Platform Alliance.', 2011),\n",
              " ('Security of Distance Bounding Protocols.', 2011),\n",
              " ('Adversarial/External Knowledge (Privacy in the Presence of).', 2011),\n",
              " ('RSA Digital Signature Scheme.', 2011),\n",
              " ('Indistinguishability of Encryptions.', 2011),\n",
              " ('Public Key Proxy Encryption.', 2011),\n",
              " ('Formal Methods in Certification and Evaluation.', 2011),\n",
              " ('Pseudo-Noise Sequences (PN-Sequences).', 2011),\n",
              " ('Elliptic Curve Trace Computation.', 2011),\n",
              " ('Advanced Hash Competition.', 2011),\n",
              " ('Fiat-Shamir Identification Protocol and the Feige-Fiat-Shamir Signature Scheme.',\n",
              "  2011),\n",
              " ('Fast Correlation Attack.', 2011),\n",
              " ('Generic Attacks Against DLP.', 2011),\n",
              " ('Reverse Public Key Encryption.', 2011),\n",
              " ('Trojan Horses, Computer Viruses, and Worms.', 2011),\n",
              " ('Proof of Work.', 2011),\n",
              " ('Chinese Wall Model.', 2011),\n",
              " ('Intrusion Detection in Ad Hoc Networks.', 2011),\n",
              " ('Discretionary Access Control Policies (DAC).', 2011),\n",
              " ('Least Common Multiple.', 2011),\n",
              " ('Chosen Plaintext Attack.', 2011),\n",
              " ('Levels of Trust.', 2011),\n",
              " ('Administrative Policies in SQL.', 2011),\n",
              " ('Specific Emitter Identification (SEI).', 2011),\n",
              " ('NSA Suite B.', 2011),\n",
              " ('OAEP: Optimal Asymmetric Encryption Padding.', 2011),\n",
              " ('Network Bandwidth Denial of Service (DoS).', 2011),\n",
              " ('Type Checking and Security.', 2011),\n",
              " ('Time-Based Access Control.', 2011),\n",
              " ('Machine Readable Travel Document Security.', 2011),\n",
              " ('HTTP Digest Authentication.', 2011),\n",
              " ('Probabilistic Key Sharing.', 2011),\n",
              " ('Keyword-Based Retrieval over Encrypted Data.', 2011),\n",
              " ('Shortest Vector Problem.', 2011),\n",
              " ('Web-Based Security Protocols.', 2011),\n",
              " ('Microdata Statistical Disclosure Control.', 2011),\n",
              " ('Biometrics for Identity Management and Fields of Application.', 2011),\n",
              " ('Formal Methods for the Orange Book.', 2011),\n",
              " ('Rule-Based Access Control.', 2011),\n",
              " ('Digital Signature Scheme Based on McEliece.', 2011),\n",
              " ('Personal Identification Number (PIN).', 2011),\n",
              " ('Linear Cryptanalysis for Block Ciphers.', 2011),\n",
              " ('Security of Cognitive Radios.', 2011),\n",
              " ('CRYPTREC (Japanese Cryptographic Algorithm Evaluation Project).', 2011),\n",
              " ('Key Encryption Key.', 2011),\n",
              " ('HTTP Digest Access Authentication Scheme.', 2011),\n",
              " ('Correlation Immune and Resilient Boolean Functions.', 2011),\n",
              " ('Schnorr Digital Signature Scheme.', 2011),\n",
              " ('Verifiable Secret Sharing.', 2011),\n",
              " ('Anomalous Binary Curves.', 2011),\n",
              " ('Wireless Locational Privacy.', 2011),\n",
              " ('Temporal Authorization Models.', 2011),\n",
              " ('DES-X (or DESX).', 2011),\n",
              " ('CPS, Certificate Practice Statement.', 2011),\n",
              " ('Single Euro Payments Area.', 2011),\n",
              " ('PKIX, Public Key Infrastructure (X.509).', 2011),\n",
              " ('Static Code Analysis.', 2011),\n",
              " ('Adaptive Chosen Ciphertext Attack.', 2011),\n",
              " ('Pairing-Based Key Exchange.', 2011),\n",
              " ('Worms in Cellular Networks.', 2011),\n",
              " ('Elliptic Curve Cryptography.', 2011),\n",
              " ('Differential Power Analysis.', 2011),\n",
              " ('Signed Window Exponentiation.', 2011),\n",
              " ('Specific Emitter Verification (SEV).', 2011),\n",
              " ('Rabin Digital Signature Scheme.', 2011),\n",
              " ('Linear Consistency Attack.', 2011),\n",
              " ('Discrete Logarithm Problem.', 2011),\n",
              " ('Binary GCD Algorithm.', 2011),\n",
              " ('Nyberg-Rueppel Signature Scheme.', 2011),\n",
              " ('Geometry of Numbers.', 2011),\n",
              " ('Communication Channel Anonymity.', 2011),\n",
              " ('Asynchronous Stream Cipher.', 2011),\n",
              " ('Elliptic Curve Point Multiplication Using Halving.', 2011),\n",
              " ('Fixed Window Exponentiation.', 2011),\n",
              " ('ECRYPT Stream Cipher Project.', 2011),\n",
              " ('Public Key Infrastructure.', 2011),\n",
              " (\"Golomb's Randomness Postulates.\", 2011),\n",
              " ('Secure Device Pairing.', 2011),\n",
              " ('Biometrics: Terms and Definitions.', 2011),\n",
              " ('Hand Geometry Recognition.', 2011),\n",
              " ('PRESENT - Block Cipher.', 2011),\n",
              " ('Adaptive Chosen Plaintext Attack.', 2011),\n",
              " ('Content-Based and View-Based Access Control.', 2011),\n",
              " ('Secure Data Aggregation.', 2011),\n",
              " ('Cellular Network Security.', 2011),\n",
              " ('Closest Vector Problem.', 2011),\n",
              " ('DNS-Based Botnet Detection.', 2011),\n",
              " ('SQL Injection Attacks.', 2011),\n",
              " ('Universal One-Way Hash Functions (UOWHF).', 2011),\n",
              " ('Secure Routing Protocols.', 2011),\n",
              " ('Single Wire Protocol.', 2011),\n",
              " ('Goldwasser-Micali Encryption Scheme.', 2011),\n",
              " ('Pattern of Blood Vessels.', 2011),\n",
              " ('McEliece Public Key Cryptosystem.', 2011),\n",
              " ('Broadcast Authentication from an Information Theoretic Perspective.', 2011),\n",
              " ('Search over Encrypted Data.', 2011),\n",
              " ('DH Key Agreement.', 2011),\n",
              " ('Chaffing and Winnowing.', 2011),\n",
              " ('Physical Random Function.', 2011),\n",
              " ('BIOS Basic Input Output System.', 2011),\n",
              " ('Virtual Machine Introspection.', 2011),\n",
              " ('Human Ear Identification.', 2011),\n",
              " ('Secure Location Discovery.', 2011),\n",
              " ('Trapdoor One-Way Function.', 2011),\n",
              " ('Hyperelliptic Curve Discrete Logarithm Problem (HECDLP).', 2011),\n",
              " ('Secure Vehicular Communication Systems.', 2011),\n",
              " ('Special-Purpose Cryptanalytical Hardware.', 2011),\n",
              " (\"Ron's Code 6.\", 2011),\n",
              " ('Big Number Multiplication.', 2011),\n",
              " ('HTTPS, HTTP over TLS.', 2011),\n",
              " ('Trusted Computing Group.', 2011),\n",
              " ('High Assurance Evaluation Methods.', 2011),\n",
              " ('PKI Trust Relationships.', 2011),\n",
              " ('Polybios Square Encryption.', 2011),\n",
              " ('Segregation of Duties.', 2011),\n",
              " ('Hyperelliptic Curve Security.', 2011),\n",
              " ('PKI Trust Models.', 2011),\n",
              " ('Applications of Rank-Metric Codes.', 2011),\n",
              " ('Trust Management in Databases.', 2011),\n",
              " ('Black Box Algorithms.', 2011),\n",
              " ('Biba Integrity Model.', 2011),\n",
              " ('Biometric Social Responsibility.', 2011),\n",
              " ('Galois Counter Mode.', 2011),\n",
              " ('Implicit Key Authentication.', 2011),\n",
              " ('Access Control Matrix.', 2011),\n",
              " ('Biometrics for Forensics.', 2011),\n",
              " (\"Shamir's Threshold Scheme.\", 2011),\n",
              " ('Digital Signature Standard.', 2011),\n",
              " ('BLS Short Digital Signatures.', 2011),\n",
              " ('Cross Site Scripting Attacks.', 2011),\n",
              " ('Biometric Performance Evaluation.', 2011),\n",
              " ('Static Separation of Duties.', 2011),\n",
              " ('ElGamal Public Key Encryption.', 2011),\n",
              " ('Digital Signature Schemes.', 2011),\n",
              " ('Transport Layer Security (TLS).', 2011),\n",
              " ('Information Theoretic Model.', 2011),\n",
              " ('HEC Acronym is Often Used for Hyper Elliptic Curves.', 2011),\n",
              " ('Binary Euclidean Algorithm.', 2011),\n",
              " ('Discretionary Access Control.', 2011),\n",
              " ('Secondary Use Regulations.', 2011),\n",
              " ('Known Plaintext Attack.', 2011),\n",
              " ('Radio-Frequency (RF) Fingerprinting.', 2011),\n",
              " ('NIST Elliptic Curves.', 2011),\n",
              " ('Blum-Goldwasser Public Key Encryption System.', 2011),\n",
              " ('Lattice Basis Reduction.', 2011),\n",
              " ('Strong Collision Resistance.', 2011),\n",
              " ('Decisional Diffie-Hellman Problem.', 2011),\n",
              " ('TPM Trusted Platform Module.', 2011),\n",
              " ('Secure Multiparty Computation.', 2011),\n",
              " ('Security Standards Activities.', 2011),\n",
              " ('Commercial Security Model.', 2011),\n",
              " ('Static Program Analysis.', 2011),\n",
              " ('Bell-La Padula Model.', 2011),\n",
              " ('Inversion in Finite Fields and Rings.', 2011),\n",
              " ('Probabilistic Primality Test.', 2011),\n",
              " ('Greatest Common Factor.', 2011),\n",
              " ('Elliptic Curve Method for Factoring.', 2011),\n",
              " ('Biometric Technologies and Security - International Biometric Standards Development Activities.',\n",
              "  2011),\n",
              " ('Itoh-Tsujii Inversion Algorithm.', 2011),\n",
              " ('Security for Mashups.', 2011),\n",
              " ('Chinese Remainder Theorem.', 2011),\n",
              " ('Elliptic Curve Discrete Logarithm Problem.', 2011),\n",
              " ('Key Generation Using Physical Properties of Wireless Communication.', 2011),\n",
              " ('Buffer Overflow Attacks.', 2011),\n",
              " ('Wireless Device Fingerprinting.', 2011),\n",
              " ('Message Authentication Algorithm.', 2011),\n",
              " ('Digital Signature Schemes from Codes.', 2011),\n",
              " ('Collaborative DoS Defenses.', 2011),\n",
              " ('ElGamal Digital Signature Scheme.', 2011),\n",
              " ('Denial of Service (DoS).', 2011),\n",
              " ('Human Ear Recognition.', 2011),\n",
              " ('Clark and Wilson Model.', 2011),\n",
              " ('Pretty Good Privacy (PGP).', 2011),\n",
              " ('ARP Poison Routing (APR).', 2011),\n",
              " ('Web Penetration Test.', 2011),\n",
              " ('Correlation Attack for Stream Ciphers.', 2011),\n",
              " ('Broadcast Stream Authentication.', 2011),\n",
              " ('Chosen Prefix Attack.', 2011),\n",
              " ('Paillier Encryption and Signature Schemes.', 2011),\n",
              " ('Secure Routing in Wireless Mesh Networks.', 2011),\n",
              " ('Application-Level Denial of Service.', 2011),\n",
              " ('Access Control Lists.', 2011),\n",
              " ('Elliptic Curves for Primality Proving.', 2011),\n",
              " ('Cramer-Shoup Public-Key System.', 2011),\n",
              " ('Privacy Protection in Biometric Systems.', 2011),\n",
              " ('ISO 15408 CC - Common Criteria.', 2011),\n",
              " ('Stream and Multicast Authentication.', 2011),\n",
              " ('Greatest Common Divisor.', 2011),\n",
              " ('Online Analytical Processing.', 2011),\n",
              " ('Logic-Based Authorization Languages.', 2011),\n",
              " ('Uncoordinated Frequency Hopping Spread Spectrum.', 2011),\n",
              " ('SQL Access Control Model.', 2011),\n",
              " ('CBC-MAC and Variants.', 2011),\n",
              " ('Data Mining (Privacy in).', 2011),\n",
              " ('Schnorr Identification Protocol.', 2011),\n",
              " ('Entity Authentication Protocol.', 2011),\n",
              " ('Nonlinear Feedback Shift Register.', 2011),\n",
              " ('Certificate of Primality.', 2011),\n",
              " ('Consistency Verification of Security Policy.', 2011),\n",
              " ('Web Vulnerability Assessment.', 2011),\n",
              " ('UMTS IC Card.', 2011),\n",
              " ('Web Application Security.', 2011),\n",
              " ('Number Field Sieve for the DLP.', 2011),\n",
              " ('Security of Web Browser Scripting Languages.', 2011),\n",
              " ('Everywhere Second Preimage Resistant Hash Function (esec).', 2011),\n",
              " ('Group Key Agreement.', 2011),\n",
              " ('Access Control Policies, Models, and Mechanisms.', 2011),\n",
              " ('HTTP Basic Authentication.', 2011),\n",
              " ('Access Control from an OS Security Perspective.', 2011),\n",
              " ('Human Ear Verification.', 2011),\n",
              " ('Malware Behavior Clustering.', 2011),\n",
              " ('Elliptic Curve Signature Schemes.', 2011),\n",
              " ('ISO-9796 Signature Standards.', 2011),\n",
              " ('Dynamic Separation of Duties.', 2011),\n",
              " ('Diffie-Hellman Key Agreement.', 2011),\n",
              " ('Cryptography on Reconfigurable Devices.', 2011),\n",
              " ('Microdata Disclosure Protection.', 2011),\n",
              " ('Public Key Cryptography.', 2011),\n",
              " ('Flexible Authorization Framework (FAF).', 2011),\n",
              " ('Multilevel Security Policies.', 2011),\n",
              " ('Mandatory Access Control.', 2011),\n",
              " ('Function Field Sieve.', 2011),\n",
              " ('Error-Correcting Cyclic Codes.', 2011),\n",
              " ('Web Cache Poisoning Attacks.', 2011),\n",
              " ('Program Verification and Security.', 2011),\n",
              " ('SYN Cookie Defense.', 2011),\n",
              " ('Broadcast Authentication from a Conditional Perspective.', 2011),\n",
              " ('Algorithmic Complexity Attacks.', 2011),\n",
              " ('Information Security Management System.', 2011),\n",
              " ('Mandatory Access Control Policy (MAC).', 2011),\n",
              " ('MASH Hash Functions (Modular Arithmetic Secure Hash).', 2011),\n",
              " ('Speaker Identification and Verification (SIV).', 2011),\n",
              " ('Privacy-Aware Access Control Policies.', 2011),\n",
              " ('Secure Wireless Multicast.', 2011),\n",
              " ('Knapsack Cryptographic Schemes.', 2011),\n",
              " ('Antispam Based on Sender Reputation.', 2011),\n",
              " ('Index Calculus Method.', 2011),\n",
              " ('Random Number Testing.', 2011),\n",
              " ('Script Language Security.', 2011),\n",
              " ('Elliptic Curve Key Agreement Schemes.', 2011),\n",
              " ('Web Session Security.', 2011),\n",
              " ('Memory and State Exhaustion DoS.', 2011),\n",
              " ('Optimal Extension Fields (OEFs).', 2011),\n",
              " ('One Time Password, from a Key Management Perspective.', 2011),\n",
              " ('Perfect Forward Secrecy.', 2011),\n",
              " ('Private Information Retrieval.', 2011),\n",
              " ('Key Life Cycle Management.', 2011),\n",
              " ('Exhaustive Key Search.', 2011),\n",
              " ('Strong RSA Assumption.', 2011),\n",
              " ('Packet Flooding Attack.', 2011),\n",
              " ('Formal Methods and Access Control.', 2011),\n",
              " ('Tripartite Key Exchange.', 2011),\n",
              " ('von Neumann Correction.', 2011),\n",
              " (\"Ron's Code 5.\", 2011),\n",
              " ('Web Access Control Strategies.', 2011),\n",
              " ('Measurement Models of Software Security.', 2011),\n",
              " ('Linear Congruential Generator.', 2011),\n",
              " ('Identity Verification Protocol.', 2011),\n",
              " ('Pseudorandom Number Generator.', 2011),\n",
              " ('Multiplicative Knapsack Cryptosystem.', 2011),\n",
              " ('Hyperelliptic Curves Performance.', 2011),\n",
              " ('SYN Flood Attack.', 2011),\n",
              " ('Information Flow and Noninterference.', 2011),\n",
              " ('Web Client Security and Privacy.', 2011),\n",
              " ('C2 - Block Cipher.', 2011),\n",
              " ('Algebraic Number Field.', 2011),\n",
              " ('Secret Sharing Schemes.', 2011),\n",
              " ('Designated Confirmer Signature.', 2011),\n",
              " ('RSA Public-Key Encryption.', 2011),\n",
              " ('Spam Detection Using Network-Level Characteristics.', 2011),\n",
              " ('Privileges in SQL.', 2011),\n",
              " ('Site Characterization Using GP, MARS and GPR.', 2015),\n",
              " ('Genetically Improved Software.', 2015),\n",
              " ('Mate Choice in Evolutionary Computation.', 2015),\n",
              " ('Genetic Programming Applications in Chemical Sciences and Engineering.',\n",
              "  2015),\n",
              " ('Evolving GP Classifiers for Streaming Data Tasks with Concept Change and Label Budgets: A Benchmarking Study.',\n",
              "  2015),\n",
              " ('Design of Real-Time Computer-Based Systems Using Developmental Genetic Programming.',\n",
              "  2015),\n",
              " ('Potential of Genetic Programming in Hydroclimatic Prediction of Droughts: An Indian Perspective.',\n",
              "  2015),\n",
              " ('Genetic Programming for Modelling of Geotechnical Engineering Systems.',\n",
              "  2015),\n",
              " ('Application of GFA-MLR and G/PLS Techniques in QSAR/QSPR Studies with Application in Medicinal Chemistry and Predictive Toxicology.',\n",
              "  2015),\n",
              " ('Graph-Based Evolutionary Art.', 2015),\n",
              " ('Genetic Programming for Mining Association Rules in Relational Database Environments.',\n",
              "  2015),\n",
              " ('Application of Genetic Programming in Hydrology.', 2015),\n",
              " ('Handbook of Genetic Programming Applications', 2015),\n",
              " ('Application of Genetic Programming for Uniaxial and Multiaxial Modeling of Concrete.',\n",
              "  2015),\n",
              " ('Application of Gene-Expression Programming in Hydraulic Engineering.',\n",
              "  2015),\n",
              " ('On the Application of Genetic Programming for New Generation of Ground Motion Prediction Equations.',\n",
              "  2015),\n",
              " ('A New Evolutionary Approach to Geotechnical and Geo-Environmental Modelling.',\n",
              "  2015),\n",
              " ('Image Classification with Genetic Programming: Building a Stage 1 Computer Aided Detector for Breast Cancer.',\n",
              "  2015),\n",
              " ('Trading Volatility Using Highly Accurate Symbolic Regression.', 2015),\n",
              " ('Use of Genetic Programming Based Surrogate Models to Simulate Complex Geochemical Transport Processes in Contaminated Mine Sites.',\n",
              "  2015),\n",
              " ('GPTIPS 2: An Open-Source Software Platform for Symbolic Data Mining.',\n",
              "  2015),\n",
              " ('eCrash: a Genetic Programming-Based Testing Tool for Object-Oriented Software.',\n",
              "  2015),\n",
              " ('Application of Genetic Programming for Electrical Engineering Predictive Modeling: A Review.',\n",
              "  2015),\n",
              " ('Evaluation of Liquefaction Potential of Soil Based on Shear Wave Velocity Using Multi-Gene Genetic Programming.',\n",
              "  2015),\n",
              " ('Gerontological Perspectives on Ambient Assisted Living.', 2012),\n",
              " ('Utilization of Cloud Infrastructures for Pervasive Healthcare Applications.',\n",
              "  2012),\n",
              " ('Preparation and Start-Up Phase of the European AAL Joint Programme.', 2012),\n",
              " ('Housing, Gerontology and AAL: New Services Development.', 2012),\n",
              " ('Innovative Rehabilitation Technologies for Home Environments - An Overview.',\n",
              "  2012),\n",
              " ('Home-Based Computer Vision Access Technologies for Individuals with Severe Motor Impairments.',\n",
              "  2012),\n",
              " ('Happy Healthy Home.', 2012),\n",
              " ('AAL in the Health Space - A Reflection.', 2012),\n",
              " ('The Role of Assistive Technology in Supporting Formal Carers.', 2012),\n",
              " ('Introduction to Section on AAL for Rehabilitation.', 2012),\n",
              " ('The universAAL Reference Model for AAL.', 2012),\n",
              " (\"New Ambient Assistive Technologies: The Users' Perspectives.\", 2012),\n",
              " ('Smart Homes as a Vehicle for AAL.', 2012),\n",
              " (\"R&amp;D Projects Related to AAL in TECNALIA's Health Technologies Unit.\",\n",
              "  2012),\n",
              " ('Smart Home Technologies for People with Cognitive Impairment: An Affordable, Rehabilitative Approach.',\n",
              "  2012),\n",
              " ('Introduction to Section on Future Developments and Visions for the AAL Area.',\n",
              "  2012),\n",
              " ('The National Health Service in England - Moving to Mainstream Use of Ambient Assisted Living Technology.',\n",
              "  2012),\n",
              " ('Biometrics in Healthcare - A Research Overview.', 2012),\n",
              " ('Ambient Assisted Living Technology to Support Older Adults with Dementia with Activities of Daily Living: Key Concepts and the State of the Art.',\n",
              "  2012),\n",
              " ('Smart Living Environment: Ubiquitous Computing Approach Based on TRON Architecture.',\n",
              "  2012),\n",
              " ('Study on Future Trend of the Elderly Care from the Aspect of Assistive Technology Rental System in Japan.',\n",
              "  2012),\n",
              " ('Social Spaces for Reseach and Innovation (SSRI): Users Leading Research and Innovation in Ambient Assisted Living.',\n",
              "  2012),\n",
              " ('Medical Information Management with ECG Biometrics: A Secure and Effective Framework.',\n",
              "  2012),\n",
              " ('Connecting Communities: The Role of Design Ethnography in Developing Social Care Technologies for Isolated Older Adults.',\n",
              "  2012),\n",
              " ('SmartSenior - Intelligent Services for Senior Citizens.', 2012),\n",
              " ('Biometric Monitoring of Behaviour.', 2012),\n",
              " ('Managing Chronic Conditions Using Wireless Sensor Networks.', 2012),\n",
              " ('Delivering Technology Enriched Health and Social Care: Policy Context for User Focused Research.',\n",
              "  2012),\n",
              " ('Gait Profile - A Biometric that Defines Our Mobility.', 2012),\n",
              " ('Electronic-Early Warning Scorecard: An Intelligent Context Aware Decision Making Approach for Patient Monitoring.',\n",
              "  2012),\n",
              " ('Face Recognition in Ambient Intelligence Applications.', 2012),\n",
              " ('ICT Infrastructures for Telerehabilitation.', 2012),\n",
              " ('Sensor Selection to Support Practical Use of Health-Monitoring Smart Environments.',\n",
              "  2012),\n",
              " ('Beyond System Integration: Who, What, How, and When.', 2012),\n",
              " ('Growing Older Together: When a Robot Becomes the Best Ally for Ageing Well.',\n",
              "  2012),\n",
              " ('Assisted Ambient Living Applied to Remote Motor Rehabilitation.', 2012),\n",
              " ('Devices and Infrastructure to Facilitate AAL.', 2012),\n",
              " ('AAL Technologies in Rehabilitation - Lessons Learned from a COPD Case Study.',\n",
              "  2012),\n",
              " ('Monitoring Patterns of Inactivity in the Home with Domotics Networks.',\n",
              "  2012),\n",
              " ('LiKeIT - RFID-Based KeepInTouch Lifestyle Monitoring.', 2012),\n",
              " ('In-Home Monitoring Technologies: Perspectives and Priorities of Older Adults.',\n",
              "  2012),\n",
              " ('Handbook of Ambient Assisted Living - Technology for Healthcare, Rehabilitation and Well-being',\n",
              "  2012),\n",
              " ('AAL Markets - Knowing Them, Reaching Them. Evidence from European Research.',\n",
              "  2012),\n",
              " ('Designing Ambient and Personalised Displays to Encourage Healthier Lifestyles.',\n",
              "  2012),\n",
              " ('Using Human Factors to Guide the Design and Implementation of Consumer Health Informatics Interventions.',\n",
              "  2012),\n",
              " ('Adaptive Neck Support for Wellbeing During Air Travel.', 2012),\n",
              " ('AAL in Cardiac Rehabilitation.', 2012),\n",
              " ('Supporting Wellbeing Through Improving Interactions and Understanding in Self-Monitoring Systems.',\n",
              "  2012),\n",
              " ('Telehealthcare Development &amp; Effectiveness in Taiwan.', 2012),\n",
              " ('Tracking Natural Human Movements Identifies Differences in Cognition and Health.',\n",
              "  2012),\n",
              " ('Optimizing Targeting of Intrusion Detection Systems in Social Networks.',\n",
              "  2010),\n",
              " ('Multi-Relational Characterization of Dynamic Social Network Communities.',\n",
              "  2010),\n",
              " ('Decentralized Online Social Networks.', 2010),\n",
              " ('Security Requirements for Social Networks in Web 2.0.', 2010),\n",
              " ('Understanding and Predicting Human Behavior for Social Communities.', 2010),\n",
              " ('Structure and Dynamics of Social Networks Revealed by Data Analysis of Actual Communication Services.',\n",
              "  2010),\n",
              " ('Perspectives on Social Network Analysis for Observational Scientific Data.',\n",
              "  2010),\n",
              " ('Online Identities and Social Networking.', 2010),\n",
              " ('Concept Discovery in Youtube.com Using Factorization Method.', 2010),\n",
              " ('Analyzing the Dynamics of Communication in Online Social Networks.', 2010),\n",
              " ('Social Network Analysis: History, Concepts, and Research.', 2010),\n",
              " ('Discovering Mobile Social Networks by Semantic Technologies.', 2010),\n",
              " ('Applications of Social Network Analysis.', 2010),\n",
              " ('Associating Human-Centered Concepts with Social Networks Using Fuzzy Sets.',\n",
              "  2010),\n",
              " ('Visualization of Social Networks.', 2010),\n",
              " ('Accessibility Testing of Social Websites.', 2010),\n",
              " ('Security and Privacy in Online Social Networks.', 2010),\n",
              " ('Analysis of Social Networks by Tensor Decomposition.', 2010),\n",
              " ('Managing Trust in Online Social Networks.', 2010),\n",
              " ('Modeling Temporal Variation in Social Network: An Evolutionary Web Graph Approach.',\n",
              "  2010),\n",
              " ('Novel Visualizations and Interactions for Social Networks Exploration.',\n",
              "  2010),\n",
              " ('Analysis of Social Networks Extracted from Log Files.', 2010),\n",
              " ('Online Advertising in Social Networks.', 2010),\n",
              " (\"Social Bookmarking on a Company's Intranet: A Study of Technology Adoption and Diffusion.\",\n",
              "  2010),\n",
              " ('Qualitative Analysis of Commercial Social Network Profiles.', 2010),\n",
              " ('Detecting Communities in Social Networks.', 2010),\n",
              " ('Discovering Communities from Social Networks: Methodologies and Applications.',\n",
              "  2010),\n",
              " ('Churn in Social Networks.', 2010),\n",
              " ('Mining Regional Representative Photos from Consumer-Generated Geotagged Photos.',\n",
              "  2010),\n",
              " ('Investigation of Key-Player Problem in Terrorist Networks Using Bayes Conditional Probability.',\n",
              "  2010),\n",
              " ('Collaborative Filtering Based on Choosing a Different Number of Neighbors for Each User.',\n",
              "  2010),\n",
              " ('Handbook of Social Network Technologies and Applications', 2010),\n",
              " ('Augmented Reality for Maintenance.', 2019),\n",
              " ('Overview of Artificial Intelligence.', 2019),\n",
              " ('Game Bot Detection on Massive Multiplayer Online Role-Playing Games (MMORPGs) Systems.',\n",
              "  2019),\n",
              " ('Crowd Evacuation Using Simulation Techniques.', 2019),\n",
              " ('Augmented Reality in Image-Guided Surgery.', 2019),\n",
              " ('MEEGA+, Systematic Model to Evaluate Educational Games.', 2019),\n",
              " ('Overview of Virtual Ambisonic Systems.', 2019),\n",
              " ('Motion Planning in Computer Games.', 2019),\n",
              " ('Uncanny Valley in Virtual Reality.', 2019),\n",
              " ('Multi-user Virtual Environments for Education.', 2019),\n",
              " ('Computer Games and Artificial Intelligence.', 2019),\n",
              " ('Semiotics of Computer Games.', 2019),\n",
              " ('Game Thinking X Game Design Thinking.', 2019),\n",
              " ('Stress Reduction, Relaxation, and Meditative States Using Psychophysiological Measurements Based on Biofeedback Systems via HRV and EEG.',\n",
              "  2019),\n",
              " ('Abstraction and Stylized Design in 3D Animated Films: Extrapolation of 2D Animation Design.',\n",
              "  2019),\n",
              " ('Computer Games in Education.', 2019),\n",
              " ('Timed Automata for Video Games and Interaction.', 2019),\n",
              " ('Artistic Data Visualization in the Making.', 2019),\n",
              " ('Games and Active Aging.', 2019),\n",
              " ('Game Interface: Influence of Diegese Theory on the User Experience.', 2019),\n",
              " ('Bounding Volume Hierarchies for Rigid Bodies.', 2019),\n",
              " ('Animation and Neurocinematics: Visible Language of E-motion-S and Its Magical Science.',\n",
              "  2019),\n",
              " ('Educational Virtual Reality Game Design for Film and Animation.', 2019),\n",
              " ('Encyclopedia of Computer Graphics and Games.', 2019),\n",
              " ('Redesigning Games for New Interfaces and Platforms.', 2019),\n",
              " ('Games in Science.', 2019),\n",
              " ('Player-Avatar Link: Interdisciplinary Embodiment Perspectives.', 2019),\n",
              " ('Interactive Augmented Reality to Support Education.', 2019),\n",
              " ('Post-Digital Graphics in Computer Games.', 2019),\n",
              " ('Detecting and Preventing Online Game Bots in MMORPGs.', 2019),\n",
              " ('Griefing in MMORPGs.', 2019),\n",
              " ('Games and the Magic Circle.', 2019),\n",
              " ('Player Personas and Game Choice.', 2019),\n",
              " (\"Children's Games, from Turtle to Squirtle.\", 2019),\n",
              " ('Virtual Reality Applications in Education.', 2019),\n",
              " ('Video Game Storytelling Fundamentals: Setting, Power Status, Tone, Escalation.',\n",
              "  2019),\n",
              " ('Sonic Interactions in Virtual Environments.', 2019),\n",
              " ('Mixed Reality, Gamified Presence, and Storytelling for Virtual Museums.',\n",
              "  2019),\n",
              " ('Public Health Education Via Computer Games.', 2019),\n",
              " ('Tactile Visualization and 3D Printing for Education.', 2019),\n",
              " ('Interaction with Mobile Augmented Reality Environments.', 2019),\n",
              " ('Children Privacy Protection.', 2019),\n",
              " ('Virtual Reality-Based Daily Scrum Meetings.', 2019),\n",
              " ('Biosensing in Interactive Art: A User-Centered Taxonomy.', 2019),\n",
              " ('Redirected Walking in Virtual Reality.', 2019),\n",
              " ('StarCraft Bots and Competitions.', 2019),\n",
              " ('Gamification and Serious Games.', 2019),\n",
              " ('Accessibility of Virtual Reality for Persons with Disabilities.', 2019),\n",
              " (\"Gamification of Modern Society: Digital Media's Influence on Current Social Practices.\",\n",
              "  2019),\n",
              " ('Computer Games and the Evolution of Digital Rights.', 2019),\n",
              " ('Lattice Boltzmann Method for Diffusion-Reaction Problems.', 2019),\n",
              " ('Foundations of Interaction in the Virtual Reality Medium.', 2019),\n",
              " ('Narrative in Video Games.', 2019),\n",
              " ('Analog Prototyping for Digital Game Design.', 2019),\n",
              " ('Key Early Verticals, Challenges and Limitations in Implementation of Augmented Reality.',\n",
              "  2019),\n",
              " ('Comic Arts in Games, Asset Production, and Rendering.', 2019),\n",
              " ('Skull and Roses Card Game.', 2019),\n",
              " ('Exploring Innovative Technology: 2D Image Based Animation with the iPad.',\n",
              "  2019),\n",
              " ('Information Presentation Methods in Virtual Reality.', 2019),\n",
              " ('Open Source 3D Printing, History of.', 2019),\n",
              " ('Virtual Reality System Fidelity.', 2019),\n",
              " ('Mobile Cloud Gaming.', 2019),\n",
              " ('3D Visualization Interface for Temporal Analysis of Social Media.', 2019),\n",
              " ('Collaborative Engineering and Virtual Prototyping Within Virtual Reality.',\n",
              "  2019),\n",
              " ('3D Printing, History of.', 2019),\n",
              " ('Everyday Virtual Reality.', 2019),\n",
              " ('Virtual Pointing Metaphor in Virtual Reality.', 2019),\n",
              " ('Physical, Virtual, and Game World Persistence.', 2019),\n",
              " ('Potential of Augmented Reality for Intelligent Transportation Systems.',\n",
              "  2019),\n",
              " ('Game-Based Interventions in Public Health: Exploiting the Engaging Factor of Gameplay.',\n",
              "  2019),\n",
              " ('Hypermedia Narrative as a Tool for Serious Games.', 2019),\n",
              " ('Cloud for Gaming.', 2019),\n",
              " ('Cognitive Psychology Applied to User Experience in Video Games.', 2019),\n",
              " ('Videogame Engagement: Psychological Frameworks.', 2019),\n",
              " ('3D-Rendered Images and Their Application in the Interior Design.', 2019),\n",
              " ('3D Modelling Through Photogrammetry in Cultural Heritage.', 2019),\n",
              " ('Virtual Hand Metaphor in Virtual Reality.', 2019),\n",
              " ('Training Spatial Skills with Virtual Reality and Augmented Reality.', 2019),\n",
              " ('Face Beautification in Antiage.', 2019),\n",
              " ('Virtual Reality as New Media.', 2019),\n",
              " ('Perceptual Illusions and Distortions in Virtual Reality.', 2019),\n",
              " ('3D Room Layout System Using IEC (Interactive Evaluational Computation).',\n",
              "  2019),\n",
              " ('Movie-Making of Spatiotemporal Dynamics in Complex Systems.', 2019),\n",
              " ('Procedural Audio in Video Games.', 2019),\n",
              " ('Online Gaming Scalability.', 2019),\n",
              " ('Integrating Virtual Reality and Augmented Reality into Advertising Campaigns: History, Technology, and Future Trends.',\n",
              "  2019),\n",
              " ('Emotional Congruence in Video Game Audio.', 2019),\n",
              " ('Augmented Learning Experience for School Education.', 2019),\n",
              " (\"Game Writer's Dilemma: Context vs. Story.\", 2019),\n",
              " ('Interacting with a Fully Simulated Self-Balancing Bipedal Character in Augmented and Virtual Reality.',\n",
              "  2019),\n",
              " ('Challenge-Based Learning in a Serious Global Game.', 2019),\n",
              " ('Lattice Boltzmann Method for Fluid Simulation.', 2019),\n",
              " ('Online Players: Engagement, Immersion, and Absorption Across Secondary Worlds.',\n",
              "  2019),\n",
              " ('Multivariate Visualization Using Scatterplots.', 2019),\n",
              " ('Virtual Reality Game Engines.', 2019),\n",
              " (\"Social-, Mobile- and Multi-Player-Games and their Impact on Today's Online Entertainment Industry.\",\n",
              "  2019),\n",
              " ('Cellular Automata Methods.', 2019),\n",
              " ('Emotion-Based 3D CG Character Behaviors.', 2019),\n",
              " ('Conceptual Model of Mobile Augmented Reality for Cultural Heritage.', 2019),\n",
              " ('Social Virtual Reality.', 2019),\n",
              " ('Holography as an Architectural Decoration.', 2019),\n",
              " ('Lattice Gas Cellular Automata for Fluid Simulation.', 2019),\n",
              " ('Monte-Carlo Tree Search.', 2019),\n",
              " ('Mixed Reality and Immersive Data Visualization.', 2019),\n",
              " ('Contemporary Computer Shogi.', 2019),\n",
              " ('History of Virtual Reality.', 2019),\n",
              " ('Presence and Immersion in Virtual Reality.', 2019),\n",
              " ('Virtual Reality Stereo Post-Conversion After Effects Workflow.', 2019),\n",
              " ('Client/Server Gaming Architectures.', 2019),\n",
              " ('Teaching Computer Graphics by Application.', 2019),\n",
              " ('Position Based Dynamics.', 2019),\n",
              " ('Distributed Simulation and Games.', 2019),\n",
              " ('Digital Games for Animals.', 2019),\n",
              " ('Area of Interest Management in Massively Multiplayer Online Games.', 2019),\n",
              " ('Image Quality Evaluation of a Computer-Generated Phase Hologram.', 2019),\n",
              " ('Tensor Field Visualization.', 2019),\n",
              " ('Genetic Algorithm (GA)-Based NPC Making.', 2019),\n",
              " ('Online Gaming Architectures.', 2019),\n",
              " ('Constructing Game Agents Through Simulated Evolution.', 2019),\n",
              " ('2-Simplex Prism as a Cognitive Graphics Tool for Decision-Making.', 2019),\n",
              " ('Raycasting in Virtual Reality.', 2019),\n",
              " ('Design of Alienation in Video Games.', 2019),\n",
              " ('Sketch-Based Posing for 3D Animation.', 2019),\n",
              " ('Scalable Techniques to Visualize Spatiotemporal Data.', 2019),\n",
              " ('Theory of Minkowski-Lorentz Spaces.', 2019),\n",
              " ('Mindfulness, Virtual Reality, and Video Games.', 2019),\n",
              " ('Origin of Games.', 2019),\n",
              " ('Interactive Virtual Reality Navigation Using Cave Automatic Virtual Environment Technology.',\n",
              "  2019),\n",
              " ('Dynamic Music Generation, Audio Analysis-Synthesis Methods.', 2019),\n",
              " ('Locomotion in Virtual Reality Video Games.', 2019),\n",
              " ('Psychological Game Design.', 2019),\n",
              " ('Immersive Auralization Using Headphones.', 2019),\n",
              " ('Character Animation Scripting Environment.', 2019),\n",
              " ('UV Map Generation on Triangular Mesh.', 2019),\n",
              " ('Game Loop and Typical Implementation.', 2019),\n",
              " ('Shape Deformation Models.', 2019),\n",
              " ('Political Game Design.', 2019),\n",
              " ('Origin of Virtual Reality.', 2019),\n",
              " ('Game Design and Emotions: Analysis Models.', 2019),\n",
              " ('Game Development Leadership Tips.', 2019),\n",
              " ('Plug-in-Based Asset Compiler Architecture.', 2019),\n",
              " ('User-Centered Design and Evaluation Methodology for Virtual Environments.',\n",
              "  2019),\n",
              " ('Immersive Technologies for Medical Education.', 2019),\n",
              " ('Game Player Modeling.', 2019),\n",
              " ('Challenges Facing the Arab Animation Cinema.', 2019),\n",
              " ('History of Augmented Reality.', 2019),\n",
              " ('Virtual World, a Definition Incorporating Distributed Computing and Instances.',\n",
              "  2019),\n",
              " ('Modeling and Mesh Processing for Games.', 2019),\n",
              " ('RTS AI Problems and Techniques.', 2019),\n",
              " ('Postproduction in Game Cinematics.', 2019),\n",
              " ('STEM Learning Through Video Games.', 2019),\n",
              " ('Virtual Reality Therapy.', 2019),\n",
              " ('Natural Walking in Virtual Reality.', 2019),\n",
              " ('Eye Tracking in Virtual Reality.', 2019),\n",
              " ('Augmented Reality Entertainment: Taking Gaming Out of the Box.', 2019),\n",
              " ('Technologies for the Design Review Process.', 2019),\n",
              " ('User Acoustics with Head-Related Transfer Functions.', 2019),\n",
              " ('Immersive Virtual Reality Serious Games.', 2019),\n",
              " ('Shadow Shooter: All-Around Game with e-Yumi 3D.', 2019),\n",
              " ('Interactive Computer Graphics and Model-View-Controller Architecture.',\n",
              "  2019),\n",
              " ('Gamification in Crowdsourcing Applications.', 2019),\n",
              " ('Video Game Trolls and Dopamine Withdrawal.', 2019),\n",
              " ('Computer Graphics, Video Games, and Gamification Impacting (Re)Habilitation, Healthcare, and Inclusive Well-Being.',\n",
              "  2019),\n",
              " ('Facial Recognition and Emotion Detection in Environmental Installation and Social Media Applications.',\n",
              "  2019),\n",
              " ('Pipeline of 2D Vector Animation in Television Series.', 2019),\n",
              " ('Augmented Reality for Human-Robot Interaction in Industry.', 2019),\n",
              " ('The New Age of Procedural Texturing.', 2019),\n",
              " ('Cognitive Processing of Information Visualization.', 2019),\n",
              " ('Spatial Perception in Virtual Environments.', 2019),\n",
              " ('Virtual Reality Retailing.', 2019),\n",
              " ('Decoupling Game Tool GUIs from Core Editing Operations.', 2019),\n",
              " ('Secure Gaming: Cheat-Resistant Protocols and Game History Validation.',\n",
              "  2019),\n",
              " ('Game Physics Engine, Overview.', 2019),\n",
              " ('Virtual Reality Exercise and Rehabilitation.', 2019),\n",
              " ('Computational Modeling of Olfactory Behavior.', 2014),\n",
              " ('Somatosensory Cortex: Neural Coding of Shape.', 2014),\n",
              " ('Population Density Models.', 2014),\n",
              " ('Biochemical Signaling Pathways and Diffusion: Overview.', 2014),\n",
              " ('Control of Aquatic and Terrestrial Gaits in Salamander.', 2014),\n",
              " ('Decision Making, Threshold.', 2014),\n",
              " ('Visual Prosthesis, Optic Nerve Approaches.', 2014),\n",
              " ('Applications of Information Theory to Analysis of Neural Data.', 2014),\n",
              " ('Hippocampal Memory Prosthesis.', 2014),\n",
              " ('Multi-objective Evolutionary Algorithms.', 2014),\n",
              " ('Network Theory in Neuroscience.', 2014),\n",
              " ('Functional Neuroscience: Cortical Control of Limb Prosthesis.', 2014),\n",
              " ('Attentional Top-Down Modulation, Models of.', 2014),\n",
              " ('Visual Prosthesis, Epiretinal Devices.', 2014),\n",
              " ('Synthetic Neuronal Circuits/Networks.', 2014),\n",
              " ('Bursting in Neurons and Small Networks.', 2014),\n",
              " ('Numerical Integration Methods.', 2014),\n",
              " ('Neuronal Model Databases.', 2014),\n",
              " ('Acoustic Timbre Recognition.', 2014),\n",
              " ('Finite Element Models of Transcutaneous Spinal Cord Stimulation.', 2014),\n",
              " ('Basal Ganglia: Overview.', 2014),\n",
              " ('Brain Ischemia and Stroke.', 2014),\n",
              " ('Pattern Formation in Neural Population Models.', 2014),\n",
              " ('Electrophysiological Indices of Speech Processing.', 2014),\n",
              " ('Basal Ganglia: Habit Formation.', 2014),\n",
              " ('Mixed-Mode Oscillations in Single Neurons.', 2014),\n",
              " ('Spindle Oscillations: Models.', 2014),\n",
              " ('Bifurcations Dynamics of Single Neurons and Small Networks.', 2014),\n",
              " ('Auditory Sensing Systems: Overview.', 2014),\n",
              " ('Neuroimaging, Neural Population Models for.', 2014),\n",
              " ('Reward-Based Learning, Model-Based and Model-Free.', 2014),\n",
              " ('Dendritic Spines: Continuum Theory.', 2014),\n",
              " ('Optic Flow Processing.', 2014),\n",
              " ('Long-Term Plasticity, Biophysical Models.', 2014),\n",
              " ('Directed Information Flow and Causality in Neural Systems.', 2014),\n",
              " ('Down Under Neural Population Models.', 2014),\n",
              " ('Pathological Changes in Peripheral Nerve Excitability.', 2014),\n",
              " ('MOOSE, the Multiscale Object-Oriented Simulation Environment.', 2014),\n",
              " ('Collision Avoidance Models, Visually Guided.', 2014),\n",
              " ('Vestibular Adaptation and Compensation.', 2014),\n",
              " ('Migraines and Cortical Spreading Depression.', 2014),\n",
              " ('Pitch Perception, Models.', 2014),\n",
              " ('Sound Localization in Mammals, Models.', 2014),\n",
              " ('Dopaminergic Cell Models.', 2014),\n",
              " ('Metabotropic Receptors Dynamics, Conductance Models.', 2014),\n",
              " ('Bayesian Approaches in Computational Neuroscience: Overview.', 2014),\n",
              " ('Perceptual Decision Making.', 2014),\n",
              " ('Spatial Spectral Analysis.', 2014),\n",
              " ('Synaptic Connectivity in Neural Population Models.', 2014),\n",
              " ('Bayesian Inference with Spiking Neurons.', 2014),\n",
              " ('Inverse Problems in Neural Population Models.', 2014),\n",
              " ('Reinforcement Learning in Cortical Networks.', 2014),\n",
              " ('Thermodynamic Models of Ion Channels.', 2014),\n",
              " ('Basal Ganglia System as an Engine for Exploration.', 2014),\n",
              " ('Peripheral Nerve Interface Applications, Obesity.', 2014),\n",
              " ('AMPA Glutamate Receptor (AMPA Receptor), Conductance Models.', 2014),\n",
              " ('Methodologies for the Treatment of Pain.', 2014),\n",
              " ('Multistability of Coupled Neuronal Oscillators.', 2014),\n",
              " ('Cutaneous Mechanoreceptive Afferents: Neural Coding of Texture.', 2014),\n",
              " ('Retinal Waves, Models of.', 2014),\n",
              " ('Computational Models of Deep Brain Stimulation (DBS).', 2014),\n",
              " ('Central Vestibular Signal Processing.', 2014),\n",
              " ('Hybrid Parameter Optimization Methods.', 2014),\n",
              " ('Spectral Interdependency Methods.', 2014),\n",
              " ('Behavioural Analysis, Bayesian.', 2014),\n",
              " ('Peripheral Nerve Interface Applications: Vagal Nerve Stimulation.', 2014),\n",
              " ('Local Field Potential, Methods of Recording.', 2014),\n",
              " ('Visual Illusions, Models of.', 2014),\n",
              " ('Open Source Brain.', 2014),\n",
              " ('Dynamic Causal Modeling with Neural Population Models.', 2014),\n",
              " ('Peripheral Nerve Interface Applications, EMG/ENG.', 2014),\n",
              " ('Vestibular Eye Movement Testing.', 2014),\n",
              " ('Modeling the Axon.', 2014),\n",
              " ('Gillespie Algorithm for Biochemical Reaction Simulation.', 2014),\n",
              " ('Finite Element Modeling of Electrical Stimulation Using Microelectrodes.',\n",
              "  2014),\n",
              " ('Olfactory Computation in Antennal Lobe and Mushroom Bodies.', 2014),\n",
              " ('Lateral Geniculate Nucleus (LGN) Models.', 2014),\n",
              " ('Spectral Methods in Neural Data Analysis: Overview.', 2014),\n",
              " ('Decision Making: Overview.', 2014),\n",
              " ('Computational Models Supporting Parameter Finding for Deep Brain Stimulation.',\n",
              "  2014),\n",
              " ('Generalized Linear Models for Point Process Analyses of Neural Spiking Activity.',\n",
              "  2014),\n",
              " ('Neuronal Parameter Co-regulation.', 2014),\n",
              " ('Bifurcations, Neural Population Models and.', 2014),\n",
              " ('Retinotopic Development, Models of.', 2014),\n",
              " ('Statistical Analysis of Neuroimaging Data.', 2014),\n",
              " ('Systems Biology Markup Language (SBML).', 2014),\n",
              " ('Tactile Sensing in Insects.', 2014),\n",
              " ('Chaos, Neural Population Models and.', 2014),\n",
              " ('Spatiotemporal Energy Models.', 2014),\n",
              " ('Control of Locomotion and Scratching in Turtles.', 2014),\n",
              " ('Working Memory, Models of.', 2014),\n",
              " ('Peripheral Nerve Interface Applications, Sleep Apnea.', 2014),\n",
              " ('Basal Ganglia: Songbird Models.', 2014),\n",
              " ('Corticothalamic Feedback: Large-Scale Synchrony.', 2014),\n",
              " ('Forward and Inverse Problems of MEG/EEG.', 2014),\n",
              " ('Radiopharmaceuticals in Molecular Imaging.', 2014),\n",
              " ('Application of Declarative Programming in Neurobiology.', 2014),\n",
              " ('Multistability Arising from Synaptic Dynamics.', 2014),\n",
              " ('Time-Delayed Neural Networks: Stability and Oscillations.', 2014),\n",
              " ('Reconstruction, Electron Microscopy.', 2014),\n",
              " ('Brain Architecture Management System (BAMS).', 2014),\n",
              " ('Visual Prosthesis, Optogenetic Approaches.', 2014),\n",
              " ('Connectionist Models of CPG Networks.', 2014),\n",
              " ('Voltage-Sensitive Dye Imaging, Intrinsic Optical Signals.', 2014),\n",
              " ('Rhythm Generation in Embryonic Chick Spinal Cord.', 2014),\n",
              " ('Hippocampal Theta, Gamma, and Theta/Gamma Network Models.', 2014),\n",
              " ('Short Term Plasticity, Biophysical Models.', 2014),\n",
              " ('Local Field Potential and Movement Disorders.', 2014),\n",
              " ('Vestibular Prosthesis, Interface.', 2014),\n",
              " ('Local Field Potential, Ephaptic Interactions.', 2014),\n",
              " ('Reduced Morphology Models.', 2014),\n",
              " ('Multiscale Brain Connectivity.', 2014),\n",
              " ('Neuronal Parameter Sensitivity.', 2014),\n",
              " ('Facilitation, Biophysical Models.', 2014),\n",
              " ('Pain Processing Pathway Models.', 2014),\n",
              " ('Receptive Field Modeling.', 2014),\n",
              " ('Modeling of Disease: Molecular Level, Overview.', 2014),\n",
              " ('Anatomy and Physiology of the Mammalian Auditory System.', 2014),\n",
              " ('Gamma Rhythm, Neural Population Models of the.', 2014),\n",
              " ('Spontaneous Activity, Models of.', 2014),\n",
              " ('Action Potential Initiation.', 2014),\n",
              " ('State-Space Models for the Analysis of Neural Spike Train and Behavioral Data.',\n",
              "  2014),\n",
              " ('Peripheral Nerve Interface Applications: Respiratory Pacing.', 2014),\n",
              " ('Cognition, Bayesian Models of.', 2014),\n",
              " ('Information Geometry as Applied to Neural Spike Data.', 2014),\n",
              " ('Hippocampus, Model Network Architecture.', 2014),\n",
              " ('Brain-Scale Networks: Overview.', 2014),\n",
              " ('BioModels Database: a public repository for sharing models of biological processes.',\n",
              "  2014),\n",
              " ('Auditory Precedence Effect.', 2014),\n",
              " ('Summary of Information Theoretic Quantities.', 2014),\n",
              " ('Software Tools for Modelling in Computational Neuroscience: Overview.',\n",
              "  2014),\n",
              " ('Retinal/Visual Interfaces (Models, Theory, Techniques): Overview.', 2014),\n",
              " ('Biophysical Models of Olfactory Mitral and Granule Cells.', 2014),\n",
              " ('Computational Models of Neuromodulation.', 2014),\n",
              " ('Signaling Pathways, Modeling of.', 2014),\n",
              " ('General Overview of Spinal Anatomy and Physiology Organization.', 2014),\n",
              " ('Patch Clamp Technique.', 2014),\n",
              " ('Biophysical Models: Neurovascular Coupling, Cortical Microcircuits, and Metabolism.',\n",
              "  2014),\n",
              " ('Visual Processing in Free Flight.', 2014),\n",
              " ('Motoneurons and Neuromuscular Systems: Overview.', 2014),\n",
              " ('Hippocampal Oscillations, Mechanisms (PING, ING, Sparse).', 2014),\n",
              " ('Local Field Potential, Synchrony of.', 2014),\n",
              " ('Context-Dependent Processing in Auditory Cortex.', 2014),\n",
              " ('Decision Making, Models.', 2014),\n",
              " ('Quasi-active Approximation of Nonlinear Dendritic Cables.', 2014),\n",
              " ('Neuropathologies and Networks.', 2014),\n",
              " ('Neuronal Parameter Space Exploration.', 2014),\n",
              " ('Calcium-Dependent Exocytosis, Biophysical Models of.', 2014),\n",
              " ('Basal Ganglia: Control of Saccades.', 2014),\n",
              " ('Collations of Connectivity Data on the Macaque Brain (CoCoMac).', 2014),\n",
              " ('Vestibular, Canal Testing: The Head Impulse Test.', 2014),\n",
              " ('Gap Junctions, Neural Population Models and.', 2014),\n",
              " (\"Parkinson's Disease: Deep Brain Stimulation.\", 2014),\n",
              " ('Leech Local Bend: Neural Coding of Touch Location.', 2014),\n",
              " ('Dynamic Diseases of the Brain.', 2014),\n",
              " ('Equivalent Cylinder Model (Rall).', 2014),\n",
              " ('Modeling of Enzyme Kinetics.', 2014),\n",
              " ('Local Field Potential in Olfaction.', 2014),\n",
              " ('Neuronal Model Reduction.', 2014),\n",
              " ('Brainstem Processing: Overview.', 2014),\n",
              " ('Stimulus-Specific Adaptation, Models.', 2014),\n",
              " ('Slow Oscillations: Physiology.', 2014),\n",
              " ('Electrophysiology Analysis, Bayesian.', 2014),\n",
              " ('Anesthesia, Neural Population Models of.', 2014),\n",
              " ('Neuronal Parameter Non-uniqueness.', 2014),\n",
              " ('Basal Ganglia: Mechanisms for Action Selection.', 2014),\n",
              " ('Space (Length) Constant, Lambda, in Neuronal Signaling.', 2014),\n",
              " ('Spike-Timing-Dependent Plasticity, Learning Rules.', 2014),\n",
              " ('Basal Ganglia: Decision-Making.', 2014),\n",
              " ('Music Processing in the Brain.', 2014),\n",
              " ('Sound Localization and Experience-Dependent Plasticity.', 2014),\n",
              " ('Peripheral Nerve Interface, Intraneural Electrode.', 2014),\n",
              " ('Multistability in Neurodynamics: Overview.', 2014),\n",
              " ('Perception, Bayesian Models of.', 2014),\n",
              " ('Color Vision, Computational Methods for.', 2014),\n",
              " ('Coordinate Transformations, Role of Spinal Cord in.', 2014),\n",
              " ('NEST: The Neural Simulation Tool.', 2014),\n",
              " ('Delayed Rectifier and A-Type Potassium Channels.', 2014),\n",
              " ('Finite Element Modeling for Extracellular Stimulation.', 2014),\n",
              " ('Simulation Experiment Description Markup Language (SED-ML).', 2014),\n",
              " ('Synaptic Dynamics: Overview.', 2014),\n",
              " ('Delta Rhythms: Models and Physiology.', 2014),\n",
              " ('Brain-Machine Interface: Overview.', 2014),\n",
              " ('Center-Surround Processing, Network Models of.', 2014),\n",
              " ('Vertebrate Pattern Generation: Overview.', 2014),\n",
              " ('Models of Extracellular Signal-Regulated Kinases.', 2014),\n",
              " ('Physical Sectioning Microscopy.', 2014),\n",
              " ('Local Field Potential, Relationship to Unit Activity.', 2014),\n",
              " ('Brian Spiking Neural Network Simulator.', 2014),\n",
              " ('Joint Peri Stimulus Time Histogram (JPSTH).', 2014),\n",
              " ('SenseLab: Integration of Multidisciplinary Neuroscience Data.', 2014),\n",
              " ('N -Methyl- d -Aspartate (NMDA) Receptors, Conductance Models.', 2014),\n",
              " ('Epilepsy: Abnormal Ion Channels.', 2014),\n",
              " ('Kinetic Models for PET/SPECT Imaging.', 2014),\n",
              " ('Control of Breathing, Integration of Adaptive Reflexes.', 2014),\n",
              " ('Cortical Maps, Intrinsic Processes.', 2014),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect\n",
        "import os\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# download nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "h4Ipq0CfBsJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ec2b47-1789-46f4-df20-995d0595f086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "buzHb_XAa6OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_title_for_lda(title, language):\n",
        "    # Convert to lowercase\n",
        "    title = title.lower()\n",
        "\n",
        "    # Normalize Unicode characters\n",
        "    title = unicodedata.normalize('NFKD', title)\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(title)\n",
        "\n",
        "    # Remove stopwords and non-alphabetic words, apply lemmatization\n",
        "    if language in stopwords.fileids():\n",
        "        lang_stopwords = set(stopwords.words(language))\n",
        "    else:\n",
        "        lang_stopwords = set()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in lang_stopwords]\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "05CN4DBFLEbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing\n",
        "def preprocess_multilingual_file_for_lda(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(\"File not found.\")\n",
        "        return\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "        preprocessed_titles = []\n",
        "        for line in lines:\n",
        "            try:\n",
        "                language = detect(line)#detect language\n",
        "                preprocessed_line = preprocess_title_for_lda(line, language)\n",
        "                preprocessed_titles.append(preprocessed_line)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing line: {e}\")\n",
        "\n",
        "        return preprocessed_titles"
      ],
      "metadata": {
        "id": "xuryx-J4JmtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/titles_from_2010.txt'\n",
        "prepro_titles_3 = preprocess_multilingual_file_for_lda(file_path)"
      ],
      "metadata": {
        "id": "7d7-8kT2CDb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_fIsiafQgWf"
      },
      "source": [
        "# Sample titles\n",
        "prepro_titles_3[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vetorization"
      ],
      "metadata": {
        "id": "wfRkyJj_bDTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer with minimal preprocessing\n",
        "num_features = 10000\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, tokenizer=lambda x: x.split(), stop_words='english')\n",
        "tf = tf_vectorizer.fit_transform(prepro_titles_3)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "_vwrcjtNCGPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a10646c-d120-4e4a-b590-f4b1a8b4c488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit the LDA model and generate topics"
      ],
      "metadata": {
        "id": "XpX-MFfGbqF3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5 topics**"
      ],
      "metadata": {
        "id": "4FLMKVeOcCYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_lda_topics = 5  # Set the number of 5 topics\n",
        "lda = LatentDirichletAllocation(n_components=num_lda_topics, max_iter=10, learning_method='online', random_state=42)\n",
        "lda.fit(tf)\n",
        "\n",
        "# Displaying the top words in each topic\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f\"Topic {topic_idx}: \", end=\"\")\n",
        "    print(\" \".join([tf_feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]))"
      ],
      "metadata": {
        "id": "r2Jz2dP3CL1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a92df4-c84f-4fec-8e0d-c6b689ed50eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: optimization learning hybrid efficient cognitive radio selection user transmission network\n",
            "Topic 1: using analysis network design dynamic method wireless energy algorithm simulation\n",
            "Topic 2: control power optimal mimo resource cooperative mobile detection adaptive strategy\n",
            "Topic 3: model performance vehicle process approach online joint effect new decision\n",
            "Topic 4: based information data channel social estimation scheme management framework robust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN5ylRd4XWCr"
      },
      "source": [
        "Topics:\n",
        "0. Systems engineering and control\n",
        "1. Computational analysis and algorithms\n",
        "2. Computer science and theoretical computing\n",
        "3. Algorithmic methods and applications\n",
        "4. Information systems and graph theory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10 topics**"
      ],
      "metadata": {
        "id": "AhVi8AIEcIdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_lda_topics = 10  # Set the more number of topics\n",
        "lda = LatentDirichletAllocation(n_components=num_lda_topics, max_iter=10, learning_method='online', random_state=42)\n",
        "lda.fit(tf)\n",
        "\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f\"Topic {topic_idx}: \", end=\"\")\n",
        "    print(\" \".join([tf_feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]))"
      ],
      "metadata": {
        "id": "V8_afUnsH-VH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b9a6c2-91f0-41a0-b38c-b2fd9d7b514d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: network design mobile detection adaptive cognitive linear evaluation novel fading\n",
            "Topic 1: control wireless algorithm resource cooperative effect scheduling strategy access code\n",
            "Topic 2: optimal knowledge field implementation solution computation distribution use synthesis comparison\n",
            "Topic 3: information optimization approach vehicle hybrid management joint framework electric decision\n",
            "Topic 4: based communication mimo power channel social scheme vehicular robust nonlinear\n",
            "Topic 5: learning online massive game transmission research reinforcement machine behavior citation\n",
            "Topic 6: analysis data dynamic selection heterogeneous interference computing cellular parallel support\n",
            "Topic 7: method energy modeling application relay multiple user service web efficiency\n",
            "Topic 8: using model performance simulation process estimation efficient distributed radio study\n",
            "Topic 9: allocation state case numerical prediction modulation interaction localization graph uncertainty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15 topics**"
      ],
      "metadata": {
        "id": "JBhNtfgZeqFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_lda_topics = 15  # Set the more number of topics\n",
        "lda = LatentDirichletAllocation(n_components=num_lda_topics, max_iter=10, learning_method='online', random_state=42)\n",
        "lda.fit(tf)\n",
        "\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f\"Topic {topic_idx}: \", end=\"\")\n",
        "    print(\" \".join([tf_feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]))"
      ],
      "metadata": {
        "id": "bi9n4hB9Mz40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13de5eaa-7fc3-4c47-bbd1-cd328bb39319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: mobile cognitive evaluation web security tracking computation protocol human internet\n",
            "Topic 1: network design wireless communication channel cooperative relay vehicular time secure\n",
            "Topic 2: mimo optimal adaptive beamforming distribution modulation mechanism offloading complex policy\n",
            "Topic 3: performance algorithm study research deep integrated case development efficiency problem\n",
            "Topic 4: information social management joint framework strategy novel knowledge numerical planning\n",
            "Topic 5: optimization approach power hybrid electric decision service code sensor intelligent\n",
            "Topic 6: resource linear heterogeneous nonlinear computing data implementation solution tool feedback\n",
            "Topic 7: analysis efficient scheme new multiple user spectrum parallel random sensing\n",
            "Topic 8: using control simulation distributed radio access impact science traffic trajectory\n",
            "Topic 9: estimation state field citation capacity localization cell finite parameter uncertainty\n",
            "Topic 10: model dynamic method energy modeling process application program predictive flow\n",
            "Topic 11: learning transmission stochastic theory digital reinforcement autonomous value sharing global\n",
            "Topic 12: data online effect selection interference support machine equation multiuser virtual\n",
            "Topic 13: based vehicle detection robust massive game spatial search behavior calculation\n",
            "Topic 14: allocation scheduling cellular quantum interaction task improving robot molecular pattern\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pStFBikpsRTz"
      },
      "source": [
        "# Part2: Combined Topic Models\n",
        "\n",
        "Method developed by [Bianchi et al. 2021](https://aclanthology.org/2021.acl-short.96/).\n",
        "\n",
        "[A 6min presentation of the paper by one of the authors.](https://underline.io/lecture/25716-pre-training-is-a-hot-topic-contextualized-document-embeddings-improve-topic-coherence)\n",
        "\n",
        "Code: [https://github.com/MilaNLProc/contextualized-topic-models](https://github.com/MilaNLProc/contextualized-topic-models)\n",
        "\n",
        "Tutorial: [https://colab.research.google.com/drive/1fXJjr_rwqvpp1IdNQ4dxqN4Dp88cxO97?usp=sharing](https://colab.research.google.com/drive/1fXJjr_rwqvpp1IdNQ4dxqN4Dp88cxO97?usp=sharing)\n",
        "\n",
        "Again, perform topic modelling for the three time periods - this time using the combined topic models (CTMs).\n",
        "\n",
        "You can use and adapt the code from the tutorial linked above.\n",
        "\n",
        "Use the available GPU for faster running times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43c27a8d-3ba1-4ff0-8699-18e2ddc68025",
        "id": "gnbFetgstAeJ"
      },
      "source": [
        "!pip install --upgrade contextualized_topic_models #prevent attribute error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contextualized_topic_models\n",
            "  Downloading contextualized_topic_models-2.5.0-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from contextualized_topic_models) (1.23.5)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from contextualized_topic_models) (0.16.0+cu118)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from contextualized_topic_models) (2.1.0+cu118)\n",
            "Collecting gensim==4.2.0 (from contextualized_topic_models)\n",
            "  Downloading gensim-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers>=2.1.1 (from contextualized_topic_models)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wordcloud>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from contextualized_topic_models) (1.9.2)\n",
            "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from contextualized_topic_models) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from contextualized_topic_models) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from contextualized_topic_models) (1.11.4)\n",
            "Collecting ipywidgets==7.5.1 (from contextualized_topic_models)\n",
            "  Downloading ipywidgets-7.5.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==8.10.0 (from contextualized_topic_models)\n",
            "  Downloading ipython-8.10.0-py3-none-any.whl (784 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m784.3/784.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0->contextualized_topic_models) (6.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized_topic_models) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized_topic_models) (4.4.2)\n",
            "Collecting jedi>=0.16 (from ipython==8.10.0->contextualized_topic_models)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized_topic_models) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized_topic_models) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized_topic_models) (3.0.41)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized_topic_models) (2.16.1)\n",
            "Collecting stack-data (from ipython==8.10.0->contextualized_topic_models)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized_topic_models) (5.7.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized_topic_models) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==7.5.1->contextualized_topic_models) (5.5.6)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==7.5.1->contextualized_topic_models) (5.9.2)\n",
            "Collecting widgetsnbextension~=3.5.0 (from ipywidgets==7.5.1->contextualized_topic_models)\n",
            "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized_topic_models) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized_topic_models) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized_topic_models) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized_topic_models) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized_topic_models) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized_topic_models) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized_topic_models) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized_topic_models) (2.8.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.1.1->contextualized_topic_models) (4.35.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.1.1->contextualized_topic_models) (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.1.1->contextualized_topic_models) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=2.1.1->contextualized_topic_models)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.1.1->contextualized_topic_models) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized_topic_models) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized_topic_models) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized_topic_models) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized_topic_models) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized_topic_models) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized_topic_models) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized_topic_models) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.7.0->contextualized_topic_models) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.1.1->contextualized_topic_models) (6.0.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized_topic_models) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized_topic_models) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized_topic_models) (6.3.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==8.10.0->contextualized_topic_models) (0.8.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized_topic_models) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized_topic_models) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized_topic_models) (5.5.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==8.10.0->contextualized_topic_models) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython==8.10.0->contextualized_topic_models) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->contextualized_topic_models) (1.16.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.1.1->contextualized_topic_models) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.1.1->contextualized_topic_models) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.1.1->contextualized_topic_models) (0.4.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->contextualized_topic_models) (2.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=2.1.1->contextualized_topic_models) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=2.1.1->contextualized_topic_models) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->contextualized_topic_models) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->contextualized_topic_models) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->contextualized_topic_models) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->contextualized_topic_models) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.1.1->contextualized_topic_models) (3.2.0)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython==8.10.0->contextualized_topic_models)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython==8.10.0->contextualized_topic_models)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pure-eval (from stack-data->ipython==8.10.0->contextualized_topic_models)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->contextualized_topic_models) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized_topic_models) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized_topic_models) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized_topic_models) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized_topic_models) (0.13.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized_topic_models) (4.1.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (21.2.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized_topic_models) (2.21)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=fda8b97c543310c2cb20c6b5bb9216ef71930b33e53ea0570e56da03441c0b89\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, pure-eval, jedi, executing, asttokens, stack-data, gensim, ipython, sentence-transformers, widgetsnbextension, ipywidgets, contextualized_topic_models\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.2\n",
            "    Uninstalling gensim-4.3.2:\n",
            "      Successfully uninstalled gensim-4.3.2\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.15.0 requires ipywidgets>=7.7.1, but you have ipywidgets 7.5.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.10.0 which is incompatible.\n",
            "ipyevents 2.0.2 requires ipywidgets>=7.6.0, but you have ipywidgets 7.5.1 which is incompatible.\n",
            "ipyleaflet 0.18.0 requires ipywidgets<9,>=7.6.0, but you have ipywidgets 7.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 contextualized_topic_models-2.5.0 executing-2.0.1 gensim-4.2.0 ipython-8.10.0 ipywidgets-7.5.1 jedi-0.19.1 pure-eval-0.2.2 sentence-transformers-2.2.2 sentencepiece-0.1.99 stack-data-0.6.3 widgetsnbextension-3.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNsJrV2DJ8GO"
      },
      "source": [
        "from contextualized_topic_models.models.ctm import CombinedTM\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
        "\n",
        "num_ctm_topics = 5  # you can also choose a higher number of topics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSv9Ch46LFxp"
      },
      "source": [
        "### Before the 1990s:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#open original dataset\n",
        "with open(path_before_1990) as fin:\n",
        "    reader = csv.reader(fin)\n",
        "    titles_1 = [row[0] for row in reader]"
      ],
      "metadata": {
        "id": "ntoxFqiNfhiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords as stop_words\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = list(stop_words.words(\"english\"))\n",
        "\n",
        "sp = WhiteSpacePreprocessingStopwords(titles_1, stopwords_list=stopwords)\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab, retained_indices = sp.preprocess()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIbkLo5Javo3",
        "outputId": "46335736-afde-4ae9-954e-45015f80301e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tp = TopicModelDataPreparation(\"all-mpnet-base-v2\")\n",
        "\n",
        "training_dataset_1 = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f1be0203c6f44b979a1b5f80daafab2c",
            "9dc68ee5e3e240f2bf90638583f87cff",
            "b4d173e2cf554fae9a12c30d892dac8a",
            "96864997f1384e568208ebbd7b0eadbe",
            "fbdd0b1e7b1947babdbc181e19c4082a",
            "9814c73c384646dbaded2eab15b3da09",
            "949d2ca18da14a528026ee2c028ac98a",
            "d5075e5960a446e6bdd8d896ecce40ee",
            "08a07b29c69842b598cf833ebccdb675",
            "b7b66cee619240b9ae4206d95fc90e19",
            "fbd2d0dd0db149cdbc0d0dbd929a683e"
          ]
        },
        "outputId": "01931e24-25c1-4766-aa48-402f643e7f31",
        "id": "S0UleqTaq7jl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/248 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1be0203c6f44b979a1b5f80daafab2c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, n_components=num_ctm_topics, num_epochs=10)\n",
        "ctm.fit(training_dataset_1) # run the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG825u0_JIyi",
        "outputId": "164aae8c-e559-4761-f291-1554e9cd1abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: [10/10]\t Seen Samples: [494080/494430]\tTrain Loss: 35.40875399545067\tTime: 0:00:14.506315: : 10it [02:25, 14.58s/it]\n",
            "100%|██████████| 773/773 [00:13<00:00, 58.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctm.get_topic_lists(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHl0YxrOf2sQ",
        "outputId": "6bcb791b-4ef9-4c5a-abac-3c540925c903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['logic',\n",
              "  'theorem',\n",
              "  'automata',\n",
              "  'sets',\n",
              "  'sub',\n",
              "  'theories',\n",
              "  'languages',\n",
              "  'properties',\n",
              "  'free',\n",
              "  'sup'],\n",
              " ['environmental',\n",
              "  'transputer',\n",
              "  'subject',\n",
              "  'event',\n",
              "  'multiobjective',\n",
              "  'empirical',\n",
              "  'congestion',\n",
              "  'acoustic',\n",
              "  'heterogeneous',\n",
              "  'nuclear'],\n",
              " ['algorithm',\n",
              "  'problem',\n",
              "  'algorithms',\n",
              "  'problems',\n",
              "  'parallel',\n",
              "  'recognition',\n",
              "  'pattern',\n",
              "  'method',\n",
              "  'note',\n",
              "  'using'],\n",
              " ['computer',\n",
              "  'information',\n",
              "  'data',\n",
              "  'language',\n",
              "  'system',\n",
              "  'design',\n",
              "  'software',\n",
              "  'science',\n",
              "  'processing',\n",
              "  'network'],\n",
              " ['systems',\n",
              "  'control',\n",
              "  'analysis',\n",
              "  'model',\n",
              "  'time',\n",
              "  'uuml',\n",
              "  'optimal',\n",
              "  'auml',\n",
              "  'decision',\n",
              "  'der']]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNRaJJEMiVQb"
      },
      "source": [
        "### From 1990 to 2009"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_from_1990_to_2009) as fin:\n",
        "    reader = csv.reader(fin)\n",
        "    titles_2 = [row[0] for row in reader]"
      ],
      "metadata": {
        "id": "o_lbjfcyXnY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = WhiteSpacePreprocessingStopwords(titles_2, stopwords_list=stopwords)\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab, retained_indices = sp.preprocess()"
      ],
      "metadata": {
        "id": "7BdoYvIkoKRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp = TopicModelDataPreparation(\"all-mpnet-base-v2\")\n",
        "\n",
        "training_dataset_2 = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ],
      "metadata": {
        "id": "aUJSCJ-qfYjY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "333dd1547ffb4e9d82620424dab332f8",
            "655f8b57c9d04b86b985ed94af5ad189",
            "b6adaba2f22541928e64dfa3d8e0c369",
            "3aad38a3b88e4ec0ab571e81ff39fc63",
            "93254fd799dd46fa8d19a66453f8bca1",
            "6fc657b3d8fa43ea91bd608106c6fb2e",
            "aef62a7c56ae4524821f934631bfe452",
            "21192685fe3a4325990c712072b103ce",
            "26165a17d2174d21adf0c366a0fd8ba7",
            "7536de54eb0c42fcb5f4eab9dbf3bafd",
            "43675e23317b41cb98a57b469d871038"
          ]
        },
        "outputId": "11902fd8-8eec-4fd5-acc8-0881adbc8c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/249 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "333dd1547ffb4e9d82620424dab332f8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26bbb5c4-15f3-48de-9e25-0f0d9c8d291d",
        "id": "RumyzZa0wWOb"
      },
      "source": [
        "ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, n_components=num_ctm_topics, num_epochs=10)\n",
        "ctm.fit(training_dataset_2) # run the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: [10/10]\t Seen Samples: [496000/496050]\tTrain Loss: 41.79111079062185\tTime: 0:00:17.012028: : 10it [02:57, 17.70s/it]\n",
            "100%|██████████| 776/776 [00:15<00:00, 50.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctm.get_topic_lists(10)"
      ],
      "metadata": {
        "id": "NwTs08czgDMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aab1829-5074-4334-f680-3a50b54b8006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['amp',\n",
              "  'science',\n",
              "  'information',\n",
              "  'behavior',\n",
              "  'review',\n",
              "  'user',\n",
              "  'book',\n",
              "  'retrieval',\n",
              "  'ai',\n",
              "  'search'],\n",
              " ['nets',\n",
              "  'solutions',\n",
              "  'programs',\n",
              "  'equations',\n",
              "  'number',\n",
              "  'integer',\n",
              "  'bounds',\n",
              "  'extended',\n",
              "  'weighted',\n",
              "  'numerical'],\n",
              " ['power',\n",
              "  'cmos',\n",
              "  'high',\n",
              "  'low',\n",
              "  'converter',\n",
              "  'frequency',\n",
              "  'dc',\n",
              "  'current',\n",
              "  'control',\n",
              "  'dual'],\n",
              " ['de',\n",
              "  'system',\n",
              "  'based',\n",
              "  'fuzzy',\n",
              "  'using',\n",
              "  'neural',\n",
              "  'oacute',\n",
              "  'model',\n",
              "  'network',\n",
              "  'approach'],\n",
              " ['time',\n",
              "  'networks',\n",
              "  'wireless',\n",
              "  'mobile',\n",
              "  'performance',\n",
              "  'systems',\n",
              "  'analysis',\n",
              "  'real',\n",
              "  'data',\n",
              "  'distributed']]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfgbLy0KiZ5b"
      },
      "source": [
        "### From 2010 onwards"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#open the original dataset\n",
        "with open(path_from_2010) as fin:\n",
        "    reader = csv.reader(fin)\n",
        "    titles_3 = [row[0] for row in reader]"
      ],
      "metadata": {
        "id": "BcyBPFo0XoEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = WhiteSpacePreprocessingStopwords(titles_3, stopwords_list=stopwords)\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab, retained_indices = sp.preprocess()"
      ],
      "metadata": {
        "id": "kO1BFsX7oNf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp = TopicModelDataPreparation(\"all-mpnet-base-v2\")\n",
        "\n",
        "training_dataset_3 = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ],
      "metadata": {
        "id": "cBEd3YnyfZD1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "14470d1d55da45ea84fce5d289d62c54",
            "bbdfb2298b364d2bac775006a11a073e",
            "34bcc0551162441cb79c21f80c92973c",
            "b2702295222d425bb335cd02c25c4231",
            "d5d3467d387e44e29a454bc1f388bc84",
            "fc715b05bd514177a5a8a6f42f5d9cbe",
            "160dd0efa01843b3a6f88205b86e93cc",
            "8dcbf4828bb442b799816f4e6f440549",
            "655eea3bad3641d79a9ce03f4bcd0c80",
            "9dd38ee2ea3c4ac29a65400293bc7cda",
            "cdba4954b2a348a4b76487981ccb347c"
          ]
        },
        "outputId": "baa6b172-9444-4f6e-d404-cf4296b40349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/249 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14470d1d55da45ea84fce5d289d62c54"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb31220c-d57e-42cd-8758-18cd516f9360",
        "id": "vggGgXu6wOOm"
      },
      "source": [
        "ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, n_components=num_ctm_topics, num_epochs=10)\n",
        "ctm.fit(training_dataset_3) # run the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: [10/10]\t Seen Samples: [496000/496140]\tTrain Loss: 46.52148956791047\tTime: 0:00:14.662077: : 10it [02:24, 14.42s/it]\n",
            "100%|██████████| 776/776 [00:13<00:00, 58.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctm.get_topic_lists(10)"
      ],
      "metadata": {
        "id": "8r49W-p8gEFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a53515-04e8-4edf-f37c-4b86764b38ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['social',\n",
              "  'research',\n",
              "  'behavior',\n",
              "  'evidence',\n",
              "  'knowledge',\n",
              "  'information',\n",
              "  'engineering',\n",
              "  'technology',\n",
              "  'science',\n",
              "  'risk'],\n",
              " ['networks',\n",
              "  'mimo',\n",
              "  'wireless',\n",
              "  'performance',\n",
              "  'cooperative',\n",
              "  'systems',\n",
              "  'allocation',\n",
              "  'channel',\n",
              "  'resource',\n",
              "  'relay'],\n",
              " ['simulation',\n",
              "  'modeling',\n",
              "  'method',\n",
              "  'process',\n",
              "  'particle',\n",
              "  'optimization',\n",
              "  'dynamics',\n",
              "  'simulations',\n",
              "  'sub',\n",
              "  'algorithm'],\n",
              " ['angle',\n",
              "  'delays',\n",
              "  'range',\n",
              "  'platoon',\n",
              "  'sampled',\n",
              "  'independent',\n",
              "  'incremental',\n",
              "  'saving',\n",
              "  'arrival',\n",
              "  'sequence'],\n",
              " ['based',\n",
              "  'control',\n",
              "  'learning',\n",
              "  'vehicle',\n",
              "  'data',\n",
              "  'system',\n",
              "  'vehicles',\n",
              "  'using',\n",
              "  'model',\n",
              "  'approach']]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}