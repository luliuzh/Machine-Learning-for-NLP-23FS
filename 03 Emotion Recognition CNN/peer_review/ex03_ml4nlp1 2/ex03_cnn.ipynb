{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading & Imports"
      ],
      "metadata": {
        "id": "NVukdggbeDCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone original repository\n",
        "!git clone https://github.com/cardiffnlp/tweeteval.git"
      ],
      "metadata": {
        "id": "iXpF2_gBkQm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e11a3f-ea16-4f3c-dd26-c17e2415500c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tweeteval'...\n",
            "remote: Enumerating objects: 370, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 370 (delta 13), reused 3 (delta 1), pack-reused 354\u001b[K\n",
            "Receiving objects: 100% (370/370), 8.49 MiB | 11.19 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# navigate to desired folder\n",
        "path = '/content/tweeteval/datasets/emotion'\n",
        "\n",
        "file_contents = {}\n",
        "\n",
        "for subdir, dirs, files in os.walk(path):\n",
        "    # list all files in the emotion dataset\n",
        "    print(files)\n",
        "    for file in files:\n",
        "      file_path = os.path.join(subdir, file)\n",
        "      with open(file_path, 'r', encoding='utf-8') as f:\n",
        "          # read file line by line and assign to list\n",
        "          text = f.readlines()\n",
        "      # keep track of the names/contents of the files\n",
        "      file_contents[file] = text"
      ],
      "metadata": {
        "id": "VQw9Gk0agNau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1269ff44-9df8-425e-be39-634caad131ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['val_text.txt', 'mapping.txt', 'test_text.txt', 'val_labels.txt', 'train_labels.txt', 'train_text.txt', 'test_labels.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign variable names according to the original file names\n",
        "test_text = file_contents['test_text.txt']\n",
        "test_labels = file_contents['test_labels.txt']\n",
        "train_text = file_contents['train_text.txt']\n",
        "train_labels = file_contents['train_labels.txt']\n",
        "val_text = file_contents['val_text.txt']\n",
        "val_labels = file_contents['val_labels.txt']\n",
        "mapping = file_contents['mapping.txt']\n",
        "\n",
        "# print data size\n",
        "print(f\"Test set: {len(test_text)} lines of text and {len(test_labels)} labels\")\n",
        "print(f\"Train set: {len(train_text)} lines of text and {len(train_labels)} labels\")\n",
        "print(f\"Validation set: {len(val_text)} lines of text and {len(val_labels)} labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxumdNt4owwK",
        "outputId": "e87c4ee9-2cf8-4b15-d156-4e8316941b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: 1421 lines of text and 1421 labels\n",
            "Train set: 3257 lines of text and 3257 labels\n",
            "Validation set: 374 lines of text and 374 labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# print random samples from the test set text\n",
        "print(test_text[random.randint(0, len(test_text))])\n",
        "print(test_text[random.randint(0, len(test_text))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMkJMFOXlpm6",
        "outputId": "2cb459a2-a1dc-46d0-e368-fc9ae522fdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Samuel 18:15\\nAnd when #Saul saw that he had great #success, he stood in #fearful #awe of him. \n",
            "\n",
            "I'm still bitter about the fact that I didn't get the Php 10/liter promo. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Create Datasets"
      ],
      "metadata": {
        "id": "xk_bfkBYeDLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create dataframes from the initial data\n",
        "# remove new line symbol from labels and convert them to integers\n",
        "test_df = pd.DataFrame({'text': test_text, 'label': [int(label) for label in test_labels]})\n",
        "train_df = pd.DataFrame({'text': train_text, 'label': [int(label) for label in train_labels]})\n",
        "val_df = pd.DataFrame({'text': val_text, 'label': [int(label) for label in val_labels]})\n",
        "\n",
        "# inspect test dataframes\n",
        "test_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KwHO_7Lcr2kU",
        "outputId": "48ab32c1-5fe0-4f7c-a9b6-448c13c93556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  #Deppression is real. Partners w/ #depressed p...      3\n",
              "1  @user Interesting choice of words... Are you c...      0\n",
              "2  My visit to hospital for care triggered #traum...      3\n",
              "3  @user Welcome to #MPSVT! We are delighted to h...      1\n",
              "4                    What makes you feel #joyful? \\n      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3ea6d95-de76-4c18-a61c-2b21e5ece8b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user Interesting choice of words... Are you c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My visit to hospital for care triggered #traum...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user Welcome to #MPSVT! We are delighted to h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What makes you feel #joyful? \\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3ea6d95-de76-4c18-a61c-2b21e5ece8b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3ea6d95-de76-4c18-a61c-2b21e5ece8b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3ea6d95-de76-4c18-a61c-2b21e5ece8b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d648f1d-9a0b-4f0f-a9da-2f70b7410b52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d648f1d-9a0b-4f0f-a9da-2f70b7410b52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d648f1d-9a0b-4f0f-a9da-2f70b7410b52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect label mapping for data filtering\n",
        "sentiments_dict = {}\n",
        "\n",
        "for line in mapping:\n",
        "    # Split each line based on the tab character\n",
        "    parts = line.strip().split('\\t')\n",
        "\n",
        "    # Extract the key and value\n",
        "    key = parts[1]\n",
        "    value = int(parts[0])\n",
        "\n",
        "    # Add the key-value pair to the dictionary\n",
        "    sentiments_dict[key] = value\n",
        "\n",
        "# Print the resulting dictionary\n",
        "print(\"Sentiments Dictionary:\")\n",
        "print(sentiments_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nXRGVUirE92",
        "outputId": "c3b7b00f-a5ee-46de-d8ad-c60d88bb1044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiments Dictionary:\n",
            "{'anger': 0, 'joy': 1, 'optimism': 2, 'sadness': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "q4s3XwBk-v9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the emoji library before running, if necessary\n",
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs34gdX_UrJd",
        "outputId": "22375bb8-b66e-462f-b3ae-540ce8e8d2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import html\n",
        "import emoji\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# By peaking at the data, we've identified the need for specific preprocessing\n",
        "# steps so we'll define a function to do that\n",
        "# First we'll define functions for the sub-steps\n",
        "\n",
        "# remove emojis\n",
        "def remove_emojis(text):\n",
        "    return emoji.demojize(text).replace(\":\", \": \")\n",
        "\n",
        "# treat chat words\n",
        "chat_words = {\n",
        "    'fyi'  : 'for your information',\n",
        "    'lol'  : 'laugh out loud',\n",
        "    'afk'  : 'away from keyboard',\n",
        "    'w/'   : 'with',\n",
        "    'brb'  : 'be right back',\n",
        "    'asap' : 'as soon as possible',\n",
        "    'lmk'  : 'let me know',\n",
        "    'nmu'  : 'not much you',\n",
        "    'hrs'  : 'hours',\n",
        "    'Fri'  : 'Friday'\n",
        "}\n",
        "def chat_words_conv(text):\n",
        "    new_text = []\n",
        "    for t in text.split():\n",
        "        t = chat_words[t] if t in chat_words.keys() else t\n",
        "        new_text.append(t)\n",
        "    return ' '.join(new_text)\n",
        "\n",
        "def handle_special_cases(text):\n",
        "    new_text = text.replace(\"\\\\n\", \"\")\n",
        "    new_text = re.sub(r'(?<!\\s)#', ' #', new_text) # add space before hashtags\n",
        "    return new_text\n",
        "\n",
        "# lowercasing\n",
        "def lowercasing(text):\n",
        "    return text.lower()\n",
        "\n",
        "# handle HTML characters\n",
        "def handle_html(text):\n",
        "    return(html.unescape(text))\n",
        "\n",
        "# tokenization & lemmatization\n",
        "# along with digit, punctuation and stop word removal\n",
        "def tokenize_lemmatize(text):\n",
        "    doc = nlp(text)\n",
        "    return [t.lemma_ for t in doc if (not t.is_digit) and (not t.is_punct) and not (t.is_stop)]\n",
        "\n",
        "def text_preprocessing(text_df):\n",
        "    # function assumes input is a dataframe with a 'text' column\n",
        "    new_text_df = text_df.copy()\n",
        "    new_text_df['text'] = new_text_df['text'].apply(remove_emojis)\n",
        "    new_text_df['text'] = new_text_df['text'].apply(handle_html)\n",
        "    new_text_df['text'] = new_text_df['text'].apply(chat_words_conv)\n",
        "    new_text_df['text'] = new_text_df['text'].apply(handle_special_cases)\n",
        "    new_text_df['text'] = new_text_df['text'].apply(lowercasing)\n",
        "    new_text_df['text'] = new_text_df['text'].apply(tokenize_lemmatize)\n",
        "    return new_text_df"
      ],
      "metadata": {
        "id": "mRlXQRo3SZnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing to all data (might take about 1min to run!)\n",
        "test_df = text_preprocessing(test_df)\n",
        "train_df = text_preprocessing(train_df)\n",
        "val_df = text_preprocessing(val_df)\n",
        "\n",
        "# Preview the preprocessed data\n",
        "print(test_df.iloc[random.randint(0, len(test_df))]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93eQ_weoLWw",
        "outputId": "b86fae46-f127-4162-af1b-c981b40b72a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['remember', 'kid', 'flip', 'shirt', 'pouch', 'snack', 'time', 'snack']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode data"
      ],
      "metadata": {
        "id": "SNO5e1kt_Pu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Build vocabulary\n",
        "# combine all text from all splits\n",
        "all_text = pd.concat([test_df['text'], train_df['text'], val_df['text']])\n",
        "\n",
        "# retrieve maximum number of tokens in sentence\n",
        "max_len = max([len(x) for x in all_text])\n",
        "\n",
        "# get unique tokens\n",
        "token_set = set(token for row in all_text for token in row)\n",
        "\n",
        "# assign unique id to each token\n",
        "word2idx = {token: idx+2 for idx, token in enumerate(token_set)}\n",
        "word2idx.update({'<pad>': 0, '<unk>': 1})"
      ],
      "metadata": {
        "id": "Aojzxaut_UY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def encode(text_df, word2idx, max_len):\n",
        "    input_ids = []\n",
        "    for row in text_df['text']:\n",
        "        row += ['<pad>']*(max_len - len(row))\n",
        "        input_ids.append([word2idx.get(token) for token in row])\n",
        "    return np.array(input_ids)"
      ],
      "metadata": {
        "id": "R1WSmLpHHsmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build datasets"
      ],
      "metadata": {
        "id": "BLIPP_jY-1ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(sentiments):\n",
        "    sent1, sent2 = sentiments_dict[sentiments[0]], sentiments_dict[sentiments[1]]\n",
        "    # filter data\n",
        "    test_filtered = test_df[(test_df[\"label\"] == sent1) | (test_df[\"label\"] == sent2)]\n",
        "    train_filtered = train_df[(train_df[\"label\"] == sent1) | (train_df[\"label\"] == sent2)]\n",
        "    val_filtered = val_df[(val_df[\"label\"] == sent1) | (val_df[\"label\"] == sent2)]\n",
        "\n",
        "    test_set = encode(test_filtered, word2idx, max_len)\n",
        "    test_label = np.array(test_filtered['label'])\n",
        "\n",
        "    train_set = encode(train_filtered, word2idx, max_len)\n",
        "    train_label = np.array(train_filtered['label'])\n",
        "\n",
        "    val_set = encode(val_filtered, word2idx, max_len)\n",
        "    val_label = np.array(val_filtered['label'])\n",
        "\n",
        "    # print data size\n",
        "    print(f\"Dataset: {sentiments[0]} and {sentiments[1]}\")\n",
        "    print(\"------------------------\")\n",
        "    print(f\"Test set size: {len(test_set)}\")\n",
        "    print(f\"Train set size: {len(train_set)}\")\n",
        "    print(f\"Validation set size: {len(val_set)}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return test_set, test_label, train_set, train_label, val_set, val_label"
      ],
      "metadata": {
        "id": "UojVn4TXicVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset 1: anger and joy\n",
        "test_set, test_lbl, train_set, train_lbl, val_set, val_lbl = build_dataset(['anger', 'joy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADso5uRArsDs",
        "outputId": "ce3a8548-0d70-48bc-d9ae-a294d76d5ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: anger and joy\n",
            "------------------------\n",
            "Test set size: 916\n",
            "Train set size: 2108\n",
            "Validation set size: 257\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIFmAFUHvqBD",
        "outputId": "c6f47c6e-208d-4a73-8d70-2825a1cc3a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1845,  597, 2414, 5373, 4103, 4856, 5077, 4417, 5337, 1895, 5145,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [9718, 8602, 3386, 5723, 6719, 3386, 6835,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [ 698, 3100, 7224,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: CNN Classifier"
      ],
      "metadata": {
        "id": "TxRQB_rAeDUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# use the GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXkjbZp5eoIl",
        "outputId": "907835ff-17c7-4d04-e7b3-92908eab7008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Class"
      ],
      "metadata": {
        "id": "pWmlK2cndwOC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIzU9ASmO7Of"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size=len(word2idx),\n",
        "                 embed_dim=300,\n",
        "                 filter_sizes=[3, 4, 5],\n",
        "                 num_filters=[100, 100, 100],\n",
        "                 num_classes=2,\n",
        "                 dropout=0.5):\n",
        "        \"\"\"\n",
        "        The constructor for CNN class.\n",
        "        Args:\n",
        "            vocab_size (int): Need to be specified when pretrained word\n",
        "                embeddings are not used.\n",
        "            embed_dim (int): Dimension of word vectors. Need to be specified\n",
        "                when pretrained word embeddings are not used. Default: 300\n",
        "            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n",
        "            num_filters (List[int]): List of number of filters, has the same\n",
        "                length as `filter_sizes`. Default: [100, 100, 100]\n",
        "            n_classes (int): Number of classes. Default: 2\n",
        "            dropout (float): Dropout rate. Default: 0.5\n",
        "        \"\"\"\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "        # Embedding layer\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                          embedding_dim=self.embed_dim,\n",
        "                                          padding_idx=0,\n",
        "                                          max_norm=5.0)\n",
        "        # Conv Network\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=self.embed_dim,\n",
        "                      out_channels=num_filters[i],\n",
        "                      kernel_size=filter_sizes[i])\n",
        "            for i in range(len(filter_sizes))\n",
        "        ])\n",
        "        # Fully-connected layer and Dropout\n",
        "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"Perform a forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): A tensor of token ids with shape\n",
        "                (batch_size, max_sent_length)\n",
        "\n",
        "        Returns:\n",
        "            logits (torch.Tensor): Output logits with shape (batch_size,\n",
        "                n_classes)\n",
        "        \"\"\"\n",
        "\n",
        "        # Get embeddings from `input_ids`. Output shape: (batch_size, max_len, embed_dim)\n",
        "        x_embed = self.embedding(input_ids).float()\n",
        "\n",
        "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
        "        # Output shape: (b, embed_dim, max_len)\n",
        "        x_reshaped = x_embed.permute(0, 2, 1)\n",
        "\n",
        "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
        "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
        "\n",
        "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
        "            for x_conv in x_conv_list]\n",
        "\n",
        "        # Concatenate x_pool_list to feed the fully connected layer.\n",
        "        # Output shape: (b, sum(num_filters))\n",
        "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
        "                         dim=1)\n",
        "        #print(x_fc.shape)\n",
        "\n",
        "        # Compute logits. Output shape: (b, n_classes)\n",
        "        logits = self.fc(self.dropout(x_fc))\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "S8SpPoPbdvlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = TensorDataset(torch.from_numpy(test_set), torch.from_numpy(test_lbl))\n",
        "train_data = TensorDataset(torch.from_numpy(train_set), torch.from_numpy(train_lbl))\n",
        "val_data = TensorDataset(torch.from_numpy(val_set), torch.from_numpy(val_lbl))\n",
        "\n",
        "batch_size = 8\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_data)\n",
        "test_dataloader = DataLoader(test_data)"
      ],
      "metadata": {
        "id": "4KUyYo2cefh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiate CNN model"
      ],
      "metadata": {
        "id": "JH4WEqkre3Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose desired hyperparamater configuration\n",
        "model = CNN(embed_dim=500,\n",
        "            filter_sizes=[3, 5, 7],\n",
        "            num_filters=[120, 120, 120],\n",
        "            num_classes=2,\n",
        "            dropout=0.5)\n",
        "\n",
        "# Send model to `device` (GPU/CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Instantiate Adadelta optimizer\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=0.01, rho=0.95)"
      ],
      "metadata": {
        "id": "0Aax3I4ddrR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "kteWiNhbe0qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Start training loop\n",
        "print(\"Start training...\\n\")\n",
        "print(f\"{'Epoch':^7} | {'Train Loss':^12}\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "for epoch_i in range(50):\n",
        "    total_loss = 0\n",
        "    # Put the model into the training mode\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "        # Zero out any previously calculated gradients\n",
        "        model.zero_grad()\n",
        "        # Perform a forward pass. This will return logits.\n",
        "        logits = model(b_input_ids)\n",
        "        # Compute loss and accumulate the loss values\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        total_loss += loss.item()\n",
        "        # Perform a backward pass to calculate gradients\n",
        "        loss.backward()\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = (total_loss / len(train_dataloader))\n",
        "    print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lTFZMQ9d7Nk",
        "outputId": "0282191c-a63b-4bc2-ef80-4a44eb9b11a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Train Loss \n",
            "------------------------------------------------------------\n",
            "   1    |   0.669133  \n",
            "   2    |   0.616094  \n",
            "   3    |   0.592888  \n",
            "   4    |   0.571710  \n",
            "   5    |   0.547343  \n",
            "   6    |   0.525237  \n",
            "   7    |   0.503240  \n",
            "   8    |   0.477858  \n",
            "   9    |   0.452352  \n",
            "  10    |   0.430146  \n",
            "  11    |   0.405969  \n",
            "  12    |   0.381853  \n",
            "  13    |   0.353032  \n",
            "  14    |   0.329927  \n",
            "  15    |   0.308135  \n",
            "  16    |   0.281708  \n",
            "  17    |   0.260262  \n",
            "  18    |   0.240150  \n",
            "  19    |   0.223705  \n",
            "  20    |   0.202177  \n",
            "  21    |   0.186298  \n",
            "  22    |   0.169693  \n",
            "  23    |   0.156417  \n",
            "  24    |   0.143009  \n",
            "  25    |   0.128293  \n",
            "  26    |   0.122298  \n",
            "  27    |   0.111662  \n",
            "  28    |   0.100782  \n",
            "  29    |   0.091895  \n",
            "  30    |   0.085990  \n",
            "  31    |   0.081570  \n",
            "  32    |   0.071683  \n",
            "  33    |   0.065988  \n",
            "  34    |   0.061903  \n",
            "  35    |   0.058536  \n",
            "  36    |   0.052742  \n",
            "  37    |   0.048783  \n",
            "  38    |   0.047020  \n",
            "  39    |   0.041995  \n",
            "  40    |   0.038254  \n",
            "  41    |   0.036765  \n",
            "  42    |   0.035596  \n",
            "  43    |   0.032407  \n",
            "  44    |   0.031064  \n",
            "  45    |   0.029351  \n",
            "  46    |   0.026208  \n",
            "  47    |   0.024988  \n",
            "  48    |   0.024549  \n",
            "  49    |   0.021624  \n",
            "  50    |   0.022107  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# define evaluation function to avoid code-deduplication\n",
        "def evaluate_model(model, eval_set_dataloader):\n",
        "    model.eval()\n",
        "    all_eval_labels = []\n",
        "    all_eval_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for eval_batch in eval_set_dataloader:\n",
        "            # Load batch to GPU\n",
        "            b_eval_input_ids, b_eval_labels = tuple(t.to(device) for t in eval_batch)\n",
        "            # Perform a forward pass on the test set\n",
        "            eval_logits = model(b_eval_input_ids)\n",
        "            # Collect labels and predictions for evaluation\n",
        "            all_eval_labels.extend(b_eval_labels.cpu().numpy())\n",
        "            all_eval_preds.extend(torch.argmax(eval_logits, axis=1).cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy and F1 score on the test set\n",
        "    eval_accuracy = accuracy_score(all_eval_labels, all_eval_preds)\n",
        "    eval_f1 = f1_score(all_eval_labels, all_eval_preds, average='macro')\n",
        "\n",
        "    print(f\"Accuracy: {eval_accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {eval_f1:.4f}\")"
      ],
      "metadata": {
        "id": "RXiwS1vkzDcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model evaluation"
      ],
      "metadata": {
        "id": "TrV9jm142Edx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluate model on the validation set:\")\n",
        "print(\"-------------------------------------\")\n",
        "evaluate_model(model, val_dataloader)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Evaluate model on the test set:\")\n",
        "print(\"-------------------------------------\")\n",
        "evaluate_model(model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBwIlCbv2Hxb",
        "outputId": "d6234e4e-d30a-4acb-a485-60777668ed8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model on the validation set:\n",
            "-------------------------------------\n",
            "Accuracy: 0.7588\n",
            "F1 Score: 0.7242\n",
            "\n",
            "\n",
            "Evaluate model on the test set:\n",
            "-------------------------------------\n",
            "Accuracy: 0.7762\n",
            "F1 Score: 0.7479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Re-training best model"
      ],
      "metadata": {
        "id": "mjY8Ihn9eDdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build dataset"
      ],
      "metadata": {
        "id": "KkO9Xrj-x7gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset 2: anger and sadness\n",
        "test_set_2, test_lbl_2, train_set_2, train_lbl_2, val_set_2, val_lbl_2 = build_dataset(['anger', 'sadness'])\n",
        "\n",
        "# fix labels\n",
        "test_lbl_2 = np.where(test_lbl_2 == 3, 1, 0)\n",
        "train_lbl_2 = np.where(train_lbl_2 == 3, 1, 0)\n",
        "val_lbl_2 = np.where(val_lbl_2 == 3, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzHuFEHpx6bQ",
        "outputId": "f5d9d714-64d2-4b29-be27-bebe42bd28e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: anger and sadness\n",
            "------------------------\n",
            "Test set size: 940\n",
            "Train set size: 2255\n",
            "Validation set size: 249\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader"
      ],
      "metadata": {
        "id": "ORHWijKLyL-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_2 = TensorDataset(torch.from_numpy(test_set_2), torch.from_numpy(test_lbl_2))\n",
        "train_data_2 = TensorDataset(torch.from_numpy(train_set_2), torch.from_numpy(train_lbl_2))\n",
        "val_data_2 = TensorDataset(torch.from_numpy(val_set_2), torch.from_numpy(val_lbl_2))\n",
        "\n",
        "batch_size = 8\n",
        "train_sampler_2 = RandomSampler(train_data_2)\n",
        "train_dataloader_2 = DataLoader(train_data_2, sampler=train_sampler_2, batch_size=batch_size)\n",
        "val_dataloader_2 = DataLoader(val_data_2)\n",
        "test_dataloader_2 = DataLoader(test_data_2)"
      ],
      "metadata": {
        "id": "FAvlyWX5x55L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiating the model"
      ],
      "metadata": {
        "id": "-a6gknW1va1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose best configuration from the previous dataset\n",
        "model_2 = CNN(embed_dim=500,\n",
        "            filter_sizes=[3, 5, 7],\n",
        "            num_filters=[120, 120, 120],\n",
        "            num_classes=2,\n",
        "            dropout=0.5)\n",
        "\n",
        "# Send model to `device` (GPU/CPU)\n",
        "model_2.to(device)\n",
        "\n",
        "# Instantiate Adadelta optimizer\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=0.01, rho=0.95)"
      ],
      "metadata": {
        "id": "bvoltO20edhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "t8w2UUlQvd3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Start training loop\n",
        "print(\"Start training...\\n\")\n",
        "print(f\"{'Epoch':^7} | {'Train Loss':^12}\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "for epoch_i in range(50):\n",
        "    total_loss = 0\n",
        "    # Put the model into the training mode\n",
        "    model_2.train()\n",
        "    for step, batch in enumerate(train_dataloader_2):\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "        # Zero out any previously calculated gradients\n",
        "        model_2.zero_grad()\n",
        "        # Perform a forward pass. This will return logits.\n",
        "        logits = model_2(b_input_ids)\n",
        "        # Compute loss and accumulate the loss values\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        total_loss += loss.item()\n",
        "        # Perform a backward pass to calculate gradients\n",
        "        loss.backward()\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = (total_loss / len(train_dataloader_2))\n",
        "    print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ16QP75vfY7",
        "outputId": "bb403fa2-d779-4c6c-e450-0bc5fad7f260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Train Loss \n",
            "------------------------------------------------------------\n",
            "   1    |   0.673050  \n",
            "   2    |   0.635470  \n",
            "   3    |   0.606128  \n",
            "   4    |   0.585084  \n",
            "   5    |   0.562489  \n",
            "   6    |   0.537555  \n",
            "   7    |   0.512713  \n",
            "   8    |   0.482599  \n",
            "   9    |   0.456489  \n",
            "  10    |   0.430594  \n",
            "  11    |   0.402979  \n",
            "  12    |   0.374019  \n",
            "  13    |   0.345472  \n",
            "  14    |   0.324439  \n",
            "  15    |   0.298599  \n",
            "  16    |   0.275204  \n",
            "  17    |   0.256216  \n",
            "  18    |   0.232106  \n",
            "  19    |   0.219697  \n",
            "  20    |   0.202086  \n",
            "  21    |   0.183350  \n",
            "  22    |   0.172613  \n",
            "  23    |   0.160839  \n",
            "  24    |   0.145036  \n",
            "  25    |   0.134568  \n",
            "  26    |   0.124854  \n",
            "  27    |   0.115235  \n",
            "  28    |   0.109627  \n",
            "  29    |   0.100743  \n",
            "  30    |   0.092569  \n",
            "  31    |   0.082842  \n",
            "  32    |   0.082088  \n",
            "  33    |   0.075648  \n",
            "  34    |   0.069962  \n",
            "  35    |   0.064864  \n",
            "  36    |   0.061423  \n",
            "  37    |   0.058191  \n",
            "  38    |   0.053983  \n",
            "  39    |   0.051865  \n",
            "  40    |   0.048661  \n",
            "  41    |   0.047463  \n",
            "  42    |   0.043737  \n",
            "  43    |   0.039368  \n",
            "  44    |   0.038475  \n",
            "  45    |   0.036734  \n",
            "  46    |   0.033648  \n",
            "  47    |   0.033363  \n",
            "  48    |   0.031863  \n",
            "  49    |   0.031500  \n",
            "  50    |   0.031209  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate on test set"
      ],
      "metadata": {
        "id": "CL9gilb6yYRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluate model on the test set:\")\n",
        "print(\"-------------------------------\")\n",
        "evaluate_model(model_2, test_dataloader_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioWMbyz5yYbU",
        "outputId": "903037b2-f7d9-46a0-ed11-78fa9172976d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model on the test set:\n",
            "-------------------------------\n",
            "Accuracy: 0.8032\n",
            "F1 Score: 0.7881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OovkqhTvtv86"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}